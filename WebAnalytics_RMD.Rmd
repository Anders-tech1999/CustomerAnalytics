---
title: "WebAnalytics"
output: html_document
date: "2024-03-21"
---

#CLICKSTREAM Application with clickstreams data        
     Course: Customer Analytics                
     Lecturer: Ana Alina Tudoran               
     Update: Spring 2022                       

## INTRODUCTION
For modeling sequences of clicks:

Virtually any model can be used to analyse clickstream data given the data is pre-processed in the correct way. However, 
 - Neural Networks (NN) and 
 - Markov Chains (MC) 
 are two of the most common type of models used for modeling clickstreams 

- NN are black-box models best for prediction. 
For example, predicting the conversion rate is a standard application. 
- NN are also used for segmentation.
For example, Self-Organizing Maps clustering (SOM clustering) is a type of neural network for unsupervised learning that reduces the data through the use of self-organizing maps (Kohonen, 1998).
- NN are not covered in this course. However, an example of using SOM for customer segmentation can be found in the supplementary reading
*Tudoran, A.A. 2022 A Machine Learning Approach to Identifying Decision-Making Styles for Managing Customer Relationships on Brightspace

Markov chains models are transparent models that are used for predicting, segmenting and understanding customer behavior. 
In this application, I focus on the "clickstream" library to model the clickstream data with MC Markov Chains models. 

## BACKGROUND
What is a (discrete state) Markov Chain? 
[Note: one can have Markov chains with discrete and continuous states in discrete and in continuous time. 
 - Here we focus on discrete state in discrete time] 

A Markov chain is a stochastic process X that takes state "m" from a ﬁnite set of states "M" at each time "n". If the state at time "n" only depends on the recent k states, we call X a Markov chain "of order k". For example:
  
- 0-order Markov chain = the probability to be in any of the "m" states in the next step is independent of the present state
- 1st-order Markov chain = the probability to be in any of the "m" states in the next step is independent of the previous states given the present state (one-period memory)
- 2nd-order Markov chain = two-periods memory
- 3rd-order Markov chain = three-periods memory
- ...so on
  
Markov chains can be described by transition probability matrices
Each value in these matrices is a parameter
Higher-order Markov chains have (m−1)m^k model parameters 
The number of lag parameters increases exponentially


## How we select the Markov chain order? 
- Usually, a user considering a Product Page might either Add the product to the shopping cart, view Product Reviews, follow a Product Recommendation, or Search for another product. 
- Moe (2003) proposes that the probability for a transition to either of the possible next states depends on the MODE (browsing, searching, or buying) the user is currently in. This MODE (latent state) can be identiﬁed when considering the recent k states.

Model order selection is usually based on a criteria like AIC or BIC. 
The function fitMarkovChain() estimates the parameters of a Markov chain model of order k.

How does R interpret the clickstreams? 
Clickstreams = collection of data sequences - with different sizes!

(1) A motivating example
Session 1: P1 P2 P1 P3 P4 Defer (visited Page 1 then Page 2, defer: did not buy)
Session 2: P3 P4 P1 P3 Defer
Session 3: P5 P1 P6 P7 P6 P7 P8 P7 Buy
Session 4: P9 P2 P11 P12 P11 P13 P11 Buy
Session 5: P4 P6 P11 P6 P1 P3 Defer
Session 6: P3 P13 P12 P4 P12 P1 P4 P1 P3 Defer
Session 7: P10 P5 P10 P8 P8 P5 P1 P7 Buy
Session 8: P9 P2 P1 P9 P3 P1 Defer
Session 9: P5 P8 P5 P7 P4 P1 P6 P4 Defer

13 possible product pages
2 absorbing states

a clickstream =  a sequence of click events for exactly one session of an online store user
a clickstream = a vector in R
a collection of clickstreams = a list in R
we read the list of cliskstreams from a file using "readClickstreams()" function
it is a comma-separated file and each line is exactly one clicktream

```{r}
#install.packages("clickstream")
library("clickstream")
cls <- readClickstreams(file = "C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Web Analytics/sample.csv", sep = ",", header = TRUE) 
cls
# writeClickstreams(cls, "sample.csv", header = TRUE, sep = ",")
```
Defer: Udskyde


Here the Markow Order is determined
- 2nd-order Markov chain = two-periods memory
```{r Markov Chain - 2nd order}
mc <- fitMarkovChain(clickstreamList = cls, 
                     order = 2, #quantity of lags (amount of sheets produced in output)
                     # second-order Markov chain is being fitted, meaning the next state depends on the current state and the previous state.
                     control = list(optimizer = "quadratic")) 
mc
# notice:
# - the two transition probabilities matrices for the two lags
# - start probabilities for the states the corresponding clickstreams started 
# - end probabilities for the states the corresponding clickstreams ended

# fitMarkovChain() computes the log-likelihood of the model
```
 o Transition Probabilities:
Lag:  1 
lambda:  0.22´

Lag:  2 
lambda:  0.78 
 - lambda values show how much weight each lag contributes to the prediction of the next state.
 
 o Start Probabilities:
  P1  P10   P3   P4   P5   P9 
0.11 0.11 0.22 0.11 0.22 0.22
 - There is 22% chance for a customer starting on Page 3, Page 5, Page 9
 - and so on...

 o End Probabilities:
  Buy Defer 
 0.33  0.67 
 - There is 33% chance for a customer to BUY
 - There is 67% chance for a customer to DEFER

 o First output sheet:
probs in the first order Markov chain
 o Second output sheet:
probs in the second order Markov chain


```{r PlotMarkowChain + AIC BIC }
# based on this, one can get AIC and BIC to compare two fitted Markov models
summary(mc) 
# model plot
plot(mc, order = 2) #has to be consistent with the upper script
```
 o LogLikelihood: -66
 - The log-likelihood value is a measure of the model’s fit to the data. 
 - Higher (less negative) values indicate a better fit.
 - A log-likelihood of -66 indicates how well the model explains the observed sequences of states.
 
 o BIC: 268
 - Bayesian Information Criterion (BIC) is similar to AIC but includes a stronger penalty for models with more parameters.
 - Lower BIC values indicate a better model, favoring simpler models that fit the data well.

SUMMARY: if running different markov chain orders (lags), the BIC and LogLikelihood can decide the better model.

## Predict next Click
i)  Predict either the next click or the ﬁnal click (state) of a customer. 
 - If a customer starts with the clickstream P9 P2, what will do next?
```{r Predict next Click - Page 9 --> Page2 --> PageX }
pattern <- new("Pattern", sequence = c("P9", "P2"))

resultPattern <- predict(mc, startPattern = pattern, dist = 1)
resultPattern
```
SUMMARY:
 - The user will most likely click on P1 next with a 0.67 prob.



If a customer has recently viewed products P9 and P2, 
 - what is the prediction for the next two clicks?
 
We add: absorbingProbabilities = data.frame(Buy = 0.333, Defer = 0.667)) 
 - which comes from:
      End Probabilities:
        Buy     Defer 
        0.3333333 0.6666667
```{r Predict Purchase }
pattern <- new("Pattern", 
               sequence = c("P9", "P2"), 
               absorbingProbabilities = data.frame(Buy = 0.333, Defer = 0.667))

resultPattern <- predict(mc, startPattern = pattern, dist = 2)
resultPattern
```
Sequence: P1 P3
Probability: 0.26
 - Customer visits products P1 and P3 but 
 - the probability that she really continues visiting products P1 P3 is only 26.17%.
 
Buy     0.058
Defer   0.94
 - Purchasing probability is 5.83% after 2 further clicks,
 - Defer probability is 94% after 2 further clicks,
 - she most likely defers the purchase

##Initial absorbing probabilities
Online stores often have evidence on how many of the visitors convert to a buyer (this info is typically used to formulate initial absorbing probabilities for all users). But, particularly for customers who log on to their account, the online stores can also know how many times a particular user has been only visiting the online store and how often she has bought a product, 
This information can be used to formulate initial absorbing probabilities for a user. 
 - If for example a user has been logged in and ﬁnally bought a product in 50% of her log-ins, we can compute absorbing probabilities (posterior) for a stream of clicks:
```{r Predict Specific Customer Purchase }
absorbingProbabilities <- c(0.5, 0.5) #initial specific customer prior probs for buy or defer
                #"user has been logged in and ﬁnally bought a product in 50% of her log-ins"
sequence <- c("P9", "P2")
for (s in sequence) {
  absorbingProbabilities <- absorbingProbabilities * data.matrix(subset(mc@absorbingProbabilities, state == s, select = c("Buy", "Defer")))
       }
absorbingProbabilities <- absorbingProbabilities /sum(absorbingProbabilities)
absorbingProbabilities
```
    Buy Defer
15 0.23  0.77
 - 23% to ﬁnally BUY a product after she has visited products P9 and P2.
 - 77% to ﬁnally DEFER a product after she has visited products P9 and P2.
 - This is a more "informed" approach having the specific customer prior buy/defer end probs.


## Clustering before Markov Chain
ii) An alternative before running the model is to identify segments of customers by clustering clickstreams and afterwards building a model within each cluster
(Reference: Huang, Ng, Ching, Ng, and Cheung, 2001, k-means alg. and Euclidean distance) 
```{r Identify Segments of customers buy/defer }
set.seed(12345)
clusters <- clusterClickstreams(clickstreamList = cls,
                                order = 1, #order of the Markov chain (1st order in this case, meaning the next state depends only on the current state).
                                centers = 3) #number of clusters to be created.
clusters
#clusters$clusters[[1]] This prints the specific cluster
#clusters$clusters[[2]]
#clusters$clusters[[3]]
```
Shows the clustered clickstream data divided into three clusters. 
Each cluster contains the sequences (sessions) of clickstreams that were grouped together based on their similarity

 o Cluster 1:
[[1]]Clickstreams
Session3: P5 P1 P6 P7 P6 P7 P8 P7 Buy
Session7: P10 P5 P10 P8 P8 P5 P1 P7 Buy
Session9: P5 P8 P5 P7 P4 P1 P6 P4 Defer
 - Cluster 1 tends to have a "Buy" action at the end 
 - or multiple "P" actions before reaching "Defer."

 o Cluster 3:
[[3]] Clickstreams
Session2: P3 P4 P1 P3 Defer
Session5: P4 P6 P11 P6 P1 P3 Defer
Session6: P3 P13 P12 P4 P12 P1 P4 P1 P3 Defer
- Cluster 3 ends in "Defer" with repeated actions around "P1," "P3," and "P4."
- Cluster 3 starts on Page 3 or 4 and ends in Defer


```{r}
clusters$clusters[[1]]
```
FROM "Real data Clickstream" - ADJUST IT
o Observations: 4324
 - The total number of observations (clicks) in the first cluster.

 o Click Frequencies:
 - shows the frequency of clicks for different pages within the FIRST cluster
            AddCartPage               CartPage           CategoryPage 
                  2254                   3014                  23663 
             ChannelAd    ChannelDirectAccess           ChannelOther 
                  4131                   4648                    138 
ChannelPriceComparison    ChannelSearchEngine  ChannelSocialNetworks 
                   437                   2896                     42 
        ChannelWebmail             Conversion           DeliveryPage 
                   161                    681                    622 
          DiscountPage              FrontPage            LandingPage 
                  2874                   7625                   1216 
             OtherPage         ProductDetails            ProductPage 
                  1018                  15366                  19903 
        Recommendation         SearchFunction 
                   249                   1830


```{r MarkovChain - Specific Customer Purchase }
# Fit a ‘MarkovChain’ object for each ‘Clickstreams’ object 
mc_clu1 <- fitMarkovChain(clickstreamList = clusters$clusters[[1]], order = 2,control = list(optimizer = "quadratic"))
mc_clu1
  
#mc_clu2 <- fitMarkovChain(clickstreamList = clusters$clusters[[2]], order = 2,control = list(optimizer = "quadratic"))
#mc_clu2
  
#mc_clu3 <- fitMarkovChain(clickstreamList = clusters$clusters[[3]], order = 2,control = list(optimizer = "quadratic"))
#mc_clu3
# or write these objects to ﬁle with writeClickstreams().
```
 o Transition Probabilities:
Lag:  1 
lambda:  1´

Lag:  2 
lambda:  3.3e-08 (approx 0%) 
 - lambda values show how much weight each lag contributes to the prediction of the next state.
 
 o Start Probabilities:
P10   P5 
0.33  0.67
 - There is 67% chance for a customer starting on Page 5

 o End Probabilities:
  Buy Defer 
 0.67  0.33 
 - There is 67% chance for a customer to BUY
 - There is 33% chance for a customer to DEFER

 o First output sheet:
probs in the first order Markov chain
 o Second output sheet:
probs in the second order Markov chain


#Simulated Clickstream data
(2) Full example with simulated data
- clickstreams for 100,000 user sessions 
- clicks are either one of 7 products or on one of the two ﬁnal states "Buy" and "Defer".
```{r Clickstream 10.000 users }
# Prepare the data
set.seed(123)
cls_sim <- randomClickstreams(
  states = c("P1", "P2", "P3", "P4", "P5", "P6", "P7", "Defer", "Buy"),
  startProbabilities = c(0.2, 0.25, 0.1, 0.15, 0.1, 0.1, 0.1, 0, 0),
  transitionMatrix = matrix(c(0.01, 0.09, 0.05, 0.21, 0.12, 0.17, 0.11, 0.2, 0.04,
                                                        0.1, 0, 0.29, 0.06, 0.11, 0.13, 0.21, 0.1, 0,
                                                        0.07, 0.16, 0.03, 0.25, 0.23, 0.08, 0.03, 0.12, 0.03,
                                                        0.16, 0.14, 0.07, 0, 0.05, 0.22, 0.19, 0.1, 0.07,
                                                        0.24, 0.27, 0.17, 0.13, 0, 0.03, 0.09, 0.06, 0.01,
                                                        0.11, 0.18, 0.04, 0.15, 0.26, 0, 0.1, 0.11, 0.05,
                                                        0.21, 0.07, 0.08, 0.2, 0.14, 0.18, 0.02, 0.08, 0.02,
                                                        0, 0, 0, 0, 0, 0, 0, 0, 0,
                                                        0, 0, 0, 0, 0, 0, 0, 0, 0),
                            nrow = 9),
meanLength = 50, n = 10000) #Alina is using 100000
summary(cls_sim)
```


```{r Chose Markov Order }
# select the model (Markov chain order)
maxOrder <- 5 
result <- data.frame()
  for (k in 1:maxOrder) {
    mc <- fitMarkovChain(clickstreamList = cls_sim, order = k)
    result <- rbind(result, c(k, summary(mc)$aic, summary(mc)$bic))
  }
names(result) <- c("Order", "AIC", "BIC")
result
```
We aim for the BIC with the value closest to zero
 - Choose BIC 267932
 - 3rd order Markov Chain
In this case, we choose Order 3, but Alina choose 2 with 100.000 users


Fit the selected model
```{r Fit Chosen X-Order MarkovChain }
mc <- fitMarkovChain(clickstreamList = cls, 
                     order = 3,
                     control = list(optimizer = "quadratic")) 
mc
```
 o Transition Probabilities:
Lag:  1 
lambda:  3.3e-08 (approx 0%) 

Lag:  2 
lambda:  0.95 
 
Lag:  3 
lambda:  0.05
 - lambda values show how much weight each lag contributes to the prediction of the next state.
 
 o Start Probabilities:
P1  P10   P3   P4   P5   P9 
0.11 0.11 0.22 0.11 0.22 0.22
 - There is 22% chance for a customer starting on Page 3, Page 5, Page 9

 o End Probabilities:
Buy Defer 
 0.33  0.67 
 - There is 33% chance for a customer to BUY
 - There is 67% chance for a customer to DEFER

 o First output sheet:
probs in the first order Markov chain
 o Second output sheet:
probs in the second order Markov chain
and so on...



Predict the next click (absorbtion probs)
If a customer has recently viewed products P3 and P4, 
 - what is the prediction for the next two clicks?
We add: absorbingProbabilities = data.frame(Buy = 0.33, Defer = 0.67)) 
 - which comes from:
      End Probabilities:
        Buy     Defer 
        0.33 0.67
```{r Predict next Click }
pattern <- new("Pattern", 
               sequence = c("P3", "P4"), 
               absorbingProbabilities = data.frame(Buy = 0.33, Defer = 0.67))

resultPattern <- predict(mc, startPattern = pattern, dist = 1)
resultPattern
```
Sequence: Defer
Probability: 0.56
 - Customer visits products P1 and P3 but 
 - the probability that the customer defers is 0.56%
 
Buy     0
Defer   1
 - Purchasing probability is 0% after 2 further clicks,
 - Defer probability is 1% after 2 further clicks,
 - she definately defers the purchase
 


Clustering before Markov Chain
 - An alternative before running the model is to identify segments of customers by clustering clickstreams 
 - and afterwards building a model within each cluster
 - fit a markovchain per cluster and predict; clustering clickstreams is useful in case of high clickstream heterogeneity
```{r Cluster - Predict Specific Customer Purchase }
clusters_sim <- clusterClickstreams(clickstreamList = cls, 
                                    order = 1, 
                                    centers = 3)  # takes 5-10 min. to converge
clusters_sim
#summary(clusters_sim$clusters[[1]]) 
#summary(clusters_sim$clusters[[2]]) 
#summary(clusters_sim$clusters[[3]])
```
Shows the clustered clickstream data divided into three clusters. 
Each cluster contains the sequences (sessions) of clickstreams that were grouped together based on their similarity

 o Cluster 2:
[[1]]Clickstreams
Session3: P5 P1 P6 P7 P6 P7 P8 P7 Buy
Session7: P10 P5 P10 P8 P8 P5 P1 P7 Buy
Session9: P5 P8 P5 P7 P4 P1 P6 P4 Defer
 - Cluster 1 tends to have a "Buy" action at the end 
 - Cluster 1 has Page 7 before purchase

 o Cluster 3:
[[3]] Clickstreams
Session2: P3 P4 P1 P3 Defer
Session5: P4 P6 P11 P6 P1 P3 Defer
Session6: P3 P13 P12 P4 P12 P1 P4 P1 P3 Defer
- Cluster 3 ends in "Defer" with repeated actions around "P1" and "P3"
- Cluster 3 starts on Page 3 or 4 and ends in Defer (as in the absorption findings)


Markov Chain for Cluster 1
```{r Cluster - Predict Specific Customer Purchase }
# markov chain for clu 1 
maxOrder <- 5 
result <- data.frame()
  for (k in 1:maxOrder) {
    mc <- fitMarkovChain(clickstreamList = clusters_sim$clusters[[1]], order = k)
    result <- rbind(result, c(k, summary(mc)$aic, summary(mc)$bic))
  }
names(result) <- c("Order", "AIC", "BIC")
result
```
Aim for the BIC with the value closest to zero
 - Choose BIC 62
 - 1st order Markov Chain

Choosing 1st order Markov Chain for Cluster 1
```{r Cluster - Predict Specific Customer Purchase }
mc_clu1 <- fitMarkovChain(clickstreamList = clusters_sim$clusters[[1]], 
                          order = 1) 
mc_clu1
```
        1st order Markov Chain for Clsuter 1
 o Transition Probabilities:
Lag:  1 
lambda:  1
 - lambda values show how much weight each lag contributes to the prediction of the next state.
 
 o Start Probabilities:
  P1   P9 
0.33 0.67
 - There is 67% chance for a customer starting on Page 9

 o End Probabilities:
Buy Defer 
 0.33  0.67 
 - There is 33% chance for a customer to BUY
 - There is 67% chance for a customer to DEFER

 o First output sheet:
probs in the first order Markov chain


NOT WORKING
```{r Cluster - Predict Specific Customer Purchase }
pattern <- new("Pattern", 
               sequence = c("P1", "P4", "P6"), 
               absorbingProbabilities = data.frame(Buy = 0.33, Defer = 0.67))

resultPattern <- predict(mc_clu1, startPattern = pattern, dist = 1)
resultPattern
```



#Real data Clickstream
(3) Example with real data 
 - (A Danish company provided us with a file of clickstream data on their e-commerce customers).
```{r  }
library("clickstream")
#mydata  <- readClickstreams(file = "~/Documents/Alina Tudoran/TEACHING/Postgraduate/Customer Analytics/6. CLICKSTREAMS/Lecture 2 Application R/StepsDesktop.csv", sep=",",header = T)
```

```{r}
library("clickstream")
mydata <- readClickstreams(file = "C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Web Analytics/StepsDesktop.csv", sep=",",header = T)
```


```{r  }
maxOrder <- 3 
result <- data.frame()
  for (k in 1:maxOrder) {
    mc <- fitMarkovChain(clickstreamList = mydata, order = k)
    result <- rbind(result, c(k, summary(mc)$aic, summary(mc)$bic))
  }
  names(result) <- c("Order", "AIC", "BIC")
  result
```
We aim for the BIC with the value closest to zero
 - Choose BIC 970591.8
 - 1st order Markov Chain


Fit the selected model
```{r  }
# mc order k = 1
mc <- fitMarkovChain(clickstreamList = mydata, 
                     order = 1,
                     control = list(optimizer = "quadratic")) 
mc
```
 o Transition Probabilities:
Lag:  1 
lambda:  1
 - lambda values show how much weight each lag contributes to the prediction of the next state.

 o Start Probabilities:
ChannelAd    ChannelDirectAccess    ChannelOther 
0.445329933   0.128705770            0.004011263 
ChannelPriceComparison    ChannelSearchEngine  ChannelSocialNetworks 
0.068882159               0.284720009            0.009430454 
ChannelWebmail 
0.058920412 
 - There is 44,5% chance for a customer starting on ChannelAd
 - and so on...

 o End Probabilities:
          AddCartPage               CartPage           CategoryPage 
          2.364255e-03           1.522155e-02           2.464403e-01 
             ChannelAd    ChannelDirectAccess ChannelPriceComparison 
          6.109871e-04           5.844225e-04           5.312932e-05 
   ChannelSearchEngine         ChannelWebmail             Conversion 
          1.859526e-04           2.656466e-05           5.565296e-02 
          DeliveryPage           DiscountPage              FrontPage 
          1.636383e-02           5.815004e-02           4.709914e-02 
           LandingPage              OtherPage         ProductDetails 
          7.172458e-03           5.443099e-02           1.487355e-01 
           ProductPage         Recommendation         SearchFunction 
          3.317129e-01           1.992349e-03           1.320264e-02
 - There is no chance for end at all???



Predict
Predict either the next click or the ﬁnal click (state) of a customer. 
 - If a customer starts with the clickstream DeliveryPage, what will do next?
```{r Predict }
# Predict
pattern <- new("Pattern", 
               sequence = c("DeliveryPage"))
resultPattern <- predict(mc, startPattern = pattern, dist = 1)
resultPattern

#pattern <- new("Pattern", 
#               sequence = c("AddCartPage"))
#resultPattern <- predict(mc, startPattern = pattern, dist = 1)
#resultPattern

#pattern <- new("Pattern", 
#               sequence = c("AddCartPage", "CartPage"))
#resultPattern <- predict(mc, startPattern = pattern, dist = 1)
#resultPattern

#pattern <- new("Pattern", 
#               sequence = c("DeliveryPage"))
#resultPattern <- predict(mc, startPattern = pattern, dist = 1)
#resultPattern
```
SUMMARY:
 - The user will most likely click on ChannelDirectAccess next with a 0.20 prob.



Clustering
An alternative before running the model is to identify segments of customers by clustering clickstreams and afterwards building a model within each cluster
```{r  }
# Clustering first 
clusters_ex <- clusterClickstreams(clickstreamList = mydata, 
                                   order = 1, 
                                   centers = 3)  # takes 5-10 min. to converge
summary(clusters_ex$clusters[[1]]) # cluster 1

#clusters_ex
#Will print output for the sequences for all 3 clusters
```
 o Observations: 4324
 - The total number of observations (clicks) in the first cluster.

 o Click Frequencies:
 - shows the frequency of clicks for different pages within the FIRST cluster
            AddCartPage               CartPage           CategoryPage 
                  2254                   3014                  23663 
             ChannelAd    ChannelDirectAccess           ChannelOther 
                  4131                   4648                    138 
ChannelPriceComparison    ChannelSearchEngine  ChannelSocialNetworks 
                   437                   2896                     42 
        ChannelWebmail             Conversion           DeliveryPage 
                   161                    681                    622 
          DiscountPage              FrontPage            LandingPage 
                  2874                   7625                   1216 
             OtherPage         ProductDetails            ProductPage 
                  1018                  15366                  19903 
        Recommendation         SearchFunction 
                   249                   1830



CLUSTER 1
```{r  }
# mc for clu 1 
maxOrder <- 3 
result <- data.frame()
  for (k in 1:maxOrder) {
    mc <- fitMarkovChain(clickstreamList = clusters_ex$clusters[[1]], order = k)
    result <- rbind(result, c(k, summary(mc)$aic, summary(mc)$bic))
  }
names(result) <- c("Order", "AIC", "BIC")
result
```
Aim for the BIC with the value closest to zero
 - Choose BIC 254074.7
 - 1st order Markov Chain


CLUSTER 2
```{r  }
summary(clusters_ex$clusters[[2]]) # clu 2
  # mc for clu 2 
maxOrder <- 2
result <- data.frame()
  for (k in 1:maxOrder) {
    mc <- fitMarkovChain(clickstreamList = clusters_ex$clusters[[2]], order = k)
    result <- rbind(result, c(k, summary(mc)$aic, summary(mc)$bic))
  }
names(result) <- c("Order", "AIC", "BIC")
result
```
Aim for the BIC with the value closest to zero
 - Choose BIC 287330.6
 - 1st order Markov Chain
 
CLUSTER 3
```{r  }
summary(clusters_ex$clusters[[3]]) # clu 3
  # mc for clu 3
maxOrder <- 3
result <- data.frame()
  for (k in 1:maxOrder) {
    mc <- fitMarkovChain(clickstreamList = clusters_ex$clusters[[3]], order = k)
    result <- rbind(result, c(k, summary(mc)$aic, summary(mc)$bic))
  }
names(result) <- c("Order", "AIC", "BIC")
result
```
Aim for the BIC with the value closest to zero
 - Choose BIC 400087.3
 - 1st order Markov Chain


Fit selected model among Cluster 1 2 3
 - Choosing Cluster 1 with the lowest BIC value
```{r  }
mc_clu1 <- fitMarkovChain(clickstreamList = clusters_ex$clusters[[1]], 
                          order = 1) 
mc_clu1

#mc_clu2 <- fitMarkovChain(clickstreamList = clusters_ex$clusters[[2]], order = 1) 
#mc_clu2

#mc_clu3 <- fitMarkovChain(clickstreamList = clusters_ex$clusters[[3]], order = 1) 
#mc_clu3
```
 o Transition Probabilities:
Lag:  1 
lambda:  0.96
 - lambda values show how much weight each lag contributes to the prediction of the next state.
 
 o Start Probabilities:
          ChannelAd           ChannelDirectAccess       ChannelOther 
          0.2469935245           0.3855226642           0.0009250694 
ChannelPriceComparison    ChannelSearchEngine  ChannelSocialNetworks 
          0.0173450509           0.3330249769           0.0013876041 
        ChannelWebmail 
          0.0148011101
 - There is 38% chance for a customer starting on ChannelDirectAccess
 - There is 24% chance for a customer starting on ChannelAd

 o End Probabilities:
      AddCartPage            CartPage          CategoryPage 
       0.0030064755        0.0444033302        0.3267807586 
ChannelDirectAccess          Conversion        DeliveryPage 
       0.0009250694        0.1574930620        0.0111008326 
       DiscountPage           FrontPage         LandingPage 
       0.0284458834        0.0450971323        0.0039315449 
          OtherPage      ProductDetails         ProductPage 
       0.0136447734        0.1348288622        0.2185476411 
     Recommendation      SearchFunction 
       0.0006938020        0.0111008326
 - There is 13,5% chance for a customer to end on ProductDetails
 - There is 32,68% chance for a customer to ProductDetails

 o First output sheet:
probs in the first order Markov chain

 o Slides Comments
 - clust.2 and clust.3 search a lot through Category page; 
 - clust.1 search more through Product page;
 - cl.1 and cl.3 search more varied (use more channels than cl.2)
 - cl.3 are more likely to enter through DirectAccess -> Front page pattern than the other two clusters.
 - In this application the product page was generalized. 
 - However, if a more fine-grained clicktream data were available by product brand it will allow the manager to take informed decisions about the preferences of each cluster.


```{r  }
# model graphical representation (i)
  plot(mc_clu1, order = 1)
  plot(mc_clu2, order = 1)
  plot(mc_clu3, order = 1)
```


```{r  }
# model graphical representation (ii)
  par(mfrow=c(1,3))
  par(mar=c(1, 1, 4, 0))
  set.seed(11)
  plot(mc_clu1, order = 1, digits = 1, minProbability = 0.40,
       vertex.color=0,
       vertex.frame.color=0,
       vertex.shape="none",
       vertex.size=8, 
       vertex.size2=3,
       vertex.label.dist=0.4, 
       vertex.color="transparent",
       vertex.label.font=2,
       vertex.label.cex=0.95, 
       vertex.label.degree=1,
       vertex.label.color="black",
       edge.arrow.size=0.2,
       edge.label.cex = 0.9, 
       edge.curved=0,
       edge.label.font=4,
       margin=c(0,0,0,0.15),
       main ="Cluster 1")
```


```{r  }
set.seed(11)
  plot(mc_clu2, order = 1, digits = 1, minProbability = 0.40,
       vertex.color=0,
       vertex.frame.color=0,
       vertex.shape="none",
       vertex.size=8, 
       vertex.size2=3,
       vertex.label.dist=0.4, 
       vertex.color="transparent",
       vertex.label.font=2,
       vertex.label.cex=0.95, 
       vertex.label.degree=1,
       vertex.label.color="black",
       edge.arrow.size=0.2,
       edge.label.cex = 0.9, 
       edge.curved=0,
       edge.label.font=4,
       margin=c(0,0,0,0.15),
       main ="Cluster 2")
```


```{r  }
set.seed(11)
  plot(mc_clu3, order = 1, digits = 1, minProbability = 0.40,
       vertex.color=0,
       vertex.frame.color=0,
       vertex.shape="none",
       vertex.size=8, 
       vertex.size2=3,
       vertex.label.dist=0.4, 
       vertex.color="transparent",
       vertex.label.font=2,
       vertex.label.cex=0.95, 
       vertex.label.degree=1,
       vertex.label.color="black",
       edge.arrow.size=0.2,
       edge.label.cex = 0.9, 
       edge.curved=0,
       edge.label.font=4,
       margin=c(0,0,0,0.15),
       main ="Cluster 3")
  
  # Characterizing the clusters. Who are the customers underlying the three 
  # patterns of movement within the website?
  # cl.2 and cl.3 search a lot through Category page; 
  # cl.1 search more through Product page;
  # cl.1 and cl.3 search more varied (use more channels than cl.2)
  # cl.3 are more likely to enter through DirectAccess -> Front page pattern
  # than the other two clusters.
  # In this application the product page was generalized. 
  # However, if a more fine-grained clicktream data were available by product brand
  # it will allow the manager to take informed decisions about the preferences of each cluster.
```




Predict either the next click or the ﬁnal click (state) of a customer. 
 - If a customer starts with the clickstream "AddCartPage", "CartPage", what will do next?
 - CLUSTER 1 and 2 and 3
 - CLUSTER 1 output:
```{r  }
# predicting the next steps
pattern <- new("Pattern", 
               sequence = c("AddCartPage", "CartPage"))

resultPattern <- predict(mc_clu1, startPattern = pattern, dist = 1)
resultPattern
  
#pattern <- new("Pattern", 
#               sequence = c("AddCartPage", "CartPage"))

#resultPattern <- predict(mc_clu2, startPattern = pattern, dist = 1)
#resultPattern
  
#pattern <- new("Pattern", 
#               sequence = c("AddCartPage", "CartPage"))

#resultPattern <- predict(mc_clu3, startPattern = pattern, dist = 1)
#resultPattern

# Possible covariates: product category, device. In that case, the analysis 
# should be done by category and device.
```
CLUSTER 1
SUMMARY:
 - The user from CLUSTER 1 will most likely click on ProductPage next with a 0.21 prob.


# Sequential patterns
(4) A second alternative to modeling clickstreams with higher-order Markov chains is representing them as 
 - sequential patterns. 
 - Such an approach answers to the following question: Which are the patterns sequences most supported in each group? 
using "arulesSequences" and "arulesViz" for vizualization
Extracting all click patterns with a particular minimum support (Apriori algorithm)
```{r  }
library("arules")
  library("arulesSequences")

# looking by clustered data
trans_clu1<- as.transactions(clusters$clusters[[1]]) 
sequences_clu1 <- as(
  apriori(trans_clu1, parameter = list(support = 0.50)),
  "data.frame") 
sequences_clu1
# subrules <- subset(sequences_clu1, support>0.05)
  
#trans_clu2<- as.transactions(clusters$clusters[[2]]) 
#sequences_clu2 <- as(
#  apriori(trans_clu2, parameter = list(support = 0.50)), 
#  "data.frame")
#sequences_clu2
  
#trans_clu3<- as.transactions(clusters$clusters[[3]]) 
#sequences_clu3 <- as(
#  apriori(trans_clu3, parameter = list(support = 0.50)), 
#  "data.frame")
#sequences_clu3
```

 o Slides Comments:
 - The corresponding output shows that pattern sequences are supported by at least 50% of the clickstreams in each cluster. 
 - cluster 1 of clickstream is the most heterogeneeous. 
 - The most common pattern {ChannelAd} => {ProductPage} has support in 41% of the clicks in clust1. This pattern reflects that these customers are most likely acquired through re-targeting.


FUCK THE KING
```{r  }
# vizualization
  library("arulesViz")
  sequences_clu1 <- apriori(trans_clu1, parameter = list(support = 0.40))
  ruleExplorer(sequences_clu1)
  sequences_clu2 <- apriori(trans_clu2, parameter = list(support = 0.50))
  ruleExplorer(sequences_clu2)
  sequences_clu3 <- apriori(trans_clu3, parameter = list(support = 0.50))
  ruleExplorer(sequences_clu3)
  # this approach is also useful for discovering product/brands that are seen together

  
# (5) A third approach to work with clickstream data is to use frequencies of events instead of sequences. 
  # Disadv: the sequential structure is lost.
  # Adv: a variety of prediction methods seen in the Machine Learning can be applied using these frequency data
  frequencyDF <- frequencies(mydata)
  frequencyDF

# (6) A fourth option is to use Neural Networks (recurrent or not) with sequences 
  # of clickstream data purely for prediction purposes. NN are not covered in this course.  


# (7) Optional exercise with solution
  # Consider a real-life data set from Cadez, I., Heckerman, D., Meek, C., 
  # Smyth, P., White, S. (2003) Model-based clustering and visualization 
  # of navigation patterns on a web site, Data Mining and Knowledge Discovery, 399-424.
  # The dataset msnbc323 (Melnykov 2016a) is available 
  # in data("msnbc323", package = "ClickClust"). 
  # There are 323 clickstream sequences that involve 17 different states:
  
  # (1) frontpage, (2) news, 
  # (3) tech, (4) local, 
  # (5) opinion, (6) on-air,
  # (7) miscellaneous, (8) weather, 
  # (9) msn-news, (10) health-on-air, 
  # (11) living, (12) business, 
  # (13) msn-sports, (14) sports, 
  # (15) summary-news, (16) bbs, 
  # and (17) travel. 
  
  # The length of sequences varies from 35 to 362. 
  # There are 289 possible transitions among the 17 states. 
  
  library(ClickClust)
  data("msnbc323", package = "ClickClust")
  summary(msnbc323)
  clusters <- clusterClickstreams(clickstreamList = msnbc323, order = 1, centers = 3)  # takes 5-10 min. to converge
 
  
  # mc for clu 1 
  maxOrder <- 5 
  result <- data.frame()
  for (k in 1:maxOrder) {
    mc <- fitMarkovChain(clickstreamList = clusters$clusters[[1]], order = k)
    result <- rbind(result, c(k, summary(mc)$aic, summary(mc)$bic))
  }
  names(result) <- c("Order", "AIC", "BIC")
  result
  #1
  
  # mc for clu 2 
  maxOrder <- 5 
  result <- data.frame()
  for (k in 1:maxOrder) {
    mc <- fitMarkovChain(clickstreamList = clusters$clusters[[2]], order = k)
    result <- rbind(result, c(k, summary(mc)$aic, summary(mc)$bic))
  }
  names(result) <- c("Order", "AIC", "BIC")
  result
  #1
  
  
  # mc for clu 3
  maxOrder <- 5 
  result <- data.frame()
  for (k in 1:maxOrder) {
    mc <- fitMarkovChain(clickstreamList = clusters$clusters[[3]], order = k)
    result <- rbind(result, c(k, summary(mc)$aic, summary(mc)$bic))
  }
  names(result) <- c("Order", "AIC", "BIC")
  result
  #1
  
  mc_clu1 <- fitMarkovChain(clickstreamList = clusters$clusters[[1]], order = 1) 
  summary(mc_clu1)
  mc_clu2 <- fitMarkovChain(clickstreamList = clusters$clusters[[2]], order = 1) 
  summary(mc_clu2)
  mc_clu3 <- fitMarkovChain(clickstreamList = clusters$clusters[[3]], order = 1) 
  summary(mc_clu3)
  
  
  # graphically
  par(mfrow=c(1,3))
  par(mar=c(1, 1, 4, 0))
  set.seed(11)
  plot(mc_clu1, order = 1, digits = 1, minProbability = 0.40,
       vertex.color=0,
       vertex.frame.color=0,
       vertex.shape="none",
       vertex.size=8, 
       vertex.size2=3,
       vertex.label.dist=0.4, 
       vertex.color="transparent",
       vertex.label.font=2,
       vertex.label.cex=0.95, 
       vertex.label.degree=1,
       vertex.label.color="black",
       edge.arrow.size=0.2,
       edge.label.cex = 0.9, 
       edge.curved=0,
       edge.label.font=4,
       margin=c(0,0,0,0.15),
       main ="Cluster 1")
  
  
  set.seed(11)
  plot(mc_clu2, order = 1, digits = 1, minProbability = 0.40,
       vertex.color=0,
       vertex.frame.color=0,
       vertex.shape="none",
       vertex.size=8, 
       vertex.size2=3,
       vertex.label.dist=0.4, 
       vertex.color="transparent",
       vertex.label.font=2,
       vertex.label.cex=0.95, 
       vertex.label.degree=1,
       vertex.label.color="black",
       edge.arrow.size=0.2,
       edge.label.cex = 0.9, 
       edge.curved=0,
       edge.label.font=4,
       margin=c(0,0,0,0.15),
       main ="Cluster 2")
  
  
  set.seed(11)
  plot(mc_clu3, order = 1, digits = 1, minProbability = 0.40,
       vertex.color=0,
       vertex.frame.color=0,
       vertex.shape="none",
       vertex.size=8, 
       vertex.size2=3,
       vertex.label.dist=0.4, 
       vertex.color="transparent",
       vertex.label.font=2,
       vertex.label.cex=0.95, 
       vertex.label.degree=1,
       vertex.label.color="black",
       edge.arrow.size=0.2,
       edge.label.cex = 0.9, 
       edge.curved=0,
       edge.label.font=4,
       margin=c(0,0,0,0.15),
       main ="Cluster 3")
  
  # interpret: 
  
  # Cluster 2 is entirely driven by transitions within the same categories
  # Thus, this group represents people who make the majority of transitions within their 
  # preferred category and do not change categories frequently.
  
  # Cluster 1 The second cluster is characterized by higher probabilities of transitions 
  # front page–news, news–news, msn-news, and summary–news. 
  # The transition front page–news reﬂects the common pattern for the users starting with 
  # the category front page to proceed directly to the category news. 
  # Once the reader gets to the category news, he or she typically stays within it or proceeds 
  # to summary.Thus, the second cluster consists of people mostly concerned with news. 
  
  # Cluster 3 is characterized by transitions travel-health-on-air, travel-frontpage, 
  # consisting of the people concerned about travelling issues.
  
  # The analysis of this dataset illustrates how click-plots can 
  # be used and interpreted to discover interesting navigation patterns common for 
  # observations within detected clusters.
```



#CHOICE MODELING

## Choice-based conjoint analysis
```{r}
# data
cbc.df <- read.csv("http://goo.gl/5xQObB",colClasses=c(seat="factor", 
                                                     cargo ="factor", 
                                                     price="factor",
                                                     choice="integer"))
cbc.df$eng<-factor(cbc.df$eng,levels=c("gas","hyb","elec"))
cbc.df$carpool<-factor(cbc.df$carpool,levels=c("yes","no"))
summary(cbc.df)
```
 - ques: This represents the question number. Each respondent answered up to 15 questions.

 - alt: indicates the alternative (option) number presented to the respondent. Each respondent was given up to 3 alternatives to choose from.
 
carpool: This categorical variable indicates whether the car supports carpooling ("yes" or "no"). 
 - There are 2655 instances of "yes" and 6345 instances of "no".

seat: This represents the seating capacity of the car, 
 - which is either 6 or 8 seats.

cargo: This indicates the cargo capacity, 
 - which is either 2ft or 3ft.

eng: This categorical variable represents the type of engine: "gas", "hyb" (hybrid), or "elec" (electric). 
 - Each type has roughly 3000 instances.

price: This categorical variable represents the price of the car, 
 - with 3 distinct pricelevels

choice: This integer variable indicates the choice made by the respondent, 
 - with "1" indicating the chosen alternative and 
 - "0" or "-1" indicating the non-chosen alternatives



```{r Inspect data }
#summary(cbc.df)
xtabs(choice~price,data=cbc.df) #Creates a cross-tabulation of counts between the choice and price variables in the cbc.df data frame.
xtabs(choice~cargo,data=cbc.df)
xtabs(choice~carpool,data=cbc.df)
xtabs(choice~seat,data=cbc.df)
xtabs(choice~eng,data=cbc.df)
```
 o price
  30   35   40 
1486  956  558 
 - consumers mostly prefer price: 30
 
 o and so on...


```{r convert into mlogit.data }
# prepare the data (convert the data to an mlogit.data)
#install.packages("dfidx")
library(dfidx)
# add a column with unique question numbers, as needed in mlogit 1.1+
cbc.df$chid <- rep(1:(nrow(cbc.df)/3 ), each=3) #creates a new column in the data frame cbc.df called chid, which stands for "case ID" or "choice situation ID". The rep function repeats the sequence from 1 to the number of rows divided by 3, each three times. 
#This is under the assumption that each respondent has three choice tasks (or alternatives) in the dataset. It's essential for the mlogit model to identify which rows belong to the same choice set.

# shape the data for mlogit
cbc.mlogit <- dfidx(cbc.df, choice="choice", idx=list(c("chid", "resp.id"), "alt" )) #reshaping the cbc.df data frame into an indexed data frame that is suitable for mlogit analysis.
```


Mlogit model - without intercept
```{r}
# fitting a nmlogit model
#install.packages("mlogit") 
library(mlogit) 
# without intercept
m1 <- mlogit(choice ~ 0 + #choice is the dependent variable, and the predictors (independent variables) are seat, cargo, eng, and price. The 0 + part indicates that no intercept is included in the model.
               seat + 
               cargo + 
               eng + 
               price,
             data = cbc.mlogit)
summary(m1)
```
 o Frequencies of alternatives:choice
      1       2       3 
0.32700 0.33467 0.33833 
 - the relative frequency of each alternative (choice) in the dataset

 o Loglikelihood : -2581.6
 - Higher values indicate a better fit to the data, with this value typically being negative for likelihoods.
 - Dont use LogLikelihood to decide between models

 o Coefficients :
          Estimate Std. Error  z-value  Pr(>|z|)    
seat7    -0.535280   0.062360  -8.5837 < 2.2e-16 ***
seat8    -0.305840   0.061129  -5.0032 5.638e-07 ***
cargo3ft  0.477449   0.050888   9.3824 < 2.2e-16 ***
enghyb   -0.811282   0.060130 -13.4921 < 2.2e-16 ***
engelec  -1.530762   0.067456 -22.6926 < 2.2e-16 ***
price35  -0.913656   0.060601 -15.0765 < 2.2e-16 ***
price40  -1.725851   0.069631 -24.7856 < 2.2e-16 ***
 - seat7: coefficient is -0.535280, indicating a negative preference for the 7-seat option relative to the base level (implicitly 6 seats since the 6-seater is not explicitly shown).
 - seat8: coefficient is -0.305840, indicating a negative preference for the 8-seat option relative to the base level.
 - cargo3ft: The coefficient is 0.470570, indicating a positive preference for the 3ft cargo capacity relative to the base level (implicitly 2ft).
 - enghyb: The coefficient is -0.819320, indicating a negative preference for hybrid engines relative to the base level (implicitly gas engines).
 - engelec: The coefficient is -1.530762, indicating a strong negative preference for electric engines relative to the base level.
 - price35: The coefficient is -0.931566, indicating a negative preference for a $35K price relative to the base level (implicitly $30K).
 - price40: The coefficient is -1.725851, indicating a strong negative preference for a $40K price relative to the base level.

 o Slides comments:
 - Estimate lists the estimated parameter (part worth coefficient) for each level;
 - these must be interpreted relative to the base levels of each attribute (if factor)
 - Estimates that are larger in magnitude indicate stronger preferences 
 - customers strongly disliked electric engines (relative to the base level, which is gas) and 
 - disliked the $40K price (relative to the base level price of $30)
 - all parameter estimates are on the logit scale and typical range between −2 and 2



Mlogit model - With intercept
```{r}
# with intercept
m2 <- mlogit(choice ~ seat + cargo + eng + price,data = cbc.mlogit)
#choice is the dependent variable, and the predictors (independent variables) are seat, cargo, eng, and price. Unlike the previous model, 
#this one includes an intercept
summary(m2)
```
Only diff from without intercept:
 - (Intercept):2 and (Intercept):3: These are the intercepts for alternatives 2 and 3 relative to the base alternative 1. 
 - They are not statistically significant (p-values > 0.05).

 o Loglikelihood : -2581.3
 - Higher values indicate a better fit to the data, with this value typically being negative for likelihoods.
 - Dont use LogLikelihood to decide between models

m1: No intercept model (simple model)
m2: Includes intercept model
```{r}
# comparing the two models
lrtest(m1,m2)
```
  #Df  LogLik Df  Chisq Pr(>Chisq)
1   7 -2581.6                     
2   9 -2581.3  2 0.6789     0.7122

 o Pr(>Chisq): 0.7122 > 0.05
 - Model 2 is insignificant having a higher p-value than level of significance
 - rejecting the Alternative hypothesis
 - Model 2 does not significantly distinguish from Model 1 (simple model)
 - Choose the simple model 1, as the bigger and more complex model 2 does not contribute with a significantly better fit


Treat price as Numeric - mlogit model without intercept
```{r}
# treating price as continuous (instead of a factor with levels)
m3 <- mlogit(choice ~ 0 + 
               seat + 
               cargo + 
               eng + 
               as.numeric(as.character(price)),
             data=cbc.mlogit)
summary(m3)
```
 o Frequencies of alternatives:choice
      1       2       3 
0.32700 0.33467 0.33833
 - the relative frequency of each alternative (choice) in the dataset

 o Loglikelihood : -2582.1
 - Higher values indicate a better fit to the data, with this value typically being negative for likelihoods.
 - Dont use LogLikelihood to decide between models

Coefficients :
                  Estimate     Std. Error  z-value  Pr(>|z|)    
seat7              -0.5345392  0.0623518  -8.5730 < 2.2e-16 ***
seat8              -0.3061074  0.0611184  -5.0084 5.488e-07 ***
cargo3f             0.4766936  0.0508632   9.3721 < 2.2e-16 ***
enghyb             -0.8107339  0.0601149 -13.4864 < 2.2e-16 ***
engelec            -1.5291247  0.0673982 -22.6879 < 2.2e-16 ***
numeric price      -0.1733053  0.0069398 -24.9726 < 2.2e-16 ***

Interpret rest of estimates as above!

numeric price:
 - coefficient for price (-0.173505) is negative, which indicates that as the price increases, the likelihood of a customer choosing that option decreases. This is consistent with the economic theory that consumers prefer lower prices.

 o Slides comments:
 - output now shows a single parameter for price. The estimate is negative
 - indicating that people prefer lower prices to higher prices


m1: No intercept model (simple model)
m3: Numeric price model, no intercept
```{r}
# comparing the two models
lrtest(m1,m3)
```
  #Df  LogLik Df  Chisq Pr(>Chisq)
1   7 -2581.6                     
2   6 -2582.1 -1 0.9054     0.3413

 o Pr(>Chisq): 0.3413 > 0.05
 - Model 3 is insignificant having a higher p-value than level of significance
 - rejecting the Alternative hypothesis
 - Model 3 does not significantly distinguish from Model 1 (simple model)
 - Choose the simple model 1, as the bigger and more complex model 2 does not contribute with a significantly better fit


Findings with more interpretable measures like WTP
 - using Model 3
 - Finding indifference level of 
 - Cargo Capacity
```{r}
# reporting findings with more interpretable measures like WTP
coef(m3)["cargo3ft"]/(-coef(m3)["as.numeric(as.character(price))"]/1000)
```
 - $2,750.60 is the price at which customers become indifferent between the two cargo capacity options
 - This same willingness to pay value can be computed for every attribute in the study and reported to decision makers to help them understand

 - Finding indifference level of 
 - Seat quantity
```{r}
# how much customers value various features. e.g. : 
coef(m3)["seat7"]/(coef(m3)["as.numeric(as.character(price))"]/1000) # 3084.38
```
 - $3,084.38 is the price at which customers become indifferent between the quantity of seats


 - Finding indifference level of 
 - Seat quantity
```{r}
coef(m3)["engelec"]/(coef(m3)["as.numeric(as.character(price))"]/1000) # 8823.302
```
 - $8,823.302 is the price at which customers become indifferent between the thre engine options



Predict how customers would choose among new alternatives (combinations) 
 - which are not included in the original data
 - New data observations are created below
```{r}
# Finally, predict how customers would choose among those new alternatives (combinations) not included in the original data
predict.mnl<-function(model,data){
  data.model<-model.matrix(update(model$formula,0~.),data=data)[,-1]
  utility<-data.model%*%model$coef
  share<-exp(utility)/sum(exp(utility))
  cbind(share,data)
  }

# create some new data
attrib<-list(seat=c("6","7","8"),
cargo=c("2ft","3ft"),
eng=c("gas","hyb","elec"),
price=c("30","35","40"))
new.data <- expand.grid(attrib)[c(8,1,3,41,49,26),] # extract only a few combinations
new.data
```


```{r}
# pass these designs to predict.mnl() to determine what customers would choose if they had to pick among these 6 minivan alternatives
predict.mnl(m3,new.data)
```
Column share: 
 - respondents choose the 7 seat hybrid engine minivan with 2 ft of cargo space at $30K 
 - a little more than 11% of the time




##Choice Analysis 1 + 2

Choice-based conjoint analysis
For the exercises in this chapter, we use a simulated conjoint data set where we observe respondents choices from among sets of sportscars. 
The attributes of sportscars in this data are 
        number of seats
        convertible top
        transmission type 
        price
The data also includes a segment variable that indicates which sportscar segment each respondent belongs to.
```{r}
# data
sportscar <- read.csv("https://goo.gl/8g7vtT")
str(sportscar)
sportscar$segment  = as.factor(sportscar$segment)
sportscar$seat  = as.factor(sportscar$seat)
sportscar$trans  = as.factor(sportscar$trans)
sportscar$convert  = as.factor(sportscar$convert)
sportscar$price  = as.factor(sportscar$price)
# ex. 1
summary(sportscar)
```
 - ques: This represents the question number. Each respondent answered up to 10 questions.

 - alt: indicates the alternative (option) number presented to the respondent. Each respondent was given up to 3 alternatives to choose from.
 
segment: Segment of the sports car
 - Values: "basic", "fun", "racer"
 - After conversion to factor: 3 levels.

seat: This represents the seating capacity of the car, 
 - which is either 2, 4 or 5 seats.

trans: Transmission type
 - Values: "manual", "auto"
 - After conversion to factor: 2 levels.

convert: Convertible type
 - Values: "yes", "no"
 - After conversion to factor: 2 levels

eng: This categorical variable represents the type of engine: "gas", "hyb" (hybrid), or "elec" (electric). 
 - Each type has roughly 3000 instances.

price: This categorical variable represents the price of the car, 
 - with 3 distinct pricelevels: 
 - 30: 2008 instances
 - 35: 2011 instances
 - 40: 1981 instances

Choice made by the respondent
 - Integer values indicating if the alternative was chosen (1) or not (0).
 - Range: 0 to 1.


```{r}
# I simply re-order the data and for last resp_id 200, the is price = 40
xtabs(choice~trans,data=sportscar) #Creates a cross-tabulation of counts between the choice and trans variables in the sportscar data frame.
```
 o trans
auto manual 
1328    672
 - consumers mostly prefer auto transmission


Convert data to an mlogit.data
```{r}
# ex. 2
# convert the data to an mlogit.data
library(dfidx)
# add a column with unique question numbers, as needed in mlogit 1.1+
sportscar$chid <- rep(1:(nrow(sportscar)/3), each=3)
# shape the data for mlogit
sportscar.mlogit <- dfidx(sportscar, 
                          choice="choice", 
                    idx=list(c("chid", "resp_id"), "alt" ))
# fitting a nmlogit model
library(mlogit)
m1 <- mlogit(choice ~ 0 + #choice is the dependent variable, and the predictors (independent variables) are seat + convert + trans + price. The 0 + part indicates that no intercept is included in the model.
               seat + 
               convert + 
               trans + 
               price, 
             data = sportscar.mlogit)
summary(m1)
```
 o Frequencies of alternatives:choice
    1     2     3 
0.328 0.327 0.345 
 - the relative frequency of each alternative (choice) in the dataset

 o Loglikelihood : -1707.3
 - Higher values indicate a better fit to the data, with this value typically being negative for likelihoods.
 - Dont use LogLikelihood to decide between models

 o Coefficients :
             Estimate Std. Error  z-value  Pr(>|z|)    
seat4       -0.020210   0.075931  -0.2662 0.7901166    
seat5        0.425636   0.075327   5.6505   1.6e-08 ***
convertyes   0.205065   0.062134   3.3004 0.0009655 ***
transmanual -1.222004   0.066598 -18.3489 < 2.2e-16 ***
price35     -0.816068   0.071871 -11.3546 < 2.2e-16 ***
price40     -1.938337   0.088608 -21.8755 < 2.2e-16 ***

 - seat4: the effect of seat4 is not statistically significant at conventional levels. Therefore, there is no evidence to suggest that having 4 seats significantly affects the choice probability.
 
 - seat5: coefficient is 0.425636, indicating a positive preference for the 5-seat option relative to the base level seat2.
  there is strong evidence to suggest that having 5 seats significantly increases the choice probability compared to the baseline level.
  
 - convertyes: coefficient 0.425636 indicates that alternatives with no convertible option are more likely to be chosen compared to the baseline.
 
 - transmanual: negative and significant coefficient -1.154602 indicates that manual transmission significantly decreases the likelihood of an alternative being chosen

price35 and price40: Both coefficients are negative and highly significant, indicating that higher prices reduce the likelihood of an alternative being chosen. The higher the price, the less likely it is to be chosen.

 o Slides comments:
 - the ideal sportscar for the respondents based on this model
ideal car: seat5, convert_yes, trans_auto, price_30
 - Estimate lists the estimated parameter (part worth coefficient) for each level;
 - these must be interpreted relative to the base levels of each attribute (if factor)
 - Estimates that are larger in magnitude indicate stronger preferences 
 - all parameter estimates are on the logit scale and typical range between −2 and 2



Treat price as Numeric - mlogit model without intercept
```{r}
# treating price as continuous (instead of a factor with levels)
m3 <- mlogit(choice ~ 0 + 
               seat + 
               convert + 
               trans +
               as.numeric(as.character(price)), 
             data = sportscar.mlogit)
summary(m3)
```
 o Frequencies of alternatives:choice
    1     2     3 
0.328 0.327 0.345 
 - the relative frequency of each alternative (choice) in the dataset

 o Loglikelihood : -1710.1
 - Higher values indicate a better fit to the data, with this value typically being negative for likelihoods.
 - Dont use LogLikelihood to decide between models

 o Coefficients :
                  Estimate    Std. Error  z-value  Pr(>|z|)    
seat4             -0.0193861  0.0759029  -0.2554  0.798409    
seat5              0.4245449  0.0752808   5.6395 1.706e-08 ***
convertyes         0.2008115  0.0620854   3.2344  0.001219 ** 
transmanual       -1.2178833  0.0665276 -18.3064 < 2.2e-16 ***
numeric price     -0.1907023  0.0086739 -21.9859 < 2.2e-16 ***

 - seat4: the effect of seat4 is not statistically significant at conventional levels. Therefore, there is no evidence to suggest that having 4 seats significantly affects the choice probability.
 
 - seat5: coefficient is 0.4245449, indicating a positive preference for the 5-seat option relative to the base level seat2.
  there is strong evidence to suggest that having 5 seats significantly increases the choice probability compared to the baseline level.
  
 - convertyes: coefficient 0.2008115 indicates that alternatives with no convertible option are more likely to be chosen compared to the baseline.
 
 - transmanual: negative and significant coefficient -1.2178833 indicates that manual transmission significantly decreases the likelihood of an alternative being chosen

numeric price:
 - coefficient for price (-0.1907023) is negative, which indicates that as the price increases, the likelihood of a customer choosing that option decreases. This is consistent with the economic theory that consumers prefer lower prices.

 o Slides comments:
 - the ideal sportscar for the respondents based on this model
ideal car: seat5, convert_yes, trans_auto, low price
 - Estimate lists the estimated parameter (part worth coefficient) for each level;
 - these must be interpreted relative to the base levels of each attribute (if factor)
 - Estimates that are larger in magnitude indicate stronger preferences 
 - all parameter estimates are on the logit scale and typical range between −2 and 2


Findings with more interpretable measures like WTP
 - using Model 3
 - Finding indifference level of 
 - Convertible top (cabriolet)
```{r}
coef(m3)["convertyes"]/(-coef(m3)["as.numeric(as.character(price))"]/1000)
# 1053.01 is the WTP or the price the customer become indifferent between 
# convert being yes versus no; so it is not reasonable to charge 5000.
```
 - $1,053.01 is the price at which customers become indifferent between the two convertible top (cabriolet) options
 - This same willingness to pay value can be computed for every attribute in the study and reported to decision makers to help them understand



Predict how customers would choose among new alternatives (combinations) 
 - which are not included in the original data
 - New data observations are created below
```{r}
# set up a function to predict for new data
predict.mnl<-function(model,data){
  data.model<-model.matrix(update(model$formula,0~.),data=data)[,-1]
  utility<-data.model%*%model$coef
  share<-exp(utility)/sum(exp(utility))
  cbind(share,data)
}
# create some new data
newcars <- data.frame(seat=factor(c("2","4", "5")),
                      trans=factor(c("manual", "automatic", "automatic")),
                      convert=factor(c("no", "yes", "no")),
                      price=c(40, 37, 35))
newcars
```



```{r}
predict.mnl(m3,newcars)
```
Column share: 
respondents choose the 
 - 2 seat 
 - transmission manual gear
 - with n convertible top (cabriolet)
 - at price $40K 
 - a little more than 4% of the time



