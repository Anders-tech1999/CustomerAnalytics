---
title: "Causal Discovery - Production Recommendation og Targeting"
output: html_document
date: "2024-05-07"
---

# Customer Retention.R 

CUSTOMER RETENTION
Application 1: Customer Retention 
1. Building the structure manually and introducing probabilities manually 
2. Learning the structure and the probabilities from data - most common
3. Model evaluation
4. Making forward and backward inference 

##1. Building the structure and parameters manually

### Graph method

Fuse: F unctional USE fulness
 - Is in the "Cognition" part of the LHS of theoretical model

Plea: PLEA sure
 - Is in the "Affect" part of the LHS of theoretical model

Atti: ATTI tude toward VC
 - VC: Value of Virtual Communities (VC): great value to online firms
 - Is in the MIDDLE of theoretical model

Comm: Customer COMM ittment
 - Mechanism of of customer commitment formation in a Virtual Communities (VC) helps to retain the customers
 - Is in the RHS of theoretical model

```{r 1. Building structure and parameters manually }
# 1. Building the structure and parameters manually 
#install.packages("bnlearn")
library(bnlearn)
# Create an empty graph 
dag <- empty.graph(nodes = c("Fuse","Plea","Atti","Comm"))
# Add the arcs that encode the direct dependencies between variables
dag <- set.arc (dag, from = "Fuse", to = "Atti")
dag <- set.arc (dag, from = "Plea", to = "Atti")
dag <- set.arc (dag, from = "Fuse", to = "Comm")
dag <- set.arc (dag, from = "Plea", to = "Comm")
dag <- set.arc (dag, from = "Atti", to = "Comm")
# Print 
dag
```
[Fuse][Plea]
- Fuse and plea have no parent, meaning that they are independent nodes

[Atti|Fuse:Plea]
- atti is conditionally dependent on fuse and plea

[Comm|Fuse:Plea:Atti]
comm is conditionally dependent on fuse, plea and atti

Arcs:                   5 
    undirected arcs:    0 
    directed arcs:      5
 - All arcs are directed, meaning that the model has 0 unidirected arcs

Average Markov Blanket Size: 3
 - The Markov blanket of a node is the set of nodes comprising its parents, its children, and the other parents of its children. 
 - An average size of 3.00 means that, on average, each node is conditionally independent of all others given three other nodes.

Average Neighbourhood Size: 2,5
 - This indicates that each node, on average, has 2.50 neighbors (nodes directly connected to it).

Average Branching Factor: 1,25
 - This represents the average number of children per node, which is 1.25 in this network.


```{r Explore grahpical net }
# Direct dependencies are listed for each variable
modelstring(dag)
# Explore the elements of the graphical net
nodes(dag)
arcs(dag)
plot(dag)
# Optional library Rgraphviz (see instructions on Blackboard on how to install it)
library(Rgraphviz) 
graphviz.plot(dag)
```
    Finding the Markov blanket of "Atti":
Parents of Atti: Fuse and Plea (because they directly influence Atti).
Children of Atti: Comm (because Atti directly influences Comm).
Co-parents of Atti's children: Fuse and Plea (because they also influence Comm, which is a child of Atti).

So, the Markov blanket of "Atti" includes Fuse, Plea, and Comm.

## Matrix method
```{r Build net: using nodes }
# Another way to build a large network from scratch is to define the nodes and create a matrix to set the whole arc set at once:
dag2 <- empty.graph(nodes = c("Fuse","Plea","Atti","Comm"))
arcs(dag2) = matrix (c("Fuse", "Atti",
                       "Plea", "Atti",
                       "Fuse", "Comm",
                       "Plea", "Comm",
                       "Atti", "Comm"),
                     byrow  = TRUE, ncol = 2,
                     dimnames = list (NULL, c("from", "to")))
plot(dag2)
graphviz.plot (dag2)
```
This upper matrix has five rows (one for each arc) and two columns representing the 'from' and 'to' nodes, indicating the direction of the relationships. 
byrow = TRUE parameter specifies that the matrix should be filled by rows. dimnames = used to name the columns "from" and "to".
NULL is specified in dimnames, it means that no row names are being set for the matrix. The second element, c("from", "to"), provides the names for the columns of the matrix.


```{r Create model - Manual }
#  A easy way to build the DAG when we know the structure:
dag3 <- model2network("[Fuse][Plea][Atti|Fuse:Plea][Comm|Fuse:Plea:Atti]")
plot(dag3)
graphviz.plot (dag3)
```


```{r Check if DAG is equal }
# Compare dags
all.equal(dag, dag2)
all.equal(dag, dag3)
```
All models are equal as expected. 

THE MANUAL SETUP IS NOT NECESSARY FOR EXAM!

Fuse: Functional Usefullness
```{r Manual parameters Functional Usefulness }
# Introducing the parameters manually
Fuse.lv <- c ("Low", "Med", "High") 
Plea.lv <- c ("Low", "Med", "High")
Atti.lv <- c ("Low", "Med", "High")
Comm.lv <- c ("Low", "Med", "High")

Fuse.prob <- array (c(0.02, 0.26, 0.72), 
                    dim = 3, 
                    dimnames = list (Fuse = Fuse.lv))
Fuse.prob
```

THE MANUAL SETUP IS NOT NECESSARY FOR EXAM!

Plea: Pleasure
```{r Manual parameters Pleasure }
Plea.prob <- array (c(0.01, 0.55, 0.44), 
                    dim = 3, dimnames= list (Plea = Plea.lv))
Plea.prob
```

THE MANUAL SETUP IS NOT NECESSARY FOR EXAM!

```{r Manual parameters Attitude }
Atti.prob <- array (c(0.99, 0.01, 0.00,
                          0.00, 0.67, 0.33,
                          0.01, 0.99, 0.00,
                          0.34, 0.33, 0.33, 
                          0.00, 0.79, 0.21,
                          0.00, 0.40, 0.60,
                          0.99, 0.01, 0.00,
                          0.00, 0.47, 0.53,
                          0.00, 0.09, 0.91), 
                    dim = c (3, 3, 3), 
                    dimnames= list (Atti = Atti.lv, Plea = Plea.lv, Fuse = Fuse.lv))
Atti.prob
```

THE MANUAL SETUP IS NOT NECESSARY FOR EXAM!

```{r Manual parameters: Commitment }
Comm.prob <- array (c(0.00, 1.00, 0.00, 
                        0.34, 0.33, 0.33, 
                        0.34, 0.33, 0.33, 
                        0.34, 0.33, 0.33, 
                        0.00, 1.00, 0.00, 
                        1.00, 0.00, 0.00, 
                        0.34, 0.33, 0.33,
                        0.00, 1.00, 0.00, 
                        0.34, 0.33, 0.33,
                        0.34, 0.33, 0.33,
                        0.34, 0.33, 0.33,
                        0.34, 0.33, 0.33,
                        0.34, 0.33, 0.33,
                        0.00, 0.98, 0.02,
                        0.00, 0.83, 0.17,
                        0.34, 0.33, 0.33,
                        0.00, 0.33, 0.67,
                        0.00, 0.44, 0.56,
                        1.00, 0.00, 0.00,
                        0.34, 0.33, 0.33,
                        0.34, 0.33, 0.33,
                        0.34, 0.33, 0.33,
                        0.00, 0.84, 0.16,
                        0.00, 0.71, 0.29,
                        0.34, 0.33, 0.33,
                        0.00, 0.40, 0.60,
                        0.00, 0.10, 0.90), 
                 dim = c (3, 3, 3, 3), 
                 dimnames= list (Comm = Comm.lv,  Atti = Atti.lv, Plea = Plea.lv, Fuse = Fuse.lv))
Comm.prob
```


CPT Conditional Prob Table
```{r CPT-table: Conditional Prob Table }
# Relate the CPT to the labels
cpt <- list(Fuse = Fuse.prob, 
            Plea = Plea.prob,
            Atti = Atti.prob, 
            Comm = Comm.prob)

#  Relate the DAG and CPT and define a fully-specified BN
bn <- custom.fit (dag, cpt)
bn
```
The resulting Bayesian Network bn represents the combined structure of the DAG and the quantitative CPTs, allowing for probabilistic inferences based on the relationships and probabilities defined in the network.

THE MANUAL SETUP IS NOT NECESSARY FOR EXAM!

##2. Learning the structure and parameters from observational data

```{r 2. Learning structure and parameters from observational data }
library(dplyr)
library(readr)
retention <- read.csv("C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Causal Discovery - Production Recommendation og Targeting/retention.csv",header = T, colClasses = "factor")

head (retention)
glimpse(retention)

retention_test <- read.csv("C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Causal Discovery - Production Recommendation og Targeting/retention_test.csv",header = T, colClasses = "factor")
```


```{r 2. Test data }
#retention <- retention %>%
#  mutate(across(where(is.character), factor))
#head (retention)
#glimpse(retention)
sum(is.na(retention))
str(retention$Fuse)
```
 - Reminder: bn are particularly designed for categorical variables continuous variable require to be discretized.
 - However, if all variables are continuous, a Gaussian Bayes net can be built. A Gaussian Bayes net is equivalent to a path analysis model or a sem model with observable variables instead of latent constructs.


##Constrained-based algorithm
2.1 Learning a structure using a constrained-based algorithm 
 - "grow-shrink (gs)", with conditional independence test chi-squared
```{r Constrained-based algorithm NOT WORKING }
library(bnlearn)
# Constrained-based alg. do not work with missing data
par(mfrow = c(1, 1))
bn.gs <- gs(retention, alpha = 0.05, test ="x2") #alternative test ="mi"
plot(bn.gs, main = "Grow shrink_X2")
graphviz.plot (bn.gs, main = "Grow shrink_X2")
```
notice that in the constrained-based alg some links are undirected.
 - this occurs because the algorithm cannot establish the direction of "causality"

The presence of an undirected edge introduces ambiguity into the model. 
 - Without knowing the direction of influence, it is challenging to make causal inferences or predictions involving "Atti" and "Comm".
The undirected edge still indicates that "Atti" and "Comm" are not conditionally independent given the other variables in the model. There is some form of dependency, but the nature (direction) of this dependency remains unspecified.


```{r Constrained-based algorithm}
# other constraint-based algorithms have been developed
bn2 <- iamb (retention, alpha = 0.05, test ="mi")
graphviz.plot (bn2, main = "Iamb1_mi" ) 

bn3 <- fast.iamb (retention, alpha = 0.05, test ="mi")
graphviz.plot (bn3, main = "FastIamb_mi") 

bn4 <- inter.iamb (retention, alpha = 0.05, test ="mi" )
graphviz.plot (bn4, main = "InterIamb_mi") 
```
in the optimal case, all will return the same graph which is also happening here


```{r Constrained-based algorithm}
# to easily identify undirected paths 
undirected.arcs(bn.gs)
# We need to set the direction of the undirected arcs to be able to learn the parameters from observational data 
bn.gs1 <- set.arc (bn.gs, from = "Atti", to = "Comm")
#plot(bn.gs1, main = "Grow Shrink_") 
graphviz.plot(bn.gs1, main = "Grow Shrink") 
```
We have now established a direction for the edge that indicates comm is influenced by atti
 - This is done with the arrow pointing from Atti towards Comm.
 
```{r}
undirected.arcs(bn.gs1)
```
     from to
 - This means that there is no undirected paths present in the model.


##Score-based algorithm
2.2. Learning the structure using a score-based algorithm

```{r Hill-Climbing greedy search - Score-based algorithm}
# Hill-Climbing (hc) greedy search
#par(mfrow = c(1, 2))
bn.hc <- hc (retention, score = "bic")
plot (bn.hc, main = "Hill Climbing_BIC") 
graphviz.plot (bn.hc, main = "Hill Climbing_BIC")
```
The hill-climbing algorithm is a search-based method for learning the structure of a Bayesian Network. 
 - It starts with an initial network (often empty) and iteratively makes small changes (adding, deleting, or reversing edges) to the network structure to improve a given scoring criterion (in this case, BIC). 
 - The algorithm continues until no further improvements can be made. 
 - It is a greedy algorithm seeking to find a local optimum in the search space of network structures.

The fact that there is no arc between comm and atti means that this additional relationship isn´t worth adding based on the penalization of complexity for BIC


Learning the parameters 
 - learn the parameters for bn.gs1 structure (the theoretical structure) 
 ATTENTION: bn.gs1 model is being evaluated here!
```{r Score-based algorithm}
bn.mle <- bn.fit (bn.gs1, data = retention, method = "mle") #mle" stands for Maximum Likelihood Estimation, which is a statistical method for estimating the parameters of a model by maximizing the likelihood function
#bn.mle
```


Functional Usefulness
```{r Score-based algorithm}
bn.mle$Fuse
```
Conditional Probability Table (CPT) for Fuse:
 - The Conditional Probability Table CPT for Fuse lists the probabilities of Fuse being in each of its possible states. 
 - Since Fuse does not have any parents in the network, these probabilities are unconditional or marginal probabilities.

High Probability (0.7206):
 - There is a 72.06% probability that Fuse will be in the High state.
Medium Probability (0.2582):
 - There is a 25.82% probability that Fuse will be in the Med state.
Low Probability (0.0212):
 - There is a 2.12% probability that Fuse will be in the Low state.


Pleasure
```{r Score-based algorithm}
bn.mle$Plea
```
Conditional Probability Table (CPT) for Plea:
 - The Conditional Probability Table CPT for Plea lists the probabilities of Plea being in each of its possible states. 
 - Since Plea does not have any parents in the network, these probabilities are unconditional or marginal probabilities.

High Probability (0.4346):
 - There is a 43.46% probability that Plea will be in the High state.
Medium Probability (0.5560):
 - There is a 55.60% probability that Plea will be in the Med state.
Low Probability (0.0094):
 - There is a 0.94% probability that Plea will be in the Low state.


```{r Score-based algorithm}
bn.mle$Atti
```
Conditional Probability Table (CPT) for Atti
 - given different states of its parent nodes Plea and Fuse
 
WHEN Plea = High:

Fuse = High:
 - Atti = High: 0.9133
 - Atti = Med: 0.0867
 - Atti = Low: 0.0000

Fuse = Med:
 - Atti = High: 0.5868
 - Atti = Med: 0.4132
 - Atti = Low: 0.0000

Fuse = Low:
 - Atti = High: 0.0000
 - Atti = Med: 0.9778
 - Atti = Low: 0.0222
 
 And so on...


```{r Score-based algorithm}
bn.mle$Comm
```
Conditional Probability Table (CPT) for Atti
 - given different states of its parent nodes Plea, Atti and Fuse

WHEN Plea = High + Atti = High

Fuse = High:
 - Comm = High: 0.8960
 - Comm = Med: 0.1040
 - Comm = Low: 0.0000

Fuse = Med:
 - Comm = High: 0.5640
 - Comm = Med: 0.4360
 - Comm = Low: 0.0000

Fuse = Low:
 - Comm = High: 0.0000?
 - Comm = Med: 0.0000?
 - Comm = Low: 0.0000?
 
 And so on...


```{r Other useful functions: }
drop.arc(net, from="A", to=""T)
e.g. newnet = drop.arc(net, from = "T", to = "A")

#Test for the conditional independence between variables 
ci.test("T", "E", c("O", "R"), test = "x2", data = data) #EXPLORES UNCONDITIONAL RELAIONSHIPS BETWEEN VARIABLES 
mb(bn.gs1, "Atti") 
```



## 3). Model evaluation

I.Metrics of model complexity 

```{r Metrics of model complexity }
nodes(bn.mle)
arcs(bn.mle)
#bn.mle ALReady printed above
```


II. Metrics of model sensitivity
 - Test if any two nodes are d-separated 
```{r Metrics of model sensitivity}
dsep(bn.mle, x = "Plea", y = "Fuse")
dsep(bn.mle, x = "Plea", y = "Comm")
```
TRUE= d-separated
This means that "Plea" and "Fuse" are d-separated in the model, implying that 
 - they are conditionally independent given the current network structure. 
 - In other words, knowing the state of "Plea" provides no additional information about the state of "Fuse" once the states of other relevant variables in the network are known.


III. Evaluate the arc.strength()

a) with criterion ="x2" or "mi", the output reports the p-value for the test. 
 - The lower the p-value, the stronger the relationship. 
```{r III. Evaluate the arc.strength() }
library(dplyr)
options(scipen = 0)
arc.strength (bn.gs1, retention, criterion = "x2") %>%.[order(.$strength),]
```
strength: p-value
All the Arcs are significant in the network


b) with criterion ="bic" reports the change in the BIC score of the net caused by an arc removal. 
 - The more negative the change, means the BIC score will go worse if we delete that arc (i.e. the arc is important for the model).
```{r III. Evaluate the arc.strength() }
library(dplyr)
options(scipen = 0)
arc.strength (bn.gs1, retention, criterion = "bic") %>%.[order(.$strength),]
```
Output: 
Plea -> Comm    -668.21187
 - The more negative the change, the more the arc is important for the model
 - if removing Plea -> Comm, BIC will decrease with -668.211: the model gets worse
      o The Plea -> Comm arc is the most important arc in the model

Atti → Comm:    40.48931
 - The more positive the change, the more the model will gain in removing this exact arc
 - if removing Atti -> Comm, BIC will increase with 40.49 
      o The Atti -> Comm arc presence is worsening the model performance
 - Atti -> Comm is a candidate for removal


Arc-strength
 - Repeating Arc-strength analysis for the hill-climbing structure
```{r hill-climbing - arc.strength }
arc.strength (bn.hc, retention, criterion = "bic") %>%.[order(.$strength),]
```
As expected, all strengths are negative
 - this is expected as BIC was optimized when the hc algorithm has searched for this model



III. Metrics of evaluation and selection among several dags:
 - BIC, BDe, AIC scores are used to compare alternative structures and choose the best structure 
 - In bnlearn, AIC, BIC, BDE closer to zero means better model; 
 - often the three indexes do not agree.
```{r Metrics of evaluation and selection among several dags }
bnlearn::score (bn.gs1, retention, type = "aic")
bnlearn::score (bn.hc, retention, type = "aic")

bnlearn::score (bn.gs1, retention, type = "bic")
bnlearn::score (bn.hc, retention, type = "bic")

bnlearn::score (bn.gs1, retention, type = "bde")
bnlearn::score (bn.hc, retention, type = "bde")
```
AIC:
bn.gs1: -11842.95       GrowShrink structure closest to zero
bn.hc:  -11919.77

BIC
bn.gs1: -12090.61
bn.hc:  -12050.12       Hill-Climbing structure closest to zero

BDE
bn.gs1: -11904.39       GrowShrink structure closest to zero
bn.hc:  -11983.02       


IV.
IV. Metrics of predictive accuracy (error rate, confusion matrix, AUC)
k-fold cross validation 
 - This function requires as one of its parameters only structure, not the full model
 - Here I use classification error ("pred") for the node Comm (our target) as a loss function. 
```{r IV. Metrics of predictive accuracy }
library(gRain)
library(gRbase)
library (caTools)
netcv = bn.cv(retention, 
              bn.gs1, 
              loss ="pred", #use classification error ("pred") for the node Comm (our target) as a loss function.
              k = 5, 
              loss.args = list(target = "Comm"), 
              debug = TRUE)
netcv
```
Prediction accuracy of Comm based on 5-fold cross validation:
1-0.18 = 0.82 
 - in a similar way one can assess each individual variable as Atti eg.


Evaluate model performance
using a testing sample to evaluate the model performance
 - needing to transform the full model into a gRain object 
```{r IV. Metrics of predictive accuracy }
net1 =  as.grain(bn.mle)
net1
```

assuming Comm is target node, we predict the probability of Comm 
 - using net1 in the test sample
```{r Probability predictions }
predComm = predict(
  net1, 
  response = c("Comm"), 
  newdata = retention_test,
  predictors = names (retention_test)[-4],
  #target variable is the 4th column in the testing dataset
  type = "distribution") 
predComm = predComm$pred$Comm
#predComm #terrible output
CommMeanValues <- colMeans(predComm)
print(CommMeanValues)
```


Instead of probabilities of 0 or 1, one can save the actual CLASS (0/1). 
```{r Class predictions }
predComm_class = predict(
  net1, 
  response = c("Comm"),
  newdata = retention_test,
  predictors = names (retention_test)[-4], 
  #target variable is the 4th column in the testing dataset
  type = "class")
predCommClass = predComm_class$pred$Comm
#predCommclass #terrible output

counts <- table(predCommClass)
counts

# Calculate the total number of instances
total_instances <- length(predCommClass)

# Calculate the percentage of each class
percentages <- (counts / total_instances) * 100
percentages
```



Alternative method substituting gRain
```{r Alternative method substituting gRain }
#Another method if you cannot use package gRain 
bn.mle1 = bn.fit(
  model2network("[Fuse][Plea][Atti|Fuse:Plea][Comm|Fuse:Plea:Atti]"),retention)

predComm1= predict(
  bn.mle1, 
  node = "Comm",
  data = retention_test) 
predComm1

table(predCommclass, predComm1)
```

Confusion matrix
```{r Alternative method substituting gRain }
table(predComm_class$pred$Comm, retention_test$Comm)
```
        Predicted
          High  Low  Med
Actual  High  903    1  194
        Low     2   25    1
        Med   250    1 1123


ROC and AUC
 - requires the predicted probabilities, not the predicted class
```{r ROC and AUC }
library(caTools) 
colAUC(predComm, retention_test[ ,4], plotROC = TRUE) 
```
getting an AUC for every column of the prediction matrix
 - our DV has 3 categories: Low, Med and High
 - observing the model has problems when distinguishing between high and medium
 - but performs pretty well when identifying the Low category (customers who are not committed to VC)
Example:
 - High [ Low vs. Med ]: Comparing the High class against the combined Low and Med classes.



## Evidence 4) Making queries (forward and backward)
How do we use the model in practice?
Below we consider several hypothetical situations.   
 - Using BN, one can evaluate the expected changes in attitude, and respectively, commitment due to changes in functional usefulness and pleasure. 
 - setting evidence in the network for Fuse and Plea and we´ll look at the CPT Conditional Probability Table for Atti and Comm before and after setting the evidence.  
 - Setting (hard) evidence means setting one of the states of the variable at probability 1 (100%).
 
Predict without Evidence
```{r Making queries (forward and backward) }
# Transform the bn into a junction tree # options(digits=1)
library (gRain)
junction <- compile (as.grain(bn.mle))
# "querygrain" function extracts the marginal distribution of the nodes
querygrain(junction, nodes = "Atti")
querygrain(junction, nodes = "Comm")
```
Marginal Distributions:

 - The marginal distribution of "Atti" suggests that 
 - there is a higher probability of "Atti" being in the "High" state (0.595) compared to the "Med" (0.397) and "Low" (0.008) states.
 
 - The marginal distribution of "Comm" suggests that 
 - "Comm" is more likely to be in the "Med" state (0.545) compared to the "High" (0.444) and "Low" (0.011) states.
 
SUMMARY:
 - The extracted marginal distributions are useful for understanding the likely states of the nodes and 
  - can inform decision-making or further analysis within the context of the Bayesian network.


Predict with Evidence
 - Imagine a new customer joins the VC reporting a Low (or Medium or High) Functional Usefulness perception. 
  - This information can be fed to the network as evidence in order to predict the conditional probability of his/her attitude and commitment to VC. 
if Fuse = Low
```{r Predict with Evidence }
# if Fuse = Low
jLow <- setEvidence (junction, nodes = "Fuse", states = "Low")

A1 = querygrain(jLow, nodes = "Atti")
A1

C1= querygrain(jLow, nodes = "Comm")
C1
```
Atti:
    High: 0.15753333
    Low: 0.01905778
    Med: 0.82340889
 - These values represent probabilities of the node "Atti" being in the states "High", "Low", "Med" 
  - given that "Fuse" is "Low".

Comm:
    High: 0.009657778
    Low: 0.157533333
    Med: 0.832808889
 - These values represent the probabilities of the node "Comm" being in the states "High", "Low", "Med" 
  - given that "Fuse" is "Low".

if Fuse = Med
```{r Predict with Evidence }
# if Fuse = Med
jMed <- setEvidence (junction, nodes = "Fuse", states = "Med")
A2 = querygrain(jMed, nodes = "Atti")
A2
C2 = querygrain(jMed, nodes = "Comm")
C2
```
Look above for interpretation

if Fuse = High
```{r Predict with Evidence }
# if Fuse = High
    jHigh <- setEvidence (junction, nodes = "Fuse", states = "High")
    A3 = querygrain(jHigh, nodes = "Atti")
    A3
    C3 = querygrain(jHigh, nodes = "Comm")
    C3
```
Look above for interpretation


Summary (only for Atti)
```{r Predict with Evidence }
# Summary (only for Atti)
AttiHigh <- c(A1$Atti[[1]], A2$Atti[[1]], A3$Atti[[1]])
AttiLow <- c(A1$Atti[[2]], A2$Atti[[2]], A3$Atti[[2]])
AttiMed <-c(A1$Atti[[3]], A2$Atti[[3]], A3$Atti[[3]])
df1 <- data.frame(
  Fuse = c("Low", "Med", "High"), AttiLow, AttiMed, AttiHigh)
df1

matplot(rownames(df1), 
        df1, type='l', xlab='Fuse', ylab='Atti', ylim=c(0,1))
legend('topright', inset=.01, legend=colnames(df1[,2:4]), 
           pch=1, horiz=T, col=2:4)
```
As Fuse changes from Low to Medium to High, 
 - the high state of attitude shows an increasing trend, 
 - the medium state of attitude shows a decreasing trend,
 - the low state of attitude shows a constant trend. 
Notice when functional usefulness is low (left-side), 
 - the probability of attitude medium is quite high (0.80); it may suggest that
 - functional usefulness does not radically affect the customer´s attitude.


Diagnostic (backward inference)
 - Let us assume that the evidence given is that the customer’s ATTI attitude towards VC is high. 
 - This information is fed to the network by setting the probability of 
 - ATTI attitude being high and 
 - observing the changes in the parent variables (Fuse and Plea)

Without Evidence Cpt Conditional Probability Table
```{r Diagnostic (backward inference) }
# Prior ctp (conditional tables) p?
querygrain(junction, nodes = "Fuse")
querygrain(junction, nodes = "Plea")
```
With Evidence Cpt Conditional Probability Table
```{r Diagnostic (backward inference) }
# New ctp
jHigh <- setEvidence (
  junction, 
  nodes = "Atti", 
  states = "High")

querygrain(jHigh, nodes = "Fuse")
querygrain(jHigh, nodes = "Plea")
```
After we set evidence for Atti as High, 
 - the probability of the high state of Plea and Fuse is increasing, 
 - while the probability of the low and medium states of Plea and Fuse is decreasing. 
 - This implies that positive attitude towards interaction in a VC is because of person’s increased perception of pleasure and functional usefulness in the VC.
 

Setting evidence
 - Assume that the online vendor observes decreasing commitment towards participation among its customers. 
- He can set evidence to the network that the probability of commitment is low and see the effect of the parent variables (attitude, functional usefulness and pleasure).
Without Evidence Cpt
```{r Setting evidence }
# Prior ctp
querygrain(junction, nodes = "Atti")
querygrain(junction, nodes = "Fuse")
querygrain(junction, nodes = "Plea")
```

With Evidence Cpt
```{r Setting evidence }
# New ctp
CLow <- setEvidence (junction, nodes = "Comm", states = "Low")
querygrain(CLow, nodes = "Atti")
querygrain(CLow, nodes = "Fuse")
querygrain(CLow, nodes = "Plea")
```
After we set evidence for Comm as Low, 
 - the prob of Pleasure to be High is 0.00000. 
A vendor, therefore, needs to take corrective action to enhance customers’ pleasure aspect in the VC to improve customers’ commitment. 

The results infer that low commitment is mainly due to lack of enhancement of the pleasure aspect of the website. 
 - The vendors need to take corrective action to provide the customers with more fun and enjoyment. 


# Modeling contradictory behavior
Assume some customers interact in the VC to seek information from the VC, but do not participate in VC activities. 
Such customers can be considered persons with 
 - positive attitudes but 
 - low commitment.
Can BN predict the reasons behind such contradictory behavior?
Without Evidence Cpt
```{r Modeling contradictory behaviore }
# Prior ctp
querygrain(junction, nodes = "Fuse")
querygrain(junction, nodes = "Plea")
```

With Evidence Cpt
```{r Modeling contradictory behaviore }
# New ctp
AHigh <- setEvidence (junction, nodes = "Att", states = "High")
AHighCLow <- setEvidence (AHigh, nodes = "Comm", states = "Low")
querygrain(AHighCLow, nodes = "Fuse")
querygrain(AHighCLow, nodes = "Plea")
```
After we set evidence for attiude and commitment we observe that 
 - FUSE is 0.30 likely to be Low, but 
 - a significant proportion is still likely to be High (0.62) 

 - PLEA is likely to be Low (0.69) and unlikely to be High (0%) 
This reveals that customers interact primarily because of fun, and they do not perceive the VC to be sufficiently useful to them to commit to.



#TARGETED_ADS

## ELP Expected Lift in Profit

Application 2: 
Identifying populations with Positive Expected Lift in Profit (ELP) and targeting
The idea is 
 - to use BN to identify segments of customers that will most likely purchase when sending the ad (persuadable segments) and 
 - avoid sending the ad to the rest (to the ones who will not buy the advertised product ever, to the ones who will be offended by receiving an unwanted advertisement or call, or to the ones who will always buy)

If historical data is available, we start learning the relationships between the variables train and select the best model as a preliminary step. 
First we use the model structure from the text (given),and we only have to 
- learn the parameters (probabilities).
- Next, we focus exclusively on how the model is used as a decision support for marketing managers.
```{r dataload + library}
library(bnlearn)
library(Rgraphviz) 
library(readr)

#targeted.adv <- read_csv("C:/8. semester - BI/CA - Customer Analytics/Causal Discovery - Production Recommendation og Targeting/targeted.adv.csv (1).zip")
library(readr)
targeted.adv <- read.csv("C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Causal Discovery - Production Recommendation og Targeting/targeted.adv.csv",header = T, colClasses = "factor")

#head (targeted.adv)
#targeted.adv <- targeted.adv %>%
#  mutate(across(where(is.character), factor))
glimpse(targeted.adv)
```


```{r Create + Plot model}
# Build the structure
dagTA <- model2network(
  "[Income][Sex][Mailed][Buy|Income:Sex:Mailed]")
#plot(dagTA)
graphviz.plot(dagTA)
```

Maximum Likelihood Estimation (MLE) method
```{r Learn the parameters }
bnTA.mle <- bn.fit(
  dagTA, data = targeted.adv[, c(2:5)], method = "mle")
bnTA.mle
```
    example: Parameters of node Buy (multinomial distribution)
When Mailed = no and Sex = female:
 - If Income is high, the 
 - probability of Buy = no is 0.409 and 
 - probability of Buy = yes is 0.591.
 
 - If Income is low, the 
 - probability of Buy = no is 0.533 and 
 - probability of Buy = yes is 0.467.

- If Income is medium, the 
- probability of Buy = no is 0.561 and 
- probability of Buy = yes is 0.439.

  example: Parameters of node Buy (multinomial distribution)
 - node represents the income levels of individuals. 
 - Since it is not conditioned on any other variable, it has a simple probability distribution.
CPT Explanation:
 - The probabilities of the income levels are:
High: 0.321
Low: 0.359
Medium: 0.320


## ELP - Expected Lift Profit
ELP=P(Buy = Yes| Mailed = yes) * r_s  - P(Buy = Yes| Mailed = no) r_u - c, for any given population Y, where:
 
c = cost of mailing the ad to a give person
r_u = the income obtained from a sale to en unsolicited customer
r_c = the income obtained from a sale to en solicited customer

r_u and r_s are different as we may offer some discount in the ad'
unsolicited = uopfordret
```{r c + r_u + r_s }
# Asuming 
c=0.5
r_s = 8
r_u = 10
```

ELP - Medium Income + Male
a. Compute the ELP for the population consisting of individuals with medium income who are male. Should we mail an ad to this population?
```{r ELP - Medium Income + Male }
# set evidence and get the ctp 
library (gRain)
junctionTA <- compile (as.grain(bnTA.mle))
Med_male_yes <- setEvidence (junctionTA, 
                             nodes = c("Income", "Sex", "Mailed"), 
                             states = c("medium", "male", "yes"))
querygrain(Med_male_yes, nodes = "Buy")# p(buy) = 0.4

Med_male_no <- setEvidence (junctionTA, 
                            nodes = c("Income", "Sex", "Mailed"), 
                            states = c("medium", "male", "no"))
querygrain(Med_male_no, nodes = "Buy")# p(buy) = 0.2

options(digits=2)

ELP = querygrain(Med_male_yes, 
                 nodes = "Buy")$Buy[[2]] * r_s -
  querygrain(Med_male_no, nodes = "Buy")$Buy[[2]] * r_u - c
ELP
```
Since ELP is positive, we may decide to mail to this population


ELP - Medium Income + Female
b. Compute the ELP for the population consisting of individuals with 
 - medium income who are 
 -female. 
Should we mail the ad to this population?
```{r ELP - Medium Income + Female }
# Asumming 
c=0.6
r_s = 7
r_u = 9

Med_fem_yes <- setEvidence(
  junctionTA, 
  nodes = c("Income", "Sex", "Mailed"),
  states = c("medium", "female", "yes"))
querygrain(Med_fem_yes, nodes = "Buy")# p(buy) = 0.7

Med_fem_no <- setEvidence(
  junctionTA, 
  nodes = c("Income", "Sex", "Mailed"),
  states = c("medium", "female", "no"))
querygrain(Med_fem_no, nodes = "Buy")# p(buy) = 0.4

options(digits=2)
ELP = querygrain(Med_fem_yes, 
                 nodes = "Buy")$Buy[[2]] * r_s -
  querygrain(Med_fem_no, nodes = "Buy")$Buy[[2]] * r_u - c
ELP
```
Since the ELP is positive, we mail to this population


ELP - Low Income 
c. Finally, let us compute the ELP for the population consisting of individuals with low income. Should we mail an ad this population?
```{r ELP - Low Income }
Low_yes <- setEvidence (
  junctionTA, nodes = c("Income", "Mailed"),
  states = c("low", "yes"))

querygrain( Low_yes, nodes = "Buy") # 0.6

Low_no <- setEvidence(
  junctionTA, 
  nodes = c("Income", "Mailed"),
  states = c("low", "no"))

querygrain( Low_no, nodes = "Buy") # 0.5

options(digits=2)
ELP =  querygrain( Low_yes, nodes = "Buy")$Buy[[2]] * r_s -
  querygrain( Low_no, nodes = "Buy")$Buy[[2]] * r_u - c
ELP
```
Since the ELP is negative, we do not mail to this population

Discussion: 
Using BN, this application allows to identify persuadable segments of individuals who would buy only if they are sent an ad. It avoids sending ads to those who will never buy, those who always buy (thus avoid wasting the ad), and those who are turned off by the advertisement when they receive it.
The network can be extended with more nodes according to the characteristics of the population in the dataset.


# Application 2_beta (extension)

Age Marital.Status Occupation Education.Level Geographic.Location    
Online.Behavior Device.Usage Social.Media.Activity etc.
```{r Application 2_beta (extension) }
#targeted.adv.beta <- read.csv("~/Cloud/Documents/Alina Tudoran/TEACHING/Postgraduate/Customer Analytics_2024/2. BN /Lecture_Applications/Data/simulated_targeted_adv_data.csv", header = T, colClasses = "factor")
library(readr)
targeted.adv.beta <- read.csv("C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Causal Discovery - Production Recommendation og Targeting/simulated_targeted_adv_data.csv", header = T, colClasses = "factor")
head (targeted.adv.beta)
glimpse (targeted.adv.beta)
```


```{r  }
# Build the structure
nb_structure <- tree.bayes(targeted.adv.beta[, -1], "Buy")
plot(nb_structure)
```


```{r  }
# Learn the parameters
bnTA.mle <- bn.fit(
  nb_structure, data = targeted.adv.beta[, -1], method = "mle")
bnTA.mle
```
Ugly output^^^^


ELP - Married + Use desktop + Average Age
a. Compute the ELP for the population consisting of individuals with the following characteristics: 
 - Married, 
 - using desktop, 
 - average age
```{r ELP - Married + Use desktop + Average Age }
# Asumming 
c=0.5
r_s = 8
r_u = 10

library (gRain)
junctionTA <- compile (as.grain(bnTA.mle))
Query_yes <- setEvidence(
  junctionTA, 
  nodes = c("Marital.Status","Device.Usage","Age","Mailed"),
  states = c("Married","Desktop","33-54","Yes"))

querygrain(Query_yes, nodes = "Buy")

Query_no<- setEvidence(
  junctionTA, 
  nodes = c("Marital.Status","Device.Usage","Age","Mailed"),
  states = c("Married","Desktop","33-54","No"))

querygrain(Query_no, nodes = "Buy")

options(digits=2)
ELP = querygrain(Query_yes, nodes = "Buy")$Buy[[2]] * r_s -
  querygrain(Query_no, nodes = "Buy")$Buy[[2]] * r_u - c
ELP
```
Since the ELP is positive and high, we mail to this population

ELP - Single + Use desktop + Young Age
```{r ELP - Single + Use desktop + Young Age }
# Single, using desktop, young age 
Query_yes <- setEvidence(
  junctionTA, 
  nodes = c("Marital.Status","Device.Usage","Age","Mailed"),
  states = c("Single","Desktop","18-24","Yes"))

querygrain(Query_yes, nodes = "Buy")

Query_no <- setEvidence(
  junctionTA, 
  nodes = c("Marital.Status","Device.Usage","Age","Mailed"),
  states = c("Single","Desktop","18-24","No"))

querygrain(Query_no, nodes = "Buy")

options(digits=2)
ELP = querygrain(Query_yes, nodes = "Buy")$Buy[[2]] * r_s -
  querygrain(Query_no, nodes = "Buy")$Buy[[2]] * r_u - c
ELP
```
Since the ELP is negative, we do not mail to this population


ELP - Rural, Blue-Collar, with Online Behavior: Low
 - [Hypothesis: Individuals in rural areas with low engagement in online activities might also neglect advertisements, possibly due to a general disinterest in advertising or a preference for local, in-person shopping experiences]
```{r ELP - Rural, Blue-Collar, with Online Behavior: Low }
Query_yes <- setEvidence(
  junctionTA, 
  nodes = c("Geographic.Location","Occupation","Social.Media.Activity","Mailed"),
  states = c("Rural","Blue-Collar","Low","Yes"))

querygrain(Query_yes, nodes = "Buy")

Query_no <- setEvidence(
  junctionTA, 
  nodes = c("Geographic.Location","Occupation","Social.Media.Activity","Mailed"),
  states = c("Rural","Blue-Collar","Low","No"))

querygrain(Query_no, nodes = "Buy")

options(digits=2)
ELP = querygrain(Query_yes, nodes = "Buy")$Buy[[2]] * r_s -
  querygrain(Query_no, nodes = "Buy")$Buy[[2]] * r_u - c
ELP
```
ELP is positive, we may decide to mail to this population. 
As a note, the ELP is much lower than for other populations tested, so once may can make the decision also based on some minimum ELP


ELP - Married, Desktop, 45-54 years old, White-Collar, Suburban
[Hypothesis: This segment, despite being in their prime earning years and possibly having a stable financial situation, might exhibit a lower propensity to engage with direct advertisements.] 
```{r ELP - Married, Desktop, 45-54 years old, White-Collar, Suburban }
Query_yes <- setEvidence(
  junctionTA, nodes = c("Marital.Status","Device.Usage","Age","Occupation","Mailed"),
  states = c("Married","Desktop","45-54","White-Collar","Yes"))

querygrain(Query_yes, nodes = "Buy")

Query_no <- setEvidence(
  junctionTA, 
  nodes = c("Marital.Status","Device.Usage","Age","Occupation","Mailed"),
  states = c("Married","Desktop","45-54","White-Collar","No"))

querygrain(Query_no, nodes = "Buy")

options(digits=2)
ELP = querygrain(Query_yes, nodes = "Buy")$Buy[[2]] * r_s -
  querygrain(Query_no, nodes = "Buy")$Buy[[2]] * r_u - c
ELP
```
contradictory to our hypothesis, since the ELP is positive and high, 
we mail to this population



# PRODUCT_RECOMMENDATION_2024_REVISED

Main Purpose
The main purpose of this code is to develop a product recommendation system by leveraging latent class analysis and Bayesian networks. This involves identifying latent user classes that are not directly observable but inferred from the data, and then using these classes to predict user preferences for various products. The steps are divided into two main parts:

Latent Class Analysis (LCA): To identify latent classes among users based on their preferences.

Bayesian Network (BN) Construction and Inference: To build a Bayesian Network model based on the latent classes and use it to make product recommendations.

Key Takeaways

Data Preparation: The variables are defined for the latent class model.

2. Latent Class Analysis (LCA)
 - Model Testing: Several LCA models with different numbers of latent classes (ranging from 2 to 6) are tested.
 - Model Selection: The Bayesian Information Criterion (BIC) is used to select the best model, with the lowest BIC value indicating the best fit.
Output of Best Model: The best model’s details, including posterior class membership probabilities and class-conditional response probabilities, are extracted and saved.

3. Bayesian Network (BN) Construction
 - Structure Learning: A Tree-Augmented Naive Bayes (TAN) structure is learned using the latent classes as the root node.
 - Parameter Learning: Parameters of the BN are learned using  - Maximum Likelihood Estimation (MLE).
 - Visualization: The learned BN structure is visualized.

4. Inference with Bayesian Networks
 - Evidence Setting: The BN is used to make predictions based on given evidence (known user preferences).
 - Product Recommendation: The probability distribution for an unknown preference (product recommendation) is calculated given known preferences.

5. Batch Processing for Recommendations
 - Loop through Data: The code loops through each row in the dataset to predict and save the most probable product recommendations.
 - Saving Predictions: The predictions are saved to a CSV file.
Detailed Explanation of Code Sections
Data Loading:

Latent Class Analysis (LCA):

The model formula f specifies the observed variables.
The loop tests models with 2 to 6 classes, calculating and storing BIC values.
The model with the lowest BIC is chosen, and its details are printed and saved.

Bayesian Network Construction:
 - The dataset with latent class labels (data_copy) is used to construct the BN.
 - A TAN structure is learned, and parameters are fitted using MLE.
 - The BN is visualized and prepared for inference.

Inference with BN:
 - Evidence is set for known preferences, and predictions are made for unknown preferences.
 - The probability distribution for a specified node (e.g., V4) is queried.

Batch Processing:
The code loops through the dataset to set evidence and predict unknown preferences.
Predictions are stored in a DataFrame and written to a CSV file.

Conclusion
The code effectively demonstrates how to use latent class analysis combined with Bayesian networks for making product recommendations. It highlights the importance of selecting the appropriate number of latent classes and constructing a probabilistic model that can infer user preferences based on both user and item similarities. This method offers a comprehensive approach to recommendation systems by considering latent user classes and their interactions with different products.



##Application 3: Product recommendations with probabilistic models
Bayesian Nets, Course Customer Analytics

 - From option 2 in lecture 18. march
 - In this analysis, we implement a latent class analysis with BN. 
 - This classification is not directly observable; it is inferred from the data. 
 - The key premise is that membership in a particular latent class can accurately predict a user's ratings across a range of items. 
 - This method offers a comprehensive to product recommendation by considering several factors:

 o User Similarities: 
 - By analyzing patterns across users, the model identifies underlying groups of users who exhibit similar behavior in their ratings. 
 - This helps in understanding user preferences and can be 
 - used to predict how a user might rate items that they have not yet encountered, based on the behavior of similar users within the same latent class

 o Item Similarities: 
 - the model accounts for the relationships between items. 
 - recognizes that certain items are consistently rated similarly by users, suggesting that these items share appealing characteristics or cater to specific interests

 o User-Item Interactions: 
 - Beyond examining users and items in isolation, 
 - this approach delves into the interactions between users and items. 
 - explores how particular types of users tend to rate certain kinds of items, capturing the dynamic interplay between user preferences and item characteristics


```{r}
library(poLCA)      # for latent classification 
library(bnlearn)    # for building BN
library (gRain)     # for querying BN
library(Rgraphviz)  # for visualizing BN

# Data on user preferences
#data = read.csv("~/Cloud/Documents/Alina Tudoran/TEACHING/Postgraduate/Customer Analytics_2024/2. BN /Lecture_Applications/Data/Coll Filtering/CollFilforR.csv", 
                #header = T, 
                #colClasses = "factor", 
                #sep = ";")
library(readr)
CollFilforR <- read.csv("C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Causal Discovery - Production Recommendation og Targeting/CollFilforR.csv",header = T,colClasses = "factor",sep = ";")
data <- CollFilforR
```


First step
## Test several models with number of classes ranging from 2 to 6
 - Display BIC. 
 - Choose the model with the lowest BIC (AIC, G^2, X^2)
 - At this stage we only decide the number of latent classes in the data
```{r}
set.seed(234)
# Defining the variables used in the model 
f <- cbind(V1, V2, V3, V4)~1 #(~1 means without covariates)
# V1...V4 are the observed categorical variables from which the latent classes are derived 
# f <- cbind(V1, V2, V3, V4) ~ Cov1 + Cov2 (if covariates, e.g. individual characteristics)

bic_values <- numeric(length = 5) #we are testing 5 models (from 2 to 6 classes)
min_bic <- 100000
for(i in 2:6){
  lc <- poLCA(f, data, nclass=i, maxiter=3000, 
              tol=1e-5, na.rm=FALSE,  
              nrep=1, verbose=TRUE, calc.se=TRUE)
  
  bic_values[i-1] <- lc$bic  # Store the BIC value for each model
  
  if(lc$bic < min_bic){
    min_bic <- lc$bic
    LCA_best_model<-lc
  } 
}
```
Conditional item response (column) probabilities,
 by outcome variable, for each class (row) 
 
$V1
             1     2     3    4    5
class 1:  0.95 0.052 0.000 0.00 0.00
class 2:  0.24 0.080 0.075 0.18 0.43

 o Comment:
 - a person in Class 1 is 95% chance of rating Product V1 with 1 (worst of 1->5)
 - a person in Class 2 is 43% chance of rating Product V1 with 5 (best of 1->5)
 - Class 1 is primarily not satisfied with Product V1
 - Class 2 is either really satisfied or NOT satisfied with Product V1
 
$V2
             1    2     3     4    5
class 1:  0.62 0.00 0.000 0.051 0.33
class 2:  0.37 0.54 0.095 0.000 0.00

$V3
             1    2     3     4     5
class 1:  0.00 0.00 0.000 0.078 0.921
class 2:  0.44 0.44 0.028 0.000 0.085

$V4
             1    2    4    5
class 1:  0.00 0.00 0.12 0.88
class 2:  0.31 0.46 0.00 0.23

Estimated class population shares 
 0.6 0.4 
 
 o Comment:
 - the proportion of the sample belonging to each latent class.
 - 60% of the sample belongs to Class 1
 - 40% of the sample belongs to Class 2
 
Predicted class memberships (by modal posterior prob.) 
 0.61 0.39 
 
 o Comment:
 - the predicted proportion of the sample assigned to each latent class based on the highest posterior probability.
 - 61% of the predicted sample belongs to Class 1
 - 39% of the predicted sample belongs to Class 2
 
========================================================= 
Fit for 2 latent classes: 
========================================================= 
number of observations: 100 
number of fully observed cases: 68 
number of estimated parameters: 31 
residual degrees of freedom: 69 
maximum log-likelihood: -312 
 
AIC(2): 686
BIC(2): 767
G^2(2): 160 (Likelihood ratio/deviance statistic) 
X^2(2): 381 (Chi-square goodness of fit)

SUMMARY:
 - a person in Class 1 is 95% chance of rating Product V1 with 1 (worst of 1->5)
 - a person in Class 2 is 43% chance of rating Product V1 with 5 (best of 1->5)
 - Class 1 is primarily not satisfied with Product V1
 - Class 2 is either really satisfied or NOT satisfied with Product V1
 - 60% of the sample belongs to Class 1
 - 40% of the sample belongs to Class 2
 


```{r}
# bic
print(bic_values)

# plot bic
classes <- 2:6
plot(classes,
     bic_values, 
     type = "b", 
     pch = 19, xlab = "Number of Classes", ylab = "BIC",
     main = "BIC Values by Number of Classes")
```
2 Latent Classes: 767     2 having the lowest BIC score
3 Latent Classes: 814 
4 Latent Classes: 861 
5 Latent Classes: 916 
6 Latent Classes: 954


```{r}
# best selected model - full output
LCA_best_model 
# specific output
#LCA_best_model$posterior # matrix of posterior class membership probabilities
#LCA_best_model$predclass # class membership
#LCA_best_model$probs # estimated class-conditional response probabilities

# save the class
data_copy <- data
data_copy$class <- factor(LCA_best_model$predclass)
#View (data_copy)
```
The same output as above with 2,3,4,5,6 Latent Classes



Second step:
## Make product recommendations
- set up a BN classifier considering the learned class as the 'root' node and preferences as ´children' nodes
```{r}
data_wNA = na.omit(data_copy) # remove missing data from the dataset
# learn the structure (e.g., TAN structure)
dag = tree.bayes(data_wNA, "class") 
graphviz.plot(dag)
```


```{r}
# learn the parameters
bn.mle <- bn.fit (dag, data = data_wNA, method = "mle")
bn.fit.barchart(bn.mle$V1)
```
 - a person in Class 1 is 95% chance of rating Product V1 with 1 (worst of 1->5)
 - a person in Class 2 is 43% chance of rating Product V1 with 5 (best of 1->5)
 - Class 1 is primarily not satisfied with Product V1
 - Class 2 is either really satisfied or NOT satisfied with Product V1


Now we can use BN to make product recommendations 
 - e.g., given a new customer has reported the following preferences for
 - V1=5, V2=1, V3=1,
 
 o What is the estimated preference for V4?
```{r NOT WORKING }
library (gRain)
junction <- compile (as.grain(bn.mle))

      # New: Warning due to 0 probabilities tables, we use Bayesian parameter estimation
      graph.model <- as.graphNEL(dag)
      gr.model <- grain(graph.model, data =  data_wNA, smooth = 1)


# now we can use the net for inference
V1V2V3 <- setEvidence (gr.model, nodes = c("V1", "V2", "V3"), states = c("5", "1", "1")) # This can be changes into the example having 1,5,5
prediction = querygrain(V1V2V3, nodes = "V4")
str(prediction)
prediction$V4

# $V4
# V4

#.   1          2          4          5 
#0.32669680 0.52234158 0.06583710 0.08512452
# this user most likely he will score 1 or 2 => do not recommend the product V4
# his expected preference for V4 is 
preference = prediction$V4[[1]]*1 + prediction$V4[[2]]*2 + prediction$V4[[3]]*4 + prediction$V4[[4]]*5  
preference

querygrain(V1V2V3, nodes = "class") # to get the expected class
```

```{r IS WORKING}
library (gRain)
junction <- compile (as.grain(bn.mle))
# now we can use the net for inference
V1V2V3 <- setEvidence (junction, nodes = c("V1", "V2", "V3"), 
                       states = c("5", "1", "1")) 
                      #can be changed into the example having 1,5,5
prediction = querygrain(V1V2V3, nodes = "V4")
#str(prediction)
prediction$V4

# FROM NOT WORKING CODE BELOW
# $V4
# V4
#.   1          2          4          5 
#0.32669680 0.52234158 0.06583710 0.08512452 
# this user most likely he will score 1 or 2 => do not recommend the product V4
# his expected preference for V4 is
```
V4
   1    2    4    5 
0.36 0.64 0.00 0.00 

SUMMARY:
 - this user is most likely to rate Product V1 64% 2 out of 5
 - this user is most likely to rate Product V1 36% 1 out of 5
 - do NOT recommend Product V1 to this user

```{r IS WORKING}
preference = prediction$V4[[1]]*1 + prediction$V4[[2]]*2 + prediction$V4[[3]]*4 + prediction$V4[[4]]*5  
preference
```
The calculated preference is 1.6
 - This score is quite bad on a scale from 1 -> 5
 - should not recommend this Product to the customer

```{r IS WORKING}
querygrain(V1V2V3, nodes = "class") # to get the expected class
```
NONSENSE^


Make recommendation in a dataset and save them
```{r}
# Loop through each row in dataset (in this example we use our data)
data=data_copy
# Initialize predictions_df outside the loop
predictions_df <- data.frame(RowIndex = integer(), 
                             Node = character(), 
                             stringsAsFactors = FALSE)

# Loop through each row in your dataset to predict and save the most probable product to recommend
for (i in 1:nrow(data)) {
  knownPreferences <- !is.na(data[i, ])
  unknownPreferences <- is.na(data[i, ])
  
  # Ensure there is at least one known preference to set as evidence
  if(any(knownPreferences)) {
    nodes <- names(data)[knownPreferences]
    states <- as.character(data[i, knownPreferences])
    
    # Only proceed if there are nodes and states to set as evidence
    if(length(nodes) > 0 && length(states) > 0) {
      junctionWithEvidence <- setEvidence(junction, nodes = nodes, states = states)
      
      
      # Now, proceed to query the model for unknown preferences
      for (nodeToPredict in names(data)[unknownPreferences]) {
        prediction <- querygrain(junctionWithEvidence, nodes = nodeToPredict)
        predictions_df <- rbind(predictions_df, data.frame(RowIndex = i, Node = nodeToPredict, stringsAsFactors = FALSE))
      }
      }
    }
  }

View(predictions_df)
#write.csv(predictions_df, "predictions_product.csv", row.names = FALSE)
```


Save the probabilities instead of the most probable state
```{r}
# To save the probabilities instead of the most probable state
predictions_df <- data.frame(RowIndex = integer(),
                             Node = character(),
                             State = character(),
                             Probability = numeric(),
                             stringsAsFactors = FALSE)

for (i in 1:nrow(data)) {
  knownPreferences <- !is.na(data[i, ])
  unknownPreferences <- is.na(data[i, ])
  
  if(any(knownPreferences)) {
    nodes <- names(data)[knownPreferences]
    states <- as.character(data[i, knownPreferences])
    
    if(length(nodes) > 0 && length(states) > 0) {
      junctionWithEvidence <- setEvidence(junction, nodes = nodes, states = states)
      
      for (nodeToPredict in names(data)[unknownPreferences]) {
        prediction <- querygrain(junctionWithEvidence, nodes = nodeToPredict)
        
       
          # Extract probabilities and their corresponding state names
          probs <- prediction[[nodeToPredict]]  # Accessing the numeric vector of probabilities
          stateNames <- attr(probs, "dimnames")[[1]]  # Extracting state names from dimnames
          
          # Iterate through each state and its probability
          for (j in seq_along(probs)) {
            new_row <- data.frame(RowIndex = i,
                                  Node = nodeToPredict,
                                  State = stateNames[j],
                                  Probability = probs[j],
                                  stringsAsFactors = FALSE)
            predictions_df <- rbind(predictions_df, new_row)
          }
        }
        
      }
    }
  }

View(predictions_df)
#write.csv(predictions_df, "prediction_probabilities.csv", row.names = FALSE)
#testtest
```








