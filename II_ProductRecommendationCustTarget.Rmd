---
title: "II_ProductRecommendationCustTarget"
output: html_document
date: "2024-04-26"
---

#Association rules mining
## a
```{r}
#install.packages("arules")
```

```{r a }
library(arules)
rm(list=ls())

# Load the grocery data
data(Groceries)
# Have a look at the data set/container
summary(Groceries)
```


```{r a }
# Have a look at the transactions
inspect(head(Groceries,3))
```


```{r a }
# Look at the more frequent items
tail(sort(itemFrequency(Groceries)),30)
```


```{r a }
itemFrequencyPlot(Groceries,support=0.01,cex.names=1.0)
```


```{r a }
# Extract association rules
groc.rules <- apriori(Groceries, parameter=list(supp=0.01, conf=0.3,
                                                target="rules"))
```


```{r a }
# Filter the rules such that they have a lift above 3
inspect(subset(groc.rules, lift > 3))
#WHY is it above 3 and not 1?
```


## b
```{r}
#install.packages("car")
#install.packages("arulesViz")
```

```{r b }
library(arules)
rm(list=ls())

## Load, inspect, and prepare data for mining
# Load the supermarket data
retail.raw <- readLines("http://goo.gl/FfjDAO")

# Have a look at the data set/container
head(retail.raw);tail(retail.raw)
summary(retail.raw)
```


```{r b }
# Prepare for mining
retail.list <- strsplit(retail.raw, " ")
# And check the result
str(retail.list)
# Assign a name to each row/transaction
names(retail.list) <- paste("Trans", 1:length(retail.list), sep="")
# Look at a randomly chosen element
library(car)
set.seed(1234)
some(retail.list)
# Remove original data
rm(retail.raw)
# Transform the data to a transactions object
retail.trans <- as(retail.list, "transactions") # takes a few seconds
summary(retail.trans)
# Remove data in list format
rm(retail.list)

## Find and visualize association rules
# Extract association rules
retail.rules <- apriori(retail.trans, parameter=list(supp=0.001, conf=0.4))
library(arulesViz)
# Plot the resulting rules
plot(retail.rules)
# Interactive plot - select area by marking two opposite corners of a rectangle
#plot(retail.rules, engine="interactive")
# Find the subset of rules with highest lift
retail.hi <- head(sort(retail.rules, by="lift"), 50)
inspect(retail.hi)
# Plot this subset
plot(retail.hi, method="graph",engine = "htmlwidget")

## Prepare the introduction of item profitability (margin)
# First get item names
retail.itemnames <- sort(unique(unlist(as(retail.trans, "list"))))
head(retail.itemnames); tail(retail.itemnames)
# Simulate per-item margin data
set.seed(03870)
retail.margin <- data.frame(margin=rnorm(length(retail.itemnames),
                                         mean=0.30, sd=0.30))
# Inspect margin data
quantile(retail.margin$margin)
# Adjust rownames
rownames(retail.margin) <- retail.itemnames
head(retail.margin); tail(retail.margin)
some(retail.margin)
# Find the margin for the items in basket {39,48} and their sum
retail.margin[c("39", "48"), ]
sum(retail.margin[c("39", "48"), ])
# Get items in third transaction and calculate sum of their margins
(basket.items <- as(retail.trans[3], "list")[[1]])
retail.margin[basket.items, ]
sum(retail.margin[basket.items, ])
# Make a more generic function to do the calculations
retail.margsum <- function(items, itemMargins) {
  # Input: 
  #     "items" == item names, rules or transactions in arules format
  #     "itemMargins" == a data frame of profit margin indexed by name
  # Output: 
  #     look up the item margins, and return the sum
  library(arules)
  # check the class of "items" and coerce appropriately to an item list
  if (class(items) == "rules") {
    tmp.items <- as(items(items), "list") # rules ==> item list
  } else if (class(items) == "transactions") {
    tmp.items <- as(items, "list") # transactions ==> item list
  } else if (class(items) == "list") {
    tmp.items <- items # it’s already an item list!
  } else if (class(items) == "character") {
    tmp.items <- list(items) # characters ==> item list
  } else {
    stop("Don’t know how to handle margin for class ", class(items))
  }
  # make sure the items we found are all present in itemMargins
  good.items <- unlist(lapply(tmp.items, function (x)
    all(unlist(x) %in% rownames(itemMargins))))
  if (!all(good.items)) {
    warning("Some items not found in rownames of itemMargins. ",
            "Lookup failed for element(s):\n",
            which(!good.items), "\nReturning only good values.")
    tmp.items <- tmp.items[good.items]
  }
  # and add them up
  return(unlist(lapply(tmp.items, function(x) sum(itemMargins[x, ]))))
}
# Test the new function supplying the items in various formats
retail.margsum(c("39", "48"), retail.margin)
retail.margsum(list(t1=c("39", "45"), t2=c("31", "32")), retail.margin)
retail.margsum(retail.trans[101:103], retail.margin)
retail.margsum(retail.hi, retail.margin)
retail.margsum(c("hello", "world"), retail.margin) # error!
retail.margsum(list(a=c("39", "45"), b=c("hello", "world"), c=c("31", "32")),
               retail.margin) # only the first and third are OK
```

## c

```{r}
#install.packages("readxl")
#install.packages("plyr")
#install.packages("tidyverse")
#install.packages("RColorBrewer")
```

Morten are not sutre if the websute is reliable - therefore the code is modified by morten compared to the website code
```{r c }
# https://www.datacamp.com/community/tutorials/market-basket-analysis-r
library(readxl)
library(plyr)
library(tidyverse)
library(arules)
library(arulesViz)
library(RColorBrewer)
rm(list=ls())

#### READ IN THE DATA AND PREPARE IT ######
# Read excel into R dataframe.
#retail <- read_excel('Online_Retail.xlsx') first not working dataload
library(readxl)
retail <- read_excel("C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/II Product Recommendation + Customer Targeting/Online_Retail.xlsx")
# Complete.cases(data) will return a logical vector indicating which rows have
```


```{r c }
# no missing values. Then use the vector to get only rows that are complete 
# using retail[,].
retail <- retail[complete.cases(retail), ]
# Mutate function is from dplyr package. It is used to edit or add new columns 
# to dataframe. Here Description column is being converted to factor column. 
# as.factor converts column to factor column. %>% is an operator with which you 
# may pipe values to another function or expression.
retail <- retail %>% 
  mutate(Description = as.factor(Description)) %>%
  mutate(Country = as.factor(Country)) %>%
  mutate(Date=as.Date(InvoiceDate)) %>%
  mutate(TransTime = format(InvoiceDate,"%H:%M:%S")) #%>% 
#  mutate(InvoiceNo = as.numeric(as.character(InvoiceNo))) 
# Get a glimpse of your data.
glimpse(retail) 

# What you need to do is group data in the retail dataframe either by 
# CustomerID, CustomerID, and Date or you can also group data using InvoiceNo 
# and Date. We need this grouping and apply a function on it and store the 
# output in another dataframe.
# This can be done by ddply.
# The following lines of code will combine all products from one InvoiceNo and 
# date and combine all products from that InvoiceNo and date as one row, with 
# each item, separated by ','.
# ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
# The R function paste() concatenates vectors to character and separated 
# results using collapse=[any optional character string ]. Here ',' is used.
transactionData <- plyr::ddply(retail,c("InvoiceNo","Date"),
                         function(df1)paste(df1$Description,collapse = ","))
head(transactionData)
# Set column InvoiceNo of dataframe transactionData.
transactionData$InvoiceNo <- NULL 
# Set column Date of dataframe transactionData.
transactionData$Date <- NULL 
# Rename column to items.
colnames(transactionData) <- c("items") 
head(transactionData)
# TransactionData: Data to be written
# "market_basket.csv": location of file with file name to be written to.
# quote: If TRUE it will surround character or factor column with double 
# quotes. If FALSE nothing will be quoted.
# row.names: either a logical value indicating whether the row names of x are 
# to be written along with x, or a character vector of row names to be written.
write.csv(transactionData,"market_basket_transactions.csv", quote = FALSE, 
          row.names = FALSE)


#### READ IN THE DATA TO ARULES ######
# sep tell how items are separated. In this case you have separated using ','
# tr #is the result of reading the data into Arules)
tr <- read.transactions('market_basket_transactions.csv', format = 'basket', 
                        sep=',')


##### SUMMARY ######
summary(tr)


##### ITEM FREQUENCY ######
# Create an item frequency plot for the top 20 items
if (!require("RColorBrewer")) {
  # install color package of R
  #install.packages("RColorBrewer")
  #include library RColorBrewer
#  library(RColorBrewer)
}
itemFrequencyPlot(tr,topN=20,type="absolute",col=brewer.pal(8,'Pastel2'), 
                  main="Absolute Item Frequency Plot")
itemFrequencyPlot(tr,topN=20,type="relative",col=brewer.pal(8,'Pastel2'),
                  main="Relative Item Frequency Plot")


##### LOOK FOR ASSOCIATION RULES ######
# Min Support as 0.001, confidence as 0.8.
# We will maximum look at 10 items, so maximum length of a set is 10.
association.rules <- apriori(tr, 
                             parameter = list(supp=0.001, conf=0.8,maxlen=10))
summary(association.rules)
#inspect the 10 first association rules
inspect(association.rules[1:10]) 
# Limiting the number and size of rules
shorter.association.rules <- apriori(tr, 
                                     parameter = list(supp=0.001, conf=0.8,maxlen=3))
# Removing redundant rules - get subset rules in vector
subset.rules <- which(colSums(is.subset(association.rules,association.rules))>1) 
length(subset.rules)  #> 3913
# Remove subset rules.
subset.association.rules. <- association.rules[-subset.rules] 
# We can sort the rules by lift.
sortedRules <- sort(association.rules,by="lift",decreasing=TRUE)
inspect(sortedRules[1:10]) 


##### MORE SPECIFIC SEARCH OF RULES ######
# For example, to find what customers buy before buying 'METAL' run the 
# following line of code
# lhs = antecedents of metal the left hand side is the unknown
metal.association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8),
                                   appearance = list(default="lhs",rhs="METAL"))
# We get five association rules telling us what customers buy, that might lead 
# to buying metal as well.
inspect(metal.association.rules)
# Similarly, to find the answer to the question Customers who bought METAL 
# also bought.... you will keep METAL on lhs:
# rhs = consequence (decendent)
metal.association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8),
                                   appearance = list(lhs="METAL",default="rhs"))
# Decoration -> Metal and Metal -> Decoration have the same support, lift, 
# and confidence. 
inspect(head(metal.association.rules))


##### VISUALIZING ASSOCIATION RULES #####
# Filter rules with confidence greater than 0.4 or 40%.
# The plot shows that rules with high lift have low support. You can use the 
# following options for the plot.
subRules<-association.rules[quality(association.rules)$confidence>0.4]
#Plot SubRules the more red color, the higher is the lift.
plot(subRules)
# Interactive plots. The order is the number of items in the rule
plot(subRules,method="two-key plot")
# Plot the top 10 (n=10)
top10subRules <- head(subRules, n = 10, by = "confidence")
plot(top10subRules, method = "graph",  engine = "htmlwidget")
```

#25 Recommendation models (Collaborating filtering)

```{r 25}
library(recommenderlab)
library(tidyverse)


### Step 1 - storage
data(MovieLense)
help(MovieLense)
class(MovieLense)
dim(MovieLense)
# Data is given in realRatingMatrix format  ; Optimized to store sparse matrices
str(MovieLense,vec.len=2) #not as we normally reference list elements by \\$ but \\@
methods(class=class(MovieLense)) # methods applicable to this class
```


```{r 25}
### Step 2 - explore data
## Loading the metadata that gets loaded with main dataset
moviemeta <- MovieLenseMeta
class(moviemeta)
colnames(moviemeta)

## What do we know about the films?
library(pander)
pander(head(moviemeta,2),caption = "First few Rows within Movie Meta Data ")
# Look at the first few ratings of the first user
head(as(MovieLense[1,], "list")[[1]])
# Number of ratings per user
hist(rowCounts(MovieLense))
# Number of ratings per movie
hist(colCounts(MovieLense))
# Top 10 movies
movie_watched <- data.frame(
  movie_name = names(colCounts(MovieLense)),
  watched_times = colCounts(MovieLense)
)
top_ten_movies <- movie_watched[order(movie_watched$watched_times, decreasing = TRUE), ][1:10, ]
```


```{r 25}
# Plot top 10
ggplot(top_ten_movies) + aes(x=movie_name, y=watched_times) + 
  geom_bar(stat = "identity",fill = "firebrick4", color = "dodgerblue2") + xlab("Movie Tile") + ylab("Count") +
  theme(axis.text = element_text(angle = 40, hjust = 1)) 

## What do we know about the ratings
summary(getRatings(MovieLense))
# Plot the ratings
data.frame(ratings=getRatings(MovieLense)) %>%
  ggplot(aes(ratings)) + geom_bar(width=0.75)+
  labs(title='MovieLense Ratings Distribution')


### Step 3 - split in training and test
# Training and test set: At least 30 items evaluated or at least 100 users for each item
rates <- MovieLense[rowCounts(MovieLense) > 30, colCounts(MovieLense) > 100]
rates1 <- rates[rowCounts(rates) > 30,]
# We randomly define the which_train vector that is True for users in the training set and FALSE for the others.
# We will set the probability in the training set as 80%
set.seed(1234)
which_train <- sample(x = c(TRUE, FALSE), size = nrow(rates1), replace = TRUE, prob = c(0.8, 0.2))
# Define the training and the test sets
recc_data_train <- rates1[which_train, ]
recc_data_test <- rates1[!which_train, ]


### step 4 - recommendations
## Get an overview of different recommender models
recommenderRegistry$get_entries(dataType="realRatingMatrix")
recommender_models <- recommenderRegistry$get_entries(dataType="realRatingMatrix")
names(recommender_models)
lapply(recommender_models,"[[","description")
recommender_models$IBCF_realRatingMatrix$parameters

## Item-based CF
# IBCF: Item-based collaborative filtering
# Let's build the recommender IBCF - cosine:
recc_model <- Recommender(data = recc_data_train, method = "IBCF", parameter = list(k = 30)) 
# We have now created a IBCF Recommender Model
# We will define n_recommended that defines the number of items to recommend to 
# each user and with the predict function, create prediction(recommendations) for the test set.
n_recommended <- 5
recc_predicted <- predict(object = recc_model, newdata = recc_data_test, n = n_recommended)
# This is the recommendation for the first user
recc_predicted@items[[1]]
# Now let's define a list with the recommendations for each user
recc_matrix <- lapply(recc_predicted@items, function(x){
  colnames(rates)[x]
})
# Let's take a look the recommendations for the first four users:
recc_matrix[1:4]

## User-based CF
# UBCF = User-based collaborative filtering
# The method computes the similarity between users with cosine
# Let's build a recommender model leaving the parameters to their defaults. 
recc_model <- Recommender(data = recc_data_train, method = "UBCF")
# A UBCF recommender has now been created
recc_predicted <- predict(object = recc_model, newdata = recc_data_test, n = n_recommended)
# Let's define a list with the recommendations to the test set users.
recc_matrix <- sapply(recc_predicted@items, function(x) {
  colnames(rates)[x]
})
# Again, let's look at the first four users
recc_matrix[,1:4]


### step 5 - evaluation
## Evaluation of IBCF ratings
# Cross validation
# We can split the data into some chunks, take a chunk out as the test set, and evaluate the accuracy. Then we can 
# do the same with each other chunk and compute the average accuracy. Here we construct the evaluation model
n_fold <- 4 
rating_threshold <- 4 # threshold at which we consider the item to be good
items_to_keep <- 20 # given=20 means that while testing the model use only 20 randomly picked ratings from every 
# user to predict the unknown ratings in the test set the known data set has the ratings specified by given and the 
# unknown data set the remaining ratings used for validation
eval_sets <- evaluationScheme(data = rates1, method = "cross-validation", k = n_fold, 
                              given = items_to_keep, goodRating = rating_threshold)
size_sets <-sapply(eval_sets@runsTrain, length)
size_sets
#IBCF
model_to_evaluate <- "IBCF"
model_parameters <- NULL  #   we use the standard settings
eval_recommender <-Recommender(data = getData(eval_sets, "train"), method = model_to_evaluate, parameter = model_parameters)
# The IBCF can recommend new items and predict their ratings. In order to build 
# the model, we need to specify how many items we want to recommend, for example, 5.
items_to_recommend <- 5
# We can build the matrix with the predicted ratings using the predict function:
eval_prediction <- predict(object = eval_recommender, newdata = getData(eval_sets, "known"), n = items_to_recommend, type = "ratings")
# By using the calcPredictionAccuracy, we can calculate the Root mean square 
# error (RMSE), Mean squared error (MSE), and the Mean absolute error (MAE).
eval_accuracy <- calcPredictionAccuracy(
  x = eval_prediction, data = getData(eval_sets, "unknown"), byUser = TRUE
  )
# This is a small sample of the results for the Prediction and Accuracy
head(eval_accuracy)
# Now, let's take a look at the RMSE by each user
ggplot(data=as.data.frame(eval_accuracy),aes(x=RMSE)) + geom_histogram(binwidth = 0.1) +
  ggtitle("Distribution of the RMSE by user")
# However, we need to evaluate the model as a whole, so we will set the byUser to False
eval_accuracy <- calcPredictionAccuracy(
  x = eval_prediction, data = getData(eval_sets, "unknown"), byUser = FALSE
)
eval_accuracy #for IBCF

## Evaluation of IBCF top-N
# Confusion matrix good threshold =4
results <- evaluate(x = eval_sets, method = model_to_evaluate, n = seq(10, 100, 10)) #n number top-n recommendations
# results object is an evaluationResults object containing the results of the evaluation.
# Each element of the list corresponds to a different split of the k-fold.
# Let's look at the first element
head(getConfusionMatrix(results)[[1]])
# In this case, look at the first four columns
# True Positives (TP): These are recommended items that have been purchased.
# False Positives (FP): These are recommended items that haven't been purchased
# False Negatives (FN): These are not recommended items that have been purchased.
# True Negatives (TN): These are not recommended items that haven't been purchased.
# If we want to take account of all the splits at the same time, we can just sum up the indices:
columns_to_sum <- c("TP", "FP", "FN", "TN")
indices_summed <- Reduce("+", getConfusionMatrix(results))[, columns_to_sum]
head(indices_summed)

## Building an ROC curve. Will need these factors
# 1. True Positive Rate (TPR): Percentage of purchased items that have been recommended. TP/(TP + FN)
# 2. False Positive Rate (FPR): Percentage of not purchased items that have been recommended. FP/(FP + TN)
plot(results, annotate = TRUE, main = "ROC curve")

## We can also look at the accuracy metrics as well
# precision: Percentage of recommended items that have been purchased. FP/(TP + FP)
# recall: Percentage of purchased items that have been recommended. TP/(TP + FN) = True Positive Rate
plot(results, "prec/rec", annotate = TRUE, main = "Precision-Recall")

## Comparing models
models_to_evaluate <- list(IBCF_cos = list(name = "IBCF", param = list(method = "cosine")), 
                           IBCF_cor = list(name = "IBCF", param = list(method = "pearson")), 
                           UBCF_cos = list(name = "UBCF", param = list(method = "cosine")), 
                           UBCF_cor = list(name = "UBCF", param = list(method = "pearson")), 
                           random = list(name = "RANDOM", param = NULL))
# In order to evaluate the models, we need to test them, varying the number of items.
n_recommendations <- c(1,5,seq(10,100,10))
# Now let's run and evaluate the models
list_results <- evaluate(x = eval_sets, method = models_to_evaluate, n = n_recommendations)
# Plot the ROC curve
plot(list_results, annotate = 1, legend = "topleft")
title("ROC curve")
# Plot precision-recall
plot(list_results, "prec/rec", annotate = 1, legend = "bottomright", ylim = c(0,0.4))
title("Precision-recall")
```


```{r 26 }
library(recommenderlab)
library(tidyverse)

data(MovieLense)
class(MovieLense)
help(MovieLense)
dim(MovieLense)

#select only the users who have rated at least 50 movies or movies that had been rated more than 100 times
(ratings_movies <- MovieLense[rowCounts(MovieLense) > 50,
                              colCounts(MovieLense) > 100])
```


```{r 26 }
# use the minimum number of items purchased by any user to decide item number to keep
(min(rowCounts(ratings_movies)))

n_fold <- 4
items_to_keep <- 15
rating_threshold <- 3


# Use k-fold to validate models
set.seed(1234)
eval_sets <- evaluationScheme(data = ratings_movies, method = "cross-validation",k = n_fold, given = items_to_keep, 
                              goodRating = rating_threshold)


models  <- list(
 
  IBCF=list(name="IBCF",param=list(method = "cosine")),
  UBCF=list(name="UBCF", param=list(method = "pearson")),
  SVD = list(name="SVD", param=list(k = 50)),
  SVDF=list(name="SVDF", param=list(k=50))
)

# varying the number of items we want to recommend to users
n_rec <- c(1, 5, seq(10, 100, 10))

# evaluating the recommendations
results <- evaluate(x = eval_sets, method = models, n= n_rec)
```


```{r 26 }
# extract the related average confusion matrices
(avg_matrices <- lapply(results, avg))
```


```{r 26 }
plot(results, annotate=TRUE)
plot(results, "prec/rec", annotate = TRUE, main = "Precision-Recall")

recommender_ibcf <- Recommender(data = getData(eval_sets, "train"),
                                method = "IBCF",parameter = list(method = "cosine"))

recommender_ubcf <- Recommender(data = getData(eval_sets, "train"),
                                method = "UBCF",parameter = list(method = "pearson"))

recommender_svd <- Recommender(data = getData(eval_sets, "train"),
                                method = "SVD",parameter = list(k=50))

recommender_svdf <- Recommender(data = getData(eval_sets, "train"),
                               method = "SVDF",parameter = list(k=50))

items_to_recommend <- 10



eval_prediction_ibcf <- predict(object = recommender_ibcf, newdata = getData(eval_sets, "known"), n = items_to_recommend, type = "ratings")

eval_prediction_ubcf <- predict(object = recommender_ubcf, newdata = getData(eval_sets, "known"), n = items_to_recommend, type = "ratings")

eval_prediction_svd <- predict(object = recommender_svd, newdata = getData(eval_sets, "known"), n = items_to_recommend, type = "ratings")

eval_prediction_svdf <- predict(object = recommender_svdf, newdata = getData(eval_sets, "known"), n = items_to_recommend, type = "ratings")
```


```{r 26 }
# compare RMSE for different models
######################RANDOM######################

#UBCF

eval_accuracy_ubcf <- calcPredictionAccuracy(
  x = eval_prediction_ubcf, data = getData(eval_sets, "unknown"), byUser = F)

eval_accuracy_ubcf_user <- calcPredictionAccuracy(
  x = eval_prediction_ubcf, data = getData(eval_sets, "unknown"), byUser = TRUE)


head(eval_accuracy_ubcf_user)
```


```{r 26 }
#IBCF
eval_accuracy_ibcf <- calcPredictionAccuracy(
  x = eval_prediction_ibcf, data = getData(eval_sets, "unknown"), byUser = F)

eval_accuracy_ibcf_user <- calcPredictionAccuracy(
  x = eval_prediction_ibcf, data = getData(eval_sets, "unknown"), byUser = TRUE)


head(eval_accuracy_ibcf_user)
```


```{r 26 }
#SVD
eval_accuracy_svd <- calcPredictionAccuracy(
  x = eval_prediction_svd, data = getData(eval_sets, "unknown"), byUser = F)

eval_accuracy_svd_user <- calcPredictionAccuracy(
  x = eval_prediction_svd, data = getData(eval_sets, "unknown"), byUser = TRUE)


head(eval_accuracy_svd_user)
```


```{r 26 }
#SVDF
eval_accuracy_svdf <- calcPredictionAccuracy(
  x = eval_prediction_svdf, data = getData(eval_sets, "unknown"), byUser = F)

eval_accuracy_svdf_user <- calcPredictionAccuracy(
  x = eval_prediction_svdf, data = getData(eval_sets, "unknown"), byUser = TRUE)


head(eval_accuracy_svdf_user)
```


```{r 26 }
eval_accuracy_ubcf
eval_accuracy_ibcf
eval_accuracy_svd
eval_accuracy_svdf
```


