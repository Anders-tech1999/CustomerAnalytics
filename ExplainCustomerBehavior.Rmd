---
title: "Explain Customer Behavior"
output: html_document
date: "2024-05-07"
---

#FACTOR ANALYSIS (+SEM) Alina

## chapter_13-FactorAnalysis (1).R

###WORKOUT Exercise
This file contains all code examples from chapter 13 in Mehmetoglu & Mittner (2021). Applied Statistics Using R. SAGE.


```{r}
## setup
#install.packages("psych")
library(tidyverse)
#library(astatur) - NOT AVAILABLE
#theme_set(theme_astatur()) - NOT AVAILABLE
library(readr)
#workout3_1_ <- read_csv("C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Explain Customer Behavior/workout3 (1).rda")

library(readr)
workout2_imputed <- read_csv("C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Explain Customer Behavior/workout2_imputed.csv")
```


```{r}
#data
load("C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Explain Customer Behavior/workout3 (1).rda")
library(dplyr)
workout3_comp <- filter(workout3,
                        complete.cases(workout3))
```


```{r i) parallel analysis }
#determine the number of factors (see other criteria in the course)
library(psych)
paranalysis <- fa.parallel(workout3_comp, 
      fm="pa", fa="fa", SMC="TRUE")
print(paranalysis)
```
Parallel analysis suggests that the number of factors =  2
- the analysis compared the actual eigenvalues of your data to those of random data and found that 2 factors are significant.

eigen values of factorsc[1]  2.34  2.28  0.00 -0.07 -0.08 -0.12
- The first two eigenvalues (2.34 and 2.28) are greater than 1, which is another criterion often used to determine the number of factors to retain.
 - -	Eigenvalue represents the variance in all of the observed variables which is accounted for by that principal component (Slide5.2)

Scree plot
 - Evaluated from FA Actual data (blue triangle) that 2 factors are above eigenvalue 1

SUMMARY: retaining 2 factors from the data.


```{r ii) SMC Squared Multiple cCorrelations }
#(SMC are commonalities at the first iteration)
squaredmc <- smc(workout3_comp)
squaredmc
mean(squaredmc)
```
 - SMCs are the squared correlations of each variable with all other variables in the dataset. They represent the proportion of variance in each variable that can be explained by the other variables.
 - In factor analysis, SMCs are often used as initial estimates of the communality for each variable.
 - High SMC values indicate that the variables are well explained by the others, which is useful information in factor analysis. 
 - The mean SMC value gives an overall sense of how well the variables are explained on average.

Gaining Loadings and cumulative variance of factors
```{r Extract factors }
library(psych) 
fmodel1 <- fa(workout3_comp,
              nfactors = 2, #Choosing Factors with eigenvalue > 1
              fm="pa",
              rotate = "varimax")#orthogonal rotation method simplifies factor loadings to make them more interpretable.

print(fmodel1$n.obs)
print(fmodel1$loadings, digits=4, cutoff=0) 
# for better interpretation play with cutoff
```
194
 - obsersations in dataset

Loadings:
     PA1     PA2    
Var1  0.8662 -0.0287
Var2  0.9522 -0.0480
Var3  0.8689  0.0465
Var4  0.0575  0.7990
Var5  0.0093  0.9550
Var6 -0.0382  0.8943
- values represent the loadings of each variable on the two extracted factors (PA1 and PA2).
 - higher absolute values indicate stronger relationships between the variable and the factor.
 
PA1 / Factor 1
 - Variables Var1, Var2, and Var3 load highly on PA1 (0.8662, 0.9522, and 0.8689, respectively).

PA2 / Factor 2
 - Variables Var4, Var5, and Var6 load highly on PA2 (0.9040, 0.9550, and 0.8943, respectively).

Cumulative Var: 0.4028 0.7954
 - These two factors together explain approximately 79.54% of the variance in the dataset. (factor 1 explains 0.4028)

Graphical representation of the factor loading:
```{r Factor and variable relationship }
#relationship between factors and variables geometrically
fa.plot(fmodel1)
```
Factor Analysis Plot
 - each point in the plot represents one of the variables from your dataset.
 - position of the points shows how strongly each variable loads on the two factors.
 
Var1, Var2, and Var3 have high loadings on PA1 (Factor 1) and low loadings on PA2 (Factor 2)
Var4, Var5, and Var6 have high loadings on PA2 and low loadings on PA1

Communalities of each variable after the factor estimation.
 - Communalities represent the proportion of each variable's variance that can be explained by the common factors
```{r Commonalities after estimation }
#commonalities after estimation
comm <- fmodel1$communality
comm
#total variance explained
sum(comm)
# [1] 4.772239; in PCA it would be 6 (6X1)
```
Var1      Var2      Var3      Var4      Var5      Var6 
0.7511719 0.9088973 0.7572130 0.6417337 0.9120803 0.8011432
 - communalities for each variable

Var1: 0.7511719
- approximately 75.12% of the variance in Var1 is explained by the common factors.

4.772239:
 - total variance explained by the common factors (sum of communalities)


```{r Eigenvalues Communalities Uniqueness }
#diving the eigenvalues by the total variance explained
shareFactor1 = 2.34/4.77 #change from eigenvalues from above
shareFactor2 = 2.28/4.77
shareFactor1
shareFactor2

#communilities and uniquenesses
cbind(Communality=fmodel1$communality, Uniquenesses=fmodel1$uniquenesses)

```
[1] 0.490566
[1] 0.4779874
 - Factor 1 explains approximately 0.490566 of the total variance.
 - Factor 2 explains approximately 0.4779874 of the total variance.

     Communality Uniquenesses
Var1   0.7511719   0.24882811
Var2   0.9088973   0.09110270
Var3   0.7572130   0.24278697
Var4   0.6417337   0.35826630
Var5   0.9120803   0.08791973
Var6   0.8011432   0.19885679
Communalities: 
 - the proportion of each variable's variance that is explained by the common factors.
 - higher communalities indicate that the variable is well represented by the factors.
 - example, Var2 has a high communality (0.9088973), indicating that about 90.89% of its variance is explained by the factors.

Uniquenesses
 - the proportion of each variable's variance that is not explained by the common factors
 - Lower uniquenesses indicate that the variable has less unique variance and is better represented by the factors.
 - example, Var2 has a low uniqueness (0.09110270), indicating that only about 9.11% of its variance is unique and not explained by the factors.

Estimated factor scores for each observation in the dataset after performing factor analysis
```{r Estimated factor scores }
#estimated factor scores
fmodel1$scores
```
First 5 Observations in the dataset of 194 observations
              PA1          PA2
  [1,] -0.074738530 -0.796923818
  [2,]  0.610194365 -1.247087125
  [3,] -1.236137173  0.265908825
  [4,]  1.252333167 -0.861741812
  [5,] -0.691961764  0.974229599
Factor Scores:
 - the values of the latent variables (factors) for each observation in the dataset. They represent how each observation scores on the extracted factors.
 - this output, there are two factors (PA1 and PA2), and the scores for each observation on these factors are provided.
 
Positive and Negative Scores:
 - positive scores on a factor indicate that the observation has higher levels of the underlying construct measured by that factor.
 - negative scores indicate lower levels of the underlying construct.

Magnitude of Scores:
- magnitude of the scores indicates the strength of the relationship between the observation and the factor. Larger absolute values indicate a stronger relationship.

Here the analyst must group the variables based on previous Factor Extraction - Find appropriate names
 - expands upon the previous analysis by including additional reliability and correlation metrics for the factor scores
```{r Generated factor scores + Cronbach Alpha }
#generated factors scores (average of the var expressing each factor)
#HERE the analyst makes groups of the variables
itemlist <- list(relaxation=c("Var1","Var2","Var3"),
                 appearance=c("Var4","Var5","Var6"))

scoreitems <- scoreItems(itemlist, workout3_comp, 
                         min=1, max=6, totals = FALSE)
#scoreitems # - Print for standard errors alpha, Average item correlation  Guttman 6* reliability, etctectetc

scoreitems$alpha
factordata <- as.data.frame(summateds$scores)
factordata
```
Cronbach's Alpha: 
relaxation: 0.92
appearance: 0.91
 - values indicate high internal consistency for both scales.

Factor Scorres
 - factor scores for each observation in the dataset after performing factor analysis and grouping variables into two factors: relaxation and appearance.

Showing the first 3 observations
relaxation    appearance
4.000000	    2.333333			
5.000000	    2.000000			
1.666667	    4.000000

Add the 2 new constructs to the dataset
```{r adding new variables }
# add new var to the dataset
workout3_comp <- cbind(workout3_comp, factordata)
names(workout3_comp)
as.data.frame(workout3_comp)
```

#SEM ANALYSIS (+Factor Analysis) Alina

## Chapter_14-StructuralEq.R

This file contains main code from chapter 14 in Mehmetoglu & Mittner (2021). Applied Statistics Using R. SAGE.
+ more discussion 
+ moderation effects (multigroup analysis)

```{r huge package load}
# to extract data
#install.packages("devtools")
#devtools::install_github("ihrke/astatur")
```

```{r}
## setup
library(tidyverse)
library(astatur) 
library(lavaan)

# data
workout2<- astatur::workout2
glimpse(workout2)

library(readr)
workout2_imputed <- read_csv("C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Explain Customer Behavior/workout2_imputed.csv")
```
## Unuseful Measurement model - CFA Confirmatory Factor Analysis

This is the measurement model - we DO NOT USE THESE OUTPUTS AS THIS MODEL IS NOT ADEQUATE
```{r Measurement model - NOT USE!}
# read hypotheses (p. 395) and poposed model (p. 396)

## cfa
meas.lpa.mod <- '
                Attractive =~ face + sexy
                Appearance =~ body + appear + attract
                Muscle =~ muscle + strength + endur
                Weight =~ lweight + calories + cweight
                '
est.meas.lpa.mod <- cfa(meas.lpa.mod, data=workout2)
summary(est.meas.lpa.mod, fit.measures=TRUE, standardized=TRUE)
```
fit not acceptable^^^
RMSEA (modified model): 0.129
- the threshold is RMSEA < 0.1
- The measurement model is not a good fit!

Chi-Square Distribution:
 - chi-square distribution is used in many statistical tests, including those related to goodness-of-fit and modification indices in SEM.
 - the value 3.84 corresponds to the critical value for a chi-square distribution with 1 degree of freedom at the 0.05 significance level.
```{r MI Modification Indices }
modindices(est.meas.lpa.mod, minimum.value = 3.84) #From Chisquare distribution

# high MI but not mentioned in the textbook
```
MI Modification Indices:
 - In SEM, modification indices indicate the expected drop in the overall chi-square statistic if a particular fixed parameter (such as a path or a covariance) were freely estimated.
 - a high modification index suggests that freeing this parameter would significantly improve the model fit.

##Modified CFA Confirmatory Factor Analysis
```{r Modified CDF Confirmatory Factor Analysis}
## modified cfa (allowing correlations between the error variances - this is not considered good practice and it reveals the data is not good quality - but we keep to the case study for this demo)
meas.lpa.mod2 <- '
                Attractive =~ face + sexy
                Appearance =~ body + appear + attract
                Muscle =~ muscle + strength + endur
                Weight =~ lweight + calories + cweight
                muscle ~~ endur 
                lweight ~~ body'
# strength ~~ endur is not incl. to avoid negative variance

est.meas.lpa.mod2 <- cfa(meas.lpa.mod2, data=workout2)
summary(est.meas.lpa.mod2, fit.measures=TRUE, standardized=TRUE)
# acceptable fit
```
RMSEA (modified model): 0.107
- in reality the threshold is RMSEA < 0.1, but accepting this RMSEA Root Mean Square Error Approximation
- Lecture 6.4 commands the threshhold being RMSEA < 0.08???
- when having adequate level of RMSEA, the model proceeds to validity and reliability properties

     Further Metrics threshold from Lecture 6.4
RMSR Root Mean Square Residual: 0.074
 - threshold RMSR < 0.08
 - adequate measure in this case

Tucker-Lewis Index (TLI)      : 0.905
 - threshold TLI > 0.95
 - NOT adequate measure in this case

Comparative Fit Index (CFI)   : 0.938
 - threshold TLI > 0.95
 - NOT adequate measure in this case


Loadings (standardized):
- minimum accpetable level: 0.4 (look in Estimate column)
- p-values significance (all has to be > 0.05)
Latent Variables:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv
  Attractive =~                                                
    face              1.000                               0.710
    sexy              1.418    0.376    3.769    0.000    1.007
  Appearance =~                                                
    body              1.000                               1.222
    appear            1.322    0.078   16.924    0.000    1.615
    attract           1.252    0.081   15.505    0.000    1.530
  Muscle =~                                                    
    muscle            1.000                               1.505
    strength          0.530    0.093    5.673    0.000    0.798
    endur             0.510    0.076    6.737    0.000    0.768
  Weight =~                                                    
    lweight           1.000                               1.489
    calories          0.995    0.060   16.463    0.000    1.482
    cweight           0.977    0.062   15.875    0.000    1.454

Convergent and Discriminant validity
 - Construct validity: is the extent to which the measured items actually reflect the theoretical latent construct they are designed to measure
```{r Convergent + Discriminant validity}
# convergent and discriminnat analysis, and scale reliability
# loadings all high and sig.
condisc(est.meas.lpa.mod2)
relicoef(est.meas.lpa.mod2)
# all tests are in line with recommendations
```
$Average_Variance_Extracted
Attractive Appearance     Muscle     Weight 
     0.688      0.796      0.631      0.779

Convergent validity:
 - all AVEs Average Variance Extracted must be (bigger than) > 0.5
 - this is the case for all AVEs Average Variance Extracted^^^

$Squared_Factor_Correlation
           Attrct Apprnc Muscle Weight
Attractive  1.000                     
Appearance  0.063  1.000              
Muscle      0.013  0.208  1.000       
Weight      0.001  0.213  0.069  1.000

Discriminant validity:
 - the extent to which a construct is truly distinct from other constructs.
 - all AVEs Average Variance Extracted must be considerely larger than $Squared_Factor_Correlations among latent variables
 - This is the case for all correlations^^^

##Structural Part - LPA Latent Part Analysis
-	Once a satisfactory measurement model is obtained, the 2nd step is to test the structural model (stages 5-6). The structural model tests a theory and relates the constructs to other constructs
```{r Structural Model - LPA Latent Part Analysis}
# structural part
full.lpa.mod <- '
              #Measurement model (latent variables)
                Attractive =~ face + sexy
                Appearance =~ body + appear + attract
                Muscle =~ muscle + strength + endur
                Weight =~ lweight + calories + cweight
                muscle ~~ endur 
                lweight ~~ body
                Muscle ~~ 0*Weight #set covariance to 0
              #Structural model (regressions)
                Appearance ~ Attractive
                Muscle ~ Appearance
                Weight ~ Appearance
                '
est.full.lpa.mod <- sem(full.lpa.mod, data=workout2)
summary(est.full.lpa.mod, fit.measures=TRUE, standardized=TRUE)
# check fit
```
RMSEA (structural part - Latent Part Analysis): 0.104
- in reality the threshold is RMSEA < 0.1, but accepting this RMSEA Root Mean Square Error Approximation
- Lecture 6.4 commands the threshhold being RMSEA < 0.08???

Tucker-Lewis Index (TLI)      : 0.911
 - threshold TLI > 0.95 (CH14 Mehmetoglu having 0.9 as threshold???)
 - NOT adequate measure in this case

Comparative Fit Index (CFI)   : 0.937
 - threshold TLI > 0.95 (CH14 Mehmetoglu having 0.9 as threshold???)
 - NOT adequate measure in this case

SRMR                          : 0.082
 - threshold SRMR < 0.1
 - adequate measure in this case

- when having adequate level of RMSEA, Tucker-Lewis Index,  Comparative Fit Index and SRMR the model proceeds to interpretation of the Structural part LPA Latens Part Analysis estimates

Alina: Go to output Regressions: and interpret sign, significance and size of the path coefficients
 - here basically we assess our theoretical hypotheses
guidelines: 
 - 0.09 small effects
 - 0.1-0.2 medium effects
 - 0.2 and above large effects

Regressions: (standardized beta coefficients)
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv
  Appearance ~                                                 
    Attractive        0.413    0.140    2.949    0.003    0.254
  Muscle ~                                                     
    Appearance        0.575    0.086    6.689    0.000    0.466
  Weight ~                                                     
    Appearance        0.559    0.095    5.865    0.000    0.461
 - standardized coefficients range typically between +-1
 - the closer a path coeff is to +-1, the stronger the relationship (pos/neg) is
  - standardized beta coeff < 0.09 indicate small effect
  - standardized beta coeff between 0.1 - 0.2 indicate medium effect
  - standardized beta coeff > 0.2 indicate large effect
  - standardized beta coeff must be significant (pvalue < 0.01)
SUMMARY
these findings provide support for the 3 first hypothesis that
 - the more attractive -> the more desire workout improve appearance
Attractive -> Appearance

 - the more workout improve appearance -> the more desire to improve muscles
Appearance -> Muscle

 - the more workout improve appearance -> the more desire to lose weight
Appearance -> Weight

Rsquares for dependent/endogenous variable
```{r Rsquares for dependent/endogenous variable}
#get R-squares
inspect(est.full.lpa.mod, what="rsquare")
```
This plot has to be inspected in the light of relationships in the Structural Part - LPA Laten Part Analysis
Structural model (regressions)
                Appearance ~ Attractive
                Muscle ~ Appearance
                Weight ~ Appearance
- Attractive alone explains 6.5% of variance in Appearance
- Appearance alone explains 21.7% of variance in Muscle 
- Appearance alone explains 21.2% of variance in Weight 


###Indirect Effects: Structural Part - LPA Latent Part Analysis

Turning to Hypothesis 4 and 5
 - the more attractive -> the more this is indirectly effects desire  to workout improving muscles
Attractive -> Appearance -> Muscle

 - the more attractive -> the more this is indirectly effects desire  to workout losing weight
Attractive -> Appearance -> Weight

Path diagram Plot
visualizes the relationships among latent variables and observed variables in a structural equation model (SEM). 
```{r Path diagram Plot}
# plot
#install.packages("lavaanPlot")
library(lavaanPlot)
lavaanPlot(model = est.full.lpa.mod, 
           node_options = list(shape = "box", 
                               fontname = "Helvetica"), 
           edge_options = list(color = "grey"), 
           coefs = TRUE, covs=TRUE, 
           stand=TRUE, sig=.05, stars="regress")
# - summarize the findings
```
      Path diagram Elements
Nodes:
 - Latent Variables (Ovals): These represent unobserved constructs measured by multiple observed variables. Examples include Attractive, Appearance, Muscle, and Weight.
 - Observed Variables (Boxes): These represent directly measured variables. Examples include face, sexy, body, appear, attract, lweight, cweight, calories, muscle, strength, endur.

Edges (Arrows):
 - Single-headed Arrows: Indicate causal relationships or regressions. An arrow from Appearance to Attractive suggests that Appearance is predicted by Attractive.
 - Double-headed Arrows: Represent covariances or correlations between variables. For example, the double-headed arrow between muscle and endur indicates a covariance between these variables.      

Path Coefficients:
 - the numbers on the arrows, representing standardized regression weights or factor loadings - indicate the strength and direction of the relationship.
 - 0.77 between Attractive and face indicates that face is strongly and positively related to the latent variable Attractive.

Significance Levels:
 - Stars (*, **, ***, ****) indicate the significance level of the path coefficients.
*: p < 0.05
**: p < 0.01

      Interrelationships
Measurement Model:
 - Attractive is measured by face and sexy with loadings of 0.77 and 0.87 respectively.

Structural Model:
 - Appearance is predicted by Attractive with a path coefficient of 0.25**, indicating a significant relationship.
 - Muscle is predicted by Appearance with a path coefficient of 0.44****, indicating a highly significant relationship.
 - Weight is predicted by Appearance with a path coefficient of 0.47****, indicating a highly significant relationship.


Indirect Effects - Structural Model output
```{r}
# assess indirect effects and mediation 
full.lpa.mod2 <- '
              #Measurement model (latent variables)
                Attractive =~ face + sexy
                Appearance =~ body + appear + attract
                Muscle =~ muscle + strength + endur
                Weight =~ lweight + calories + cweight
                muscle ~~ endur 
                lweight ~~ body
                Muscle ~~ 0*Weight #set covariance to 0
              #Structural model (regressions)
                Appearance ~ a*Attractive
                Muscle ~ b1*Appearance
                Weight ~ b2*Appearance
              #Indirect effects
                #of Attraction on Muscle
                ind1 := a*b1 
                #of Attraction on Weight
                ind2 := a*b2 
                '
#est.full.lpa.mod2 <- sem(full.lpa.mod2, data=workout2)
#summary(est.full.lpa.mod2, standardized=TRUE)
```
Preferring the bootstrapped output below instead of the non-bootstrap

```{r}
# recheck with se="bootstrap"
est.full.lpa.mod2 <- sem(full.lpa.mod2, data=workout2, se="bootstrap")
summary(est.full.lpa.mod2, standardized=TRUE)

# assess moderating effects (moderation analysis)
# If we have two groups of customers, women and men and want to see the differences between them we can implement multigroups analysis
```
Defined Parameters:
            Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
    ind1      0.238    0.100    2.365    0.018    0.119   0.119
    ind2      0.231    0.089    2.586    0.010    0.117   0.117

    ind1 (Indirect effect 1):
Estimate: 0.238
P(>|z|): 0.018
Std.lv: 0.119
 - interpretation: The parameter ind1 is significant (p = 0.018) (actually not by the level of 99% significance), with a standardized loading of 0.119.

     ind2 (Indirect effect 2):
Estimate: 0.231
P(>|z|): 0.010
Std.lv: 0.117
 - interpretation: The parameter ind2 is significant (p = 0.010), with a standardized loading of 0.117.

Alina: Go to output Regressions: and interpret sign, significance and size of the path coefficients

Regressions: (standardized beta coefficients)
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv
  Appearance ~                                                 
    Attractiv  (a)    0.413    0.163    2.537    0.011    0.254
  Muscle ~                                                     
    Appearanc (b1)    0.575    0.092    6.275    0.000    0.466
  Weight ~                                                     
    Appearanc (b2)    0.559    0.106    5.274    0.000    0.461
 - standardized coefficients range typically between +-1
 - the closer a path coeff is to +-1, the stronger the relationship (pos/neg) is
  - standardized beta coeff < 0.09 indicate small effect
  - standardized beta coeff between 0.1 - 0.2 indicate medium effect
  - standardized beta coeff > 0.2 indicate large effect
  - standardized beta coeff must be significant (pvalue < 0.01)
SUMMARY
these findings provide support for the 2 last hypothesis that
 - the more attractive -> the more this is indirectly effects desire  to workout improving muscles
Attractive -> Appearance -> Muscle

 - the more attractive -> the more this is indirectly effects desire  to workout losing weight
Attractive -> Appearance -> Weight

The significance of the path between Attractive and Appearance is not quite significant but really close. Therefore accepting the Alternative hypothesis


###Alina selfmade: Creating men and women

for this example, Alina created a fictitious variable representing women and men in our sample
 - also I imputed the missing values 
 - upload the new data
```{r Creating men/women data}
workout2_imputed <- read_csv("C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Explain Customer Behavior/workout2_imputed.csv")
imputed_data <- workout2_imputed
```

Generate new gender variable
```{r Generate new gender variable }
# Generate random binary variable
workout2$gender <- sample(0:1, nrow(workout2), replace = TRUE)
# also as we have many missing I will impute with knn the values for this demo
#install.packages("mice")
library(mice)
imputed_data <- complete(mice(workout2, method = "pmm", m = 5))
# write.csv(imputed_data, file="workout2_imputed.csv", row.names = FALSE)
```


```{r CFA multigroup }
# cfa multigroup to assess configural invariance
est.meas.lpa.mod_configural <- cfa(meas.lpa.mod, 
                         data=imputed_data,
                         group = "gender")
summary(est.meas.lpa.mod_configural, fit.measures=TRUE, standardized=TRUE)
# check output - not excellent but we have very small sample in each group
# let us consider it acceptable.
# We save this for later:
    # Test statistic                               280.675
    # Degrees of freedom                                76
```


```{r}
# modified cfa multigroup - metric invariance (factor loadings are equal between groups)
est.meas.lpa.mod_metric <- cfa(meas.lpa.mod, 
                            data=imputed_data,
                            group = "gender",
                            group.equal = c("loadings"))
summary(est.meas.lpa.mod_metric, fit.measures=TRUE, standardized=TRUE)

# Test statistic                               288.578
# Degrees of freedom                                83
```


```{r}
# Test of difference in fit
(Chisquare_Dif = 288.578 - 280.675)
#[1] 7.903
(df_Dif=83-76)
#[1] 7
(p_value <- 1 - pchisq(7.903, 7))
# 0.341225 
# Increase in chi-square is n.s., meaning that a model imposing equal loadings
# performs equally good. Thus the loadings are not sig. different between groups
# Therefore metric invariance is fulfilled.
```
P-value: [1] 0.341225
 - therefore metric invariance is fulfilled.

SEM:
```{r}
# once configureal and metric invariance are established, we test SEM multi-group
est.full.lpa.mod_MG <- sem(full.lpa.mod, 
                           data=imputed_data, 
                           group = "gender")
summary(est.full.lpa.mod_MG)
```


```{r}
# Go to output Regressions: and evaluate the size and sig. of path coefficients
# Are they significantly different in the two groups? 
# In other words, is gender a moderator?

# Impose them to be equal and assess the modification in model fit (chi-square dif.)
est.full.lpa.mod_eqpath <- sem(full.lpa.mod, 
                           data=imputed_data, 
                           group = "gender", 
                           group.equal = c("regressions"))
summary(est.full.lpa.mod_eqpath)
```


```{r}
# Test of difference in fit
(Chisquare_Dif = 224.756 - 222.613)
#[1] 2.143
(df_Dif=79-76)
#[1] 3
(p_value <- 1 - pchisq(2.143, 3))
# 0.53
# Conclusion: the increase in chi-square is n.s., meaning the model imposing equal path
# coeficients is not signbiifcantly worse than the standard model 
# Therefore, we conclude that paths are not significantly different between groups.
# In other words, gender does not moderate the relationships between constructs.
# For both women and men the relationships between constructs are the same.
# Note: recall that we created gender. 
# This is a demo and does not mean the results correspond to reality.
```

# ApplicationEFA_CFA_SEM_Lavaan.RMD

"The relationships between Customer Perceptions and the Likelihood of Future Business"

0. Problem & objective (we use the datafile from Hair et al., Multivariate Data Analysis, Pearson)
HBAT is a manufacturer of paper products who sells products to two market segments: the newsprint industry and the magazine industry. The current market is very competitive, so the manufacturer wants to understand how its customers perceive the company and make purchasing decisions, in order to enforce customers loyalty. The manufacturer commissioned a study asking its customers to complete a questionnaire on a secure website. In total, 100 customers - purchasing managers from different firms - buying from HBAT completed the questionnaire. The data consist of three main pieces of information:

•	A 1st type of information is available from HBAT́s data warehouse and includes information on:
-	customer type in terms of length of purchase relationship (X1)
-	industry type(X2)
-	size of the customer(X3)
-	region of the customer(X4) 
-	distribution system(X5)

•	The 2nd type of information is collected based on the online questionnaire and includes consumers’ perceptions of HBAT ́s performance on 13 attributes using a continuous 0-10 (line) scale with 10 being “Excellent” and 0 being “Poor”. The 13 attributes are:
-	X6 Product quality
-	X7 E-commerce
-	X8 Technical support
-	X9 Complaint resolution
-	X10 Advertising
-	X11 Product line
-	X12 Salesforce image
-	X13 Competitive pricing
-	X14 Warranty and claims
-	X15 Packaging
-	X16 Order and billing
-	X17 Price flexibility
-	X18 Delivery speed

• The 3rd type of information relates to purchase outcomes and business relationships:
-	satisfaction with HBAT, future purchase intention etc.  (X19-X22)
-	whether the firm would consider a strategic alliance/partnership with HBAT (X23).

The dataset (HBAT.sav) consists of data for n = 100 customers. Each observation contains information on 23 variables described above. Consistent with the marketing theory, there is an underlying factor structure in the data. When designing the study, the company has clearly 4 types of factors in their mind. They expect that the customer satisfaction is determined by the following four type of perceptions: 
perceptions about the product value, 
perceptions about the marketing actions, 
perceptions about the customer service and 
perceptions about the technical support.
These factors are abstract constructs that can be measured in a survey using multi-item scales. The following items define each construct:  

- X18 Delivery Speed 
- X9 Complain resolution
- X16 Order and Billing,
to express “Customer service” 

- X11Product line
- X6 Product quality
- X13 Competing pricing,
to express “Product value”

- X12 Salesforce image
- X7 E-commerce
- X10 Advertising, 
to express “Marketing” 

- X8 Technical support 
- X14 Warranty and claims,
to express “Technical support”

1. Data uploading, etc. 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r dataload }
library(foreign)
data <- read.spss("HBAT.sav", to.data.frame=TRUE)

library(haven)
HBAT <- read_sav("HBAT.sav")
```


```{r libraries}
#install.packages("lavaan", dependencies=TRUE)
library(lavaan)
```

```{r variable summary }
variable.names(data)
VariableLabels <- unname(attr(data, "variable.labels"))
# data.label.table <- attr(sav, "label.table") # if you load it with read_sav()
summary(data)
```

##2. Check if Exploratory factor analysis (EFA) applies

```{r Linear correlationmatrix }
# Look at their the coefficient of linear correlation
cormatrix <- cor(data[, c(7:19)])
round(cormatrix, 2)
```
Observe that most of the variables have a high correlation (>0.40 as a rule-of-thumb) with at least one of the others. 
 - x15 does not have decent correlation with any of the others; the analyst may decide to delete x15. 
 - If the analyst does not discover the problem here, it will be evident a few steps later. 

Bartlett Sphericity Test. 
 - The null hypothesis is that the data dimension reduction is not possible. 
 - If p-value < 0.05, we reject the null hypothesis and apply FA. This test is sensitive to N.
```{r Bartlett Sphericity Test }
#install.packages("psych")
library(psych)
print(cortest.bartlett(cor(data[, c(7:19)]), nrow(data[, c(7:19)])))
```
$p.value: 8.81589e-150
 - is close to 0.000->: we reject the H0

Kaiser-Meyer-Oklin Test (KMO). 
 - MSA overall should be .60 or higher to proceed with factor analysis
```{r Kaiser-Meyer-Oklin Test (KMO) }
library(psych)
KMO(data[, c(7:19)])
```
x15 does not share much with the other variables. x6 does share 87% with other variables. 
 - Go primarily with overall MSA = 0.61

##3. Apply EFA Exploratory Factor Analysis with Common Factor Analysis
```{r EFA Exploratory Factor Analysis }
#install.packages("nFactors")
# Extracting as many factors as variables and check eigenvalues 
library(nFactors)
ev <- eigen(cor(data[, c(7:19)]))
ev$values
# the first 4 factors have an eigenvalue >1
plot(ev$values, type="line")   
# the screeplot suggests 3 factors
# we go for 4 factors and see later if necessary to reduce this number
```
[1] 3.567074795 2.997644547 1.738077491 1.287225051 1.005237601
 - from output, the 5 first eigenvalues exceeds 1. 
 - These 5 values pass the step and goes further into the analysis

CHANGE factors = 4 in relation to the eigenvalues
```{r EFA factanal() }
fit1 = factanal(~ x6 + x7 + x8 + x9 + x10 + x11 + x12 + x13 + x14 + x15 + x16 + x17 + x18, factors = 4, data = data, lower=0.1, rotation = "varimax") #we dont have responsevariable bevause of interdependence
# factanal() function can analyze raw data or a correlation matrix or covariance matrix; 
# factanal() applies Maximum Likelihood by default. 
print(fit1, sort=TRUE, cutoff=0.2) #Choose the cut-off!!!
```
Uniquenesses: 
x6    x7    x8    x9   x10   x11   x12   x13   x14   x15   
0.623 0.305 0.285 0.183 0.663 0.100 0.100 0.595 0.100 0.987 
x16   x17   x18 
0.358 0.100 0.100
 - has to be small, if its big, the variable doesnt share anything with the rest which it bad. 
 - R ONly prints uniqueness which is the contrary to Communality

Loadings:
- matrix only displays the useable loadings having values above the cutoff (0.2)
    Factor1 Factor2 Factor3 Factor4
x9   0.879                         
x16  0.784                         
x18  0.940                         
x6           0.609                 
x11  0.500   0.814                 
x13         -0.561   0.219         
x17  0.553  -0.750   0.204         
x7                   0.826         
x10                  0.530         
x12                  0.929         
x8                           0.838 
x14                          0.931 
x15                                

- x17        0.553  -0.750   0.204 
- We dont want x17 to explain 3 different components. The operator does not matter, as it is just negative or positive relationships.

               Factor1 Factor2 Factor3 Factor4
SS loadings      2.910   2.030   1.990   1.657
Proportion Var   0.224   0.156   0.153   0.127
Cumulative Var   0.224   0.380   0.533   0.661
 - Cum/Favtor4 means explaining 66,1% of the data by 4 factors, this can be changed in the "fit1 code by factors = 4 into factors = 5
        
Test of the hypothesis that 4 factors are sufficient.
The chi-square statistic (comparison on the actual corr matrix with the fitted matrix) is 162.89 on 32 degrees of freedom.
The p-value is 1.83e-19 

GUIDELINES FOR OUTPUT INTERPRETATION
 - To ease interpretation, very low loadings (<.1, <.2) are not displayed
According to the guidelines:
 - High loadings (>0.6 or > 0.7) are expected for the items 
 - Items with high cross-loadings should be removed 
 - communalities should be >50 to retain the item in the analysis
 - factor loaadings should be high to retain the item in the analysis
 - and eigenvalues should be >=1 for factor selected
 - cummulative variance explained >0.60
 - The chi-square test is highly sigificant (p-value is 1.83e-19) meaning poor fit. But this test is not always reliable because it is highly influenced by the sample size analyzed. 
    
Loadings
 - x11 and x17 load high simultaneusly on factor 1 and factor 2
 - This phenomenon is called  "cross-loading" - it means these items do not measure a single construct 
 - They are candidates for deletion 
      
 - x15 which does not correlate with any of the four factors
 - Does x15 represent a factor for which we do not have sufficient observable variables (measurements)?
        
Near the bottom of the output, we also see a test of the hypothesis that 4 factors are sufficient.
 - the chi-square fit statistic is very small, indicating the hypothesis of perfect model fit is rejected. 

```{r Uniqueness EFA factanal() output }
# Uniquesness for each item are 1-communality
1- apply(fit1$loadings^2,1,sum)
#fit2$uniquenesses
```
one can observe, some items like x15 have very higfh uniqueness


```{r Communalities - EFA factanal() output }
# Communalities
apply(fit1$loadings^2,1,sum)
# as one can observe, some items like x15 have very low communality
```
one can observe, some items like x15 have very low communality


Deleting x15 and x17 due to the former analysis
 - finding these variables redundant or making noise to the model
```{r Refit EFA fit2 factanal() }
# Refining EFA without x15 and x17 (x11 could also be a candidate)
fit2 = factanal(~ x6 + x7 + x8 + x9 + x10 + x11 + x12 + x13 + x14 + x16 + x18, factors = 4, data = data, lower=0.1, rotation = "varimax")
print(fit2, sort=TRUE, cutoff=0.3) #The cut-off is higher compared to previous model
```
Uniquenesses:
x6    x7    x8    x9   x10   x11   x12   x13   x14   x16   x18 
0.635 0.305 0.285 0.163 0.668 0.100 0.100 0.599 0.100 0.342 0.100 

Loadings:
    Factor1 Factor2 Factor3 Factor4
x9   0.895                         
x16  0.796                         
x18  0.918                         
x7           0.827                 
x10          0.537                 
x12          0.928                 
x8                   0.838         
x14                  0.932         
x6                           0.598 
x11  0.519                   0.786#Delete because of crossload?
x13                         -0.553

                 Factor1 Factor2 Factor3 Factor4
SS loadings      2.613   1.962   1.645   1.391
Proportion Var   0.238   0.178   0.150   0.126
Cumulative Var   0.238   0.416   0.565   0.692

Test of the hypothesis that 4 factors are sufficient.
The chi square statistic is 26.7 on 17 degrees of freedom.
The p-value is 0.0626 
 - p-value 0.0626 associated with the chi-square statistic 
 - this result is much promising. 

The analysis can still be refined by exclussing x11. 
 - some researchers make a compromise and keep x11 in the model if the scale for the corresponding item was validated previously in the literature. 

Last step: Naming the factors 
x9, x16, x18 load high on Factor 1 ; we call it Customer service
x7, x10, x12 load high on Factor 2; we call it Marketing
x8 and x14 load high on Factor 3; we call it Technical support
x6, x11, x13 load high on Factor 4;  we call it Product value

OBS. Item x13 was negatively formulated in the questionnaire. 
It should be reversed if the analysis is ussed further in the CFA and SEM.


##4. Confirmatory Factor Analyis (CFA)

Next, we set up a confirmatory factor analysis to confirm the measurement model (CFA). 
Finally, given the measurement model has been examined and validated in the CFA analysis, we set up a SEM model, to test the structural relationships between the four constructs identified and the customers´ likelihood to continue doing business with the company (X19-Satisfaction, X20-Likelihood of recommendation and X21-Likelihood of future purchase).

```{r CFA Confirmatory Factor Analyis }
CFA.model <- 'CustomerService =~ x18 + x9 + x16
             ProductValue =~ x11 + x6 + x13
             MarKeting =~ x12 + x7 + x10
             TechSupport =~ x8 + x14
# Correlations between exogeneous constructs are optional because by default, all exogenous latent variables in a CFA model are allowed to correlate
        CustomerService ~~ ProductValue
        CustomerService ~~ MarKeting
        CustomerService ~~ TechSupport
        ProductValue ~~ MarKeting
        ProductValue ~~ TechSupport
        MarKeting ~~ TechSupport'

# fit the model
fit <- cfa(CFA.model, data = data)
# display summary output
summary(fit, fit.measures=TRUE, standardized = TRUE, modindices = FALSE)
```
fit is acceptable^^^
RMSEA (modified model): 0.079
- the threshold is RMSEA < 0.1
- The measurement model is a good fit!

NOTE: we get "lavaan WARNING: some estimated ov variances are negative". 
This is called in the literature "Heywood case". Heywood cases or negative variance estimates, are a common occurrence in factor analysis and latent variable structural equation models.
There are several potential causes (https://journals.sagepub.com/doi/10.1177/0049124112442138). Here,eliminating the problematic item x11, will solve the problem.

Chi-Square Distribution:
 - chi-square distribution is used in many statistical tests, including those related to goodness-of-fit and modification indices in SEM.
 - the value 3.84 corresponds to the critical value for a chi-square distribution with 1 degree of freedom at the 0.05 significance level.
```{r MI Modification Indices }
#From Chisquare distribution
modificationindices(fit, sort = T, minimum.value = 10, op = "~~")
#The minimumvalue = 10 is really conservative and only shows the variables which impacts the model heavily.
```
MI Modification Indices:
 - In SEM, modification indices indicate the expected drop in the overall chi-square statistic if a particular fixed parameter (such as a path or a covariance) were freely estimated.
 - a high modification index suggests that freeing this parameter would significantly improve the model fit.
- MI reveals that x11 is correlated with x16 and x18; it means that x11 has substantial cross-loading on two factors (as in EFA).
 - Cross-loading goes against one of the principles of unidimensionality in SEM. 
 - delete x11 from the analysis and re-run CFA.


Modified CFA Confirmatory Factor Analysis

```{r Modified CFA post deletion}
# CFA model after deleting x11
set.seed(1234)
CFA.model <- 'CustomerService =~ x18 + x9 + x16
             ProductValue =~ x6 + x13
             MarKeting =~ x12 + x7 + x10
             TechSupport =~ x8 + x14'
# fit the model
fit <- cfa(CFA.model, data = data)
# display summary output
summary(fit, fit.measures=TRUE, standardized = TRUE, modindices = FALSE)
```
RMSEA (modified model): 0.000
- in reality the threshold is RMSEA < 0.1, but accepting this RMSEA Root Mean Square Error Approximation
- Lecture 6.4 commands the threshhold being RMSEA < 0.08
- when having adequate level of RMSEA, the model proceeds to validity and reliability properties

     Further Metrics threshold from Lecture 6.4
Tucker-Lewis Index (TLI)      : 1.035
 - threshold TLI > 0.95
 - adequate measure in this case

Comparative Fit Index (CFI)   : 1.000
 - threshold TLI > 0.95
 - adequate measure in this case

SRMR                          : 0.039
 - threshold SRMR < 0.05
 - adequate measure in this case


Loadings (standardized):
- minimum acceptable level: 0.4 (look in Estimate column)
- p-values significance (all has to be > 0.05)
Latent Variables:
                     Estimate  Std.Err  z-value  P(>|z|)
  CustomerService =~                                    
    x18                 1.000                           
    x9                  1.658    0.113   14.664    0.000
    x16                 1.107    0.098   11.294    0.000
  ProductValue =~                                       
    x6                  1.000                           
    x13                -2.197    0.962   -2.284    0.022
  MarKeting =~                                          
    x12                 1.000                           
    x7                  0.518    0.063    8.249    0.000
    x10                 0.571    0.103    5.531    0.000
  TechSupport =~                                        
    x8                  1.000                           
    x14                 0.604    0.135    4.467    0.000
 - standardized coefficients range typically between +-1
 - the closer a path coeff is to +-1, the stronger the relationship (pos/neg) is
  - standardized beta coeff < 0.09 indicate small effect
  - standardized beta coeff between 0.1 - 0.2 indicate medium effect
  - standardized beta coeff > 0.2 indicate large effect
  - standardized beta coeff must be significant (pvalue < 0.01)

SUMMARY:
 - factor 2, competitive pricing (x13) and product quality (x6) have opposite signs. 
 - It means that the product quality and competitive pricing vary together, but move in direction oposite to each other. 
 - Perceptions are more positive whether product quality increases or price decreases. This trade-off leads to naming the factor product value. 
 - When variables have different signs, we need to be careful to reverse one when creating summated scales or using further in SEM analysis. 


In case of negative path coefficient x13 is subtracted with 10, as the scale of the variable is on 10
```{r CFA rerun}
#given our variable is using a 0-10 scale , to reverse it we take:
data$x13r = 10-data$x13

# and re-run
CFA.model <- '
    # Measurement model
        CS =~ x18 + x9 + x16
        PV =~ x6 + x13r
        MK =~ x12 + x7 + x10
        TS =~ x8 + x14'
    
fit <- cfa(CFA.model, data = data)
summary(fit, fit.measures=TRUE, standardized = TRUE, modindices = FALSE)
```

Examine RELIABILITY of the factors
 - Reliability = degree of consistency between multiple measurements of a variable 
```{r CFA Reliability}
#install.packages("semTools")
library(semTools)
semTools::reliability (fit)
```
one can conclude that all factors display good reliability

alpha Cronbach
- should be > than 0.5 or 0.6

omega = similar to composite reliability index (CR) (Fornell & Larcker (1981) 
- should be > 0.7

avevar = average variance extracted (AVE) (Fornell & Larcker (1981))  - should be > than 0.5


4). Examine DISCRIMINANT VALIDITY of the factors
 - the latent variables can be thought of representing two distinct contructs.
```{r CFA Discriminant validity}
discriminantValidity(fit, merge=TRUE)
```
Discriminant validity:
 - the extent to which a construct is truly distinct from other constructs
 - The first set are factor correlation estimates and their confidence intervals.
 - Are these correlations sufficiently low to claim discriminant validity of the four constructs?
 
The "{r Convergent + Discriminant validity}" treats dicsriminant validity much better and easier


Based on Fornell & Larcker (1981), the square root of each construct´s AVE Average Vairance Explained should have a greater value than the inter-constructs correlations (or AVE > corr^2). Let us check that:
```{r CFA FornellLarcker}
reliability_out = reliability (fit)
AVEs = reliability_out[5,]
sqrtAVEs = sqrt(AVEs)
sqrtAVEs
```
Comparing the inter-constructs correlations (see "est"" column in the output of discriminantValidity(fit, merge=TRUE)) with the sqrtAVEs, conclude that the four constructss display significant discriminant validity.
 - All Fornell-Larcker values exceeds the "est" in discriminant validity table
 - There is significant discriminant validity


```{r Lavaanplot }
library(lavaanPlot)
lavaanPlot(model = fit, 
           node_options = list(shape = "box", 
                               fontname = "Helvetica"), 
           edge_options = list(color = "grey"), 
           coefs = TRUE, covs=TRUE, stand=TRUE, 
           sig=.05, stars="covs")    
```
      Path diagram Elements
Nodes:
 - Latent Variables (Ovals): These represent unobserved constructs measured by multiple observed variables. Examples include Attractive, Appearance, Muscle, and Weight.
 - Observed Variables (Boxes): These represent directly measured variables. Examples include face, sexy, body, appear, attract, lweight, cweight, calories, muscle, strength, endur.

Edges (Arrows):
 - Single-headed Arrows: Indicate causal relationships or regressions. An arrow from Appearance to Attractive suggests that Appearance is predicted by Attractive.
 - Double-headed Arrows: Represent covariances or correlations between variables. For example, the double-headed arrow between muscle and endur indicates a covariance between these variables.      

Path Coefficients:
 - the numbers on the arrows, representing standardized regression weights or factor loadings - indicate the strength and direction of the relationship.
 - 0.77 between Attractive and face indicates that face is strongly and positively related to the latent variable Attractive.

Significance Levels:
 - Stars (*, **, ***, ****) indicate the significance level of the path coefficients.
*: p < 0.05
**: p < 0.01

      Interrelationships
Measurement Model:
 - Attractive is measured by face and sexy with loadings of 0.77 and 0.87 respectively.

Structural Model:
 - Appearance is predicted by Attractive with a path coefficient of 0.25**, indicating a significant relationship.
 - Muscle is predicted by Appearance with a path coefficient of 0.44****, indicating a highly significant relationship.
 - Weight is predicted by Appearance with a path coefficient of 0.47****, indicating a highly significant relationship.


5. SEM

Dependent variable: 
 - x19-Customer Satisfaction. Build a model to explain x19;
 - NOTE: Three variables were not includeded in CFA (x11, x15, x17).
 - Reason: These variables did not load high on the main constructs
 - If they are important in theory, they can be treated as separate explanatory variables in SEM
```{r SEM} 
SEM.model1 <- '
# Measurement model
        CustomerService =~ x18 + x9 + x16
        ProductValue =~ x6 + x13r
        MarKeting =~ x12 + x7 + x10
        TechSupport =~ x8 + x14
# Structural model
        x19 ~ CustomerService + ProductValue + MarKeting + TechSupport'
# fit the model
fitSEM1 <- sem(SEM.model1, data=data, se ="robust", estimator = "ML") 
summary(fitSEM1, fit.measures=TRUE, standardized = TRUE, rsquare=TRUE)
```
The message "lavaan WARNING: some estimated ov variances are negative" shows up. 
 - In this case, the problematic items are x12 and x14. It reflects that we would need more items per construct to run a good model. 
 - We set se="robust" to produce robust standard errors; 
 - setting se="boot" or se="bootstrap" will produce bootstrap standard errors. 
 - Check the fit indexes for SEM model as done in CFA 
 - fitmeasures(fit) # alternative summary
 
Structural coefficients:
Regressions:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv
  x19 ~                                                        
    CustomerServic    0.787    0.116    6.758    0.000    0.534
    ProductValue      0.663    0.110    6.022    0.000    0.746
    MarKeting         0.518    0.078    6.671    0.000    0.595
    TechSupport      -0.039    0.045   -0.870    0.384   -0.042
SUMMARY: 
 - Customers perceptions about CustomerServic, ProductValue and MarKeting are positively and significantly correlated with satisfaction. 
 - TechSupport perceptions is not significantly related to customer satisfaction. pvalue:0.384

```{r SEM modification indices } 
# check modification indices if relevant
summary(fitSEM1, fit.measures=TRUE, standardized = TRUE, rsquare=TRUE, modindices=TRUE)
modificationindices(fitSEM1, sort = T, minimum.value = 10, op = "~~")
# no suggestion for improvement
```
MI Modification Indices:
 - In SEM, modification indices indicate the expected drop in the overall chi-square statistic if a particular fixed parameter (such as a path or a covariance) were freely estimated.
 - a high modification index suggests that freeing this parameter would significantly improve the model fit.
- The table is empty, whereas there is no variables which could create impactful model improvement by bveing deleted from the Structural model


```{r IF bootstrap is asked}
# The bootstrap model parameters are available with:
# PAR.boot <- bootstrapLavaan(fitSEM1, R=10, type="ordinary",FUN="coef")
# T.boot <- bootstrapLavaan(fitSEM1, R=10, type="bollen.stine",FUN=fitMeasures, fit.measures="chisq")
```

```{r Lavaan plot}
#### Plotting the model
library(lavaanPlot)
labels <- list(x19 = "SATISFACTION")
lavaanPlot(model = fitSEM1, 
           node_options = list(shape = "box", 
                               fontname = "Helvetica"), 
           edge_options = list(color = "grey"), 
           coefs = TRUE, covs=TRUE, stand=TRUE, 
           sig=.05, stars="regress", labels = labels)
```
      Path diagram Elements
Nodes:
 - Latent Variables (Ovals): These represent unobserved constructs measured by multiple observed variables. Examples include Attractive, Appearance, Muscle, and Weight.
 - Observed Variables (Boxes): These represent directly measured variables. Examples include face, sexy, body, appear, attract, lweight, cweight, calories, muscle, strength, endur.

Edges (Arrows):
 - Single-headed Arrows: Indicate causal relationships or regressions. An arrow from Appearance to Attractive suggests that Appearance is predicted by Attractive.
 - Double-headed Arrows: Represent covariances or correlations between variables. For example, the double-headed arrow between muscle and endur indicates a covariance between these variables.      

Path Coefficients:
 - the numbers on the arrows, representing standardized regression weights or factor loadings - indicate the strength and direction of the relationship.
 - 0.77 between Attractive and face indicates that face is strongly and positively related to the latent variable Attractive.

Significance Levels:
 - Stars (*, **, ***, ****) indicate the significance level of the path coefficients.
*: p < 0.05
**: p < 0.01

      Interrelationships
Measurement Model:
 - Attractive is measured by face and sexy with loadings of 0.77 and 0.87 respectively.

Structural Model:
 - Appearance is predicted by Attractive with a path coefficient of 0.25**, indicating a significant relationship.
 - Muscle is predicted by Appearance with a path coefficient of 0.44****, indicating a highly significant relationship.
 - Weight is predicted by Appearance with a path coefficient of 0.47****, indicating a highly significant relationship.

```{r}
#or
library(semPlot)
semPaths(fitSEM1, "std", intercepts = FALSE, style="lisrel", layout="tree2")
```


 6. extended SEM model - Mediating effects
 - RUN THROUGH QUICKLY...
 
SEM involving a mediating effect and correcting the model. Consistent with the theory, Sem.model2 proposed x19 (Satisfaction) as mediator between the four latent constructs and Likelihood of future purchase (x21)
```{r extended SEM }
SEM.model2 <- '
# Measurement model
             CS =~ x18 + x9 + x16
             PV =~ x6 + x13r
             MK =~ x7 + x10
             TS =~ x8
# Structural model
             x19 ~ CS + PV + MK + TS
             x21 ~ x19'
# fit the model
fitSEM2 <- sem(SEM.model2, data=data, se="robust") 
summary(fitSEM2, fit.measures=TRUE)
```


```{r extended SEM 2fit}
summary(fitSEM2, fit.measures=TRUE, standardized = TRUE, rsquare=TRUE, modindices=TRUE)
modificationindices(fitSEM2, sort = T, minimum.value = 10, op = "~~")
# model has a good fit
```



```{r Lavaan plot }
# plot
library(lavaanPlot)
labels <- list(x19 = "SATISFACTION", 
               x21 = "FUTURE PURCHASE")
lavaanPlot(model = fitSEM2, 
           node_options = list(shape = "box", 
                               fontname = "Helvetica"), 
           edge_options = list(color = "grey"), 
           coefs = TRUE, covs=TRUE, stand=TRUE, 
           sig=.05, stars="regress", labels = labels)

 # - summarizing the findings 
 # - are the all structural paths in the sem model significant? 
 # - which is the most important determinant of customer satisfaction? (check std. path coefficients and conclude)
 # - does satisfaction act as a sigificant mediator? (check the sig. of mediating patterns and conclude)
 # - how much variance in x21 (Likelihood of future purchase) the model explains? (check R^2 associated)
```


#PLS SEM (Morten)

## 8.PLS_Ia_solution_estimation_exercise: PLS_SEM Intro

```{r dataload satisfaction }
rm(list=ls())
#install.packages("seminr")
library(seminr)
# Load data
#satisfaction <- read.csv(file = "satisfaction.csv", header = TRUE, sep = " ") #Morten's dataload
satisfaction <- read.csv(file = "C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Explain Customer Behavior/PLS Morten/satisfaction.csv", header = TRUE, sep = " ")
```

```{r Original model: measurement/structural/estimate model }
## Original model
# Specifying the measurement model 
simple_mm <- constructs(
  composite("IMAG", multi_items("imag", 1:5), weights = mode_B),
  composite("EXPE", c("expe1", "expe2", "expe3", "expe4", "expe5"), weights = mode_A), #Alternative
  composite("QUAL", multi_items("qual", 1:5), weights = mode_A),
  composite("VAL", multi_items("val", 1:4), weights = mode_A),
  composite("SAT", multi_items("sat", 1:4), weights = mode_A),
  composite("LOY", multi_items("loy", 1:4), weights = mode_A))
# Specifying the structural model
simple_sm <- relationships(
  paths(from = c("IMAG"), to = c("EXPE", "SAT", "LOY")),
  paths(from = c("EXPE"), to = c("QUAL","VAL","SAT")),
  paths(from = c("QUAL"), to = c("VAL", "SAT")),
  paths(from = c("VAL"), to = c("SAT")),
  paths(from = c("SAT"), to = c("LOY")))
# Estimate the model
sat_model <- estimate_pls(data = satisfaction,
                          measurement_model = simple_mm,
                          structural_model = simple_sm,
                          inner_weights = path_weighting,
                          missing = mean_replacement,
                          missing_value = "-99")
# Summarize the model results
summary_sat_model <- summary(sat_model)
# Inspect the indicator loadings
summary_sat_model$loadings
# Inspect the model's path coefficients and the R^2 values
summary_sat_model$paths
```

```{r Model1 }
## Model 1
# Specifying the measurement model 
simple_mm <- constructs(
  composite("IMAG", multi_items("imag", 1:5), weights = mode_B),
  composite("EXPE", multi_items("expe", 1:5), weights = mode_A),
  composite("QUAL", multi_items("qual", 1:5), weights = mode_A),
  composite("VAL", multi_items("val", 1:4), weights = mode_A),
  composite("SAT", multi_items("sat", 1:4), weights = mode_A),
  composite("LOY", multi_items("loy", 1:4), weights = mode_A))
# Specifying the structural model 
simple_sm <- relationships(
  paths(from = c("IMAG"), to = c("EXPE", "SAT")),
  paths(from = c("EXPE"), to = c("QUAL", "SAT")),
  paths(from = c("QUAL"), to = c("VAL")),
  paths(from = c("VAL"), to = c("SAT")),
  paths(from = c("SAT"), to = c("LOY")))
# Estimate the model
sat_model <- estimate_pls(data = satisfaction,
                          measurement_model = simple_mm,
                          structural_model = simple_sm,
                          inner_weights = path_weighting,
                          missing = mean_replacement,
                          missing_value = "-99")
# Summarize the model results
summary_sat_model <- summary(sat_model)
# Inspect the indicator loadings
summary_sat_model$loadings
# Inspect the model's path coefficients and the R^2 values
summary_sat_model$paths
```


```{r Model2 }
## Model 2
# Specifying the measurement model 
simple_mm <- constructs(
  composite("IMAG", multi_items("imag", 1:5), weights = mode_B),
  composite("EXPE", c("val1","expe1", "expe2", "expe3", "expe4", "expe5"), weights = mode_A),
  composite("QUAL", multi_items("qual", 1:4), weights = mode_A),
  composite("VAL", multi_items("val", 2:4), weights = mode_A),
  composite("SAT", c("sat1","sat2", "sat3", "sat4", "loy1"), weights = mode_A),
  composite("LOY", multi_items("loy", 2:4), weights = mode_A))
# Specifying the structural model 
simple_sm <- relationships(
  paths(from = c("IMAG"), to = c("EXPE", "SAT", "LOY")),
  paths(from = c("EXPE"), to = c("QUAL", "SAT")),
  paths(from = c("QUAL"), to = c("VAL")),
  paths(from = c("VAL"), to = c("SAT")),
  paths(from = c("SAT"), to = c("LOY")))
# Estimate the model
sat_model <- estimate_pls(data = satisfaction,
                          measurement_model = simple_mm,
                          structural_model = simple_sm,
                          inner_weights = path_weighting,
                          missing = mean_replacement,
                          missing_value = "-99")
# Summarize the model results
summary_sat_model <- summary(sat_model)
# Inspect the indicator loadings
summary_sat_model$loadings
# Inspect the model's path coefficients and the R^2 values
summary_sat_model$paths
```


```{r Model3 }
## Model 3
# Specifying the measurement model 
simple_mm <- constructs(
  composite("IMAG", multi_items("imag", c(1,2,4,5)), weights = mode_A),
  composite("EXPE", multi_items("expe", 1:3), weights = mode_A),
  composite("QUAL", multi_items("qual", 1:5), weights = mode_A),
  composite("VAL", multi_items("val", 2:4), weights = mode_A),
  composite("SAT", c("sat1","sat2", "sat3", "sat4"), weights = mode_A),
  composite("LOY", c("val1","loy1","loy2", "loy3", "loy4"), weights = mode_A))
# Specifying the structural model 
simple_sm <- relationships(
  paths(from = c("IMAG"), to = c("EXPE", "SAT")),
  paths(from = c("EXPE"), to = c("QUAL", "SAT", "VAL")),
  paths(from = c("QUAL"), to = c("VAL")),
  paths(from = c("VAL"), to = c("SAT")),
  paths(from = c("SAT"), to = c("LOY")))
# Estimate the model
sat_model <- estimate_pls(data = satisfaction,
                          measurement_model = simple_mm,
                          structural_model = simple_sm,
                          inner_weights = path_weighting,
                          missing = mean_replacement,
                          missing_value = "-99")
# Summarize the model results
summary_sat_model <- summary(sat_model)
# Inspect the indicator loadings
summary_sat_model$loadings
# Inspect the model's path coefficients and the R^2 values
summary_sat_model$paths
```


Satisfaction is not in the book....


## 8.PLS_Ib: Model Estimation
```{r dataload Corporate Reputation}
# R script for the illustrations in chapter 3
rm(list=ls())
library(seminr)
# Read in data and inspect the first few observations
#corp_rep_data <- read.csv(file ="Corporate Reputation Data.csv",header=TRUE,sep=";") #Mortens dataload
corp_rep_data <- read.csv(file ="C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Explain Customer Behavior/PLS Morten/Corporate Reputation Data.csv",header=TRUE,sep=";")
head(corp_rep_data)
```
Corporate Reputation
 - the simple corporate reputation model has two main theoretical
components: (1) the target constructs of interest – namely, CUSA and CUSL (endogenous constructs) 
 – and (2) the two corporate reputation dimensions COMP
and LIKE (exogenous constructs), 

 - customer satisfaction (CUSA) 
 - customer loyalty (CUSL)
 - company’s competence (COMP)
represents cognitive evaluations of the company
 - company’s likeability (LIKE).
captures affective judgments

Competence (COMP)
 - comp_1 [The company] is a top competitor in its market
 - comp_2 As far as I know, [the company] is recognized worldwide
 - comp_3 I believe [the company] performs at a premium level
 
Likeability (LIKE)
 - like_1 [The company] is a company I can better identify with than other companies
 - like_2 [The company] is a company I would regret more not having if it no longer existed than I would other companies
 - like_3 I regard [the company] as a likeable company
 
Customer satisfaction (CUSA)
 - cusa I am satisfied with [the company]
 
Customer loyalty (CUSL)
 - cusl_1 I would recommend [company] to friends and relatives
 - cusl_2 If I had to choose again, I would choose [company] as my mobile phone service provider
 - cusl_3 I will remain a customer of [company] in the future
 
ANTEDECENTs (foregående) TO CORPORATE REPUTATION
-	Drivers of corporate reputation
o	Quality (QUAL)
o	Performance (PERF)
o	Attractiveness (ATTR)
o	Corporate social responsibility (CSOR)
 
```{r Original model: measurement/structural/estimate model}
# Create measurement model
simple_mm <- constructs(
  composite("COMP",multi_items("comp_",1:3),weights = mode_A),
  composite("LIKE",multi_items("like_",1:3),weights = mode_A),
  composite("CUSA",single_item("cusa")), #constructed alone
  composite("CUSL",multi_items("cusl_",1:3),weights = mode_A)) #Mode_A or correlation_weights for reflectively specified measurement models and mode_B or regression_weights for formatively specified measurement models. Mode_A is the default

# Create structural model
simple_sm <- relationships(paths(from = c("COMP","LIKE"), to = c("CUSA","CUSL")),
  paths(from = c("CUSA"), to = c("CUSL")))
# Estimate the model
corp_rep_simple_model <- estimate_pls(data = corp_rep_data,
                                      measurement_model = simple_mm,
                                      structural_model = simple_sm,
                                      inner_weights = path_weighting,
                                      missing = mean_replacement,
                                      missing_value = "-99")
# Estimate the model with default settings
corp_rep_simple_model <- estimate_pls(data = corp_rep_data,
                                      measurement_model = simple_mm,
                                      structural_model = simple_sm,
                                      missing_value = "-99")
# Summarize the model results
summary_simple_corp_rep <- summary(corp_rep_simple_model)
summary(corp_rep_simple_model)
```
Path Coefficients:
        CUSA  CUSL
R^2    0.295 0.562
AdjR^2 0.290 0.558
 - R^2: Indicates the proportion of variance in the dependent variables explained by the independent variables.
 - AdjR^2: Adjusted R-squared accounts for the number of predictors in the model.

        CUSA  CUSL
COMP   0.162 0.009
LIKE   0.424 0.342
CUSA       . 0.504
 - These coefficients indicate the strength and direction of the relationships between constructs.

Reliability:
     alpha  rhoC   AVE  rhoA
COMP 0.776 0.865 0.681 0.832
LIKE 0.831 0.899 0.747 0.836
CUSA 1.000 1.000 1.000 1.000(singleitem construct: perfect reliabily)
CUSL 0.831 0.899 0.748 0.839
alpha
 - Cronbach’s Alpha, measures internal consistency.
rhoC
 - Composite Reliability, measures the construct’s reliability.
AVE
 - Average Variance Extracted, measures the amount of variance captured by the construct in relation to the amount of variance due to measurement error.
rhoA
 - Another measure of composite reliability.

Alpha, rhoC, and rhoA should exceed 0.7 
AVE should exceed 0.5
SUMMARY: the model appears to have good reliability and validity, as all constructs meet the required thresholds for alpha, rhoC, rhoA, and AVE.

```{r Iterations + Loadings}
# Iterations to converge
summary_simple_corp_rep$iterations

# Inspect the model's loadings
summary_simple_corp_rep$loadings
```
Iterations
- 4 means that the algorithm converged after 4 iterations.
Loadings
- Loadings represent the correlation between the observed variables (indicators) and the latent variables (constructs).
- Higher loadings indicate that the indicator is a good measure of the latent construct.

PLS-SEM is a nonparametric method – thus, we need to perform bootstrapping to estimate standard errors and compute confidence intervals. 
```{r Bootstrap model}
# Bootstrap the model
boot_simple_corp_rep <- bootstrap_model(seminr_model = corp_rep_simple_model,nboot = 1000,cores = NULL, seed = 123)

# Store the summary of the bootstrapped model
sum_boot_simple_corp_rep <- summary(boot_simple_corp_rep)

# Inspect the bootstrapped indicator loadings
sum_boot_simple_corp_rep$bootstrapped_loadings
```
Bootstrap Mean:
- if the bootstrap mean values are very close to the original estimates, indicating that the original loadings are stable.

Bootstrap SD:
 - if the standard deviations (Bootstrap SD) are relatively small, indicating that the estimated loadings have low variability across the bootstrap samples, suggesting reliable estimates.

95% Confidence Intervals (CI):
 - confidence intervals (2.5% CI and 97.5% CI) do not include zero for any of the loadings, reinforcing the significance of these loadings.
 
SUMMARY
 -  bootstrap means are very close to the original estimates, with low variability as indicated by the bootstrap standard deviations. The high t-statistics and confidence intervals that do not include zero further confirm the significance of the indicators' loadings on their respective constructs. This robust bootstrap validation indicates that the PLS model is well-specified and that the measurement model is reliable.
 
Bootstrapped structural path coefficients 
 - Bootstrapping helps assess the stability and reliability of these path coefficients by resampling the data.
```{r Bootstrap model}
# Inspect the bootstrapped structural paths
sum_boot_simple_corp_rep$bootstrapped_paths
```
Bootstrap Mean:
 - the average of the path coefficients across all bootstrap samples.
Bootstrap SD:
 - the standard deviation of the path coefficients across the bootstrap samples, indicating the variability.
2.5% CI and 97.5% CI:
 - the 2.5th and 97.5th percentiles of the bootstrap distribution, representing the 95% confidence interval for the path coefficient.

Significance:
 - the paths LIKE -> CUSA, LIKE -> CUSL, and CUSA -> CUSL are highly significant, with high t-statistics and confidence intervals that do not include zero.
Non-Significance: 
 - the path COMP -> CUSL is not significant, as indicated by the confidence interval that includes zero.

Stability: 
- bootstrap means are very close to the original estimates, indicating that the path coefficients are stable and reliable.
Variability: 
- bootstrap standard deviations are relatively small, suggesting low variability in the path coefficients across the bootstrap samples.

SUMMARY:
- bootstrapped analysis confirms the robustness of the significant paths in the model, providing confidence in the reliability of these estimates.


This is using the satisfaction dataset once agian...
## 8.PLS_Ib_algorithm: Algorithm
```{r dataload satisfaction}
#install.packages("cSEM")
library(cSEM)
library(seminr)
# Example of PLS-SEM algorithm

# Get data
data(satisfaction)
# Selecting indicators 
sat_reduc <- satisfaction[,c("imag1", "imag2",
                             "expe1", "expe2",
                             "loy1", "loy2", "loy3")]
```

```{r Original model: measurement/structural model }
# Specifying the measurement model matrix
W <- matrix(c(1,0,0,
              1,0,0,
              0,1,0,
              0,1,0,
              0,0,1,
              0,0,1,
              0,0,1), 
            ncol = 3,
            byrow = TRUE)
# Specifying the structural model matrix
P <- matrix(c(0,0,1,
              0,0,1,
              0,0,0), 
            ncol = 3,
            byrow = TRUE)
```


```{r Initialization - step1}
# Standardizing and transforming to matrix
X <- as.matrix(scale(sat_reduc))

# Creating initial latent variables with weights equal to one
Y_hat=X%*%W
```


```{r Inner + Outer approximation - step2+3}
for (i in 1:300){
# Step 2, inner approximation

# Using factorial weighting scheme
#P[1:2,3] <- cor(Y_hat)[1:2,3]
#C <- P+t(P)
# Using path weighting
P[1:2,3] <- coef(lm(Y_hat[,3]~0+ Y_hat[,1:2]))
C <- P+t(P)
# Each latent variable is created as a weighted sum of its neighboring LVs
Y_hat <- Y_hat%*%C
# Standardizing latent variables
Y_hat <- scale(Y_hat)

# Step 3, outer approximation
# The reflective part (mode A)
W[5,3]=coef(lm(X[,5] ~ Y_hat[,3]))[2]
W[6,3]=coef(lm(X[,6] ~ Y_hat[,3]))[2]
W[7,3]=coef(lm(X[,7] ~ Y_hat[,3]))[2]
# The formative part (mode B)
W[1:2,1]=coef(lm(Y_hat[,1] ~ X[,1:2]))[2:3]
W[3:4,2]=coef(lm(Y_hat[,2] ~ X[,3:4]))[2:3]
# Estimate LV approximations
Y_hat=X%*%W
# Standardizing latent variables
Y_hat <- scale(Y_hat)

# Step 4, convergence of weights
# To simplify the code this step is skipped, and instead we set the number of iteration sufficiently high an hope for convergence. E.g. number of iteration=300.
# Notice that the algorithm normally converge must faster than after 300 iteration, but just setting a high number of iterations also means that we cannot be sure that the algorithm actually did converge.
}
```


```{r Final estimates - step5}
# Step 5: Final estimates

# Inner path coefficients
paths<-coef(lm(Y_hat[,3] ~ 0 + Y_hat[,1] + Y_hat[,2]))
# weights for formative models
weights<-c(coef(lm(Y_hat[,1] ~ 0 + X[,1] + X[,2])),
           coef(lm(Y_hat[,2] ~ 0 + X[,3] + X[,4])),
           coef(lm(Y_hat[,3] ~ 0 + X[,5] + X[,6] + X[,7]))
           )
# loadings for reflective model
loadings<-c(cor(Y_hat[,1],X[,1]),cor(Y_hat[,1],X[,2]),
            cor(Y_hat[,2],X[,3]),cor(Y_hat[,2],X[,4]),
            cor(Y_hat[,3],X[,5]),cor(Y_hat[,3],X[,6]),cor(Y_hat[,3],X[,7])
            )
```


```{r seminR Original model: measurement/structural model }
# Using seminR package
# Original model
# Specifying the measurement model 
simple_mm <- constructs(
  composite("IMAG", multi_items("imag", 1:2), weights = mode_B),
  composite("EXPE", multi_items("expe", 1:2), weights = mode_B),
  composite("LOY", multi_items("loy", 1:3), weights = mode_A))

# Specifying the structural model 
simple_sm <- relationships(
  paths(from = c("IMAG","EXPE"), to = c("LOY")))
# Estimate the model
sat_model <- estimate_pls(data = sat_reduc,
                          measurement_model = simple_mm,
                          structural_model = simple_sm,
#                          inner_weights = path_factorial,
                          inner_weights = path_weighting,
                          missing = mean_replacement,
                          missing_value = "-99")
# Summarize the model results
summary_sat_model <- summary(sat_model)
# Inspect the model's path coefficients and the R^2 values
summary_sat_model$paths
paths
# Inspect the indicator loadings
summary_sat_model$loadings
loadings
# Inspect the indicator weights
summary_sat_model$weights
weights
```


## 9.PLS_II: Reflective Measurement model

Reflective Measurement model
```{r dataload Corporate Reputation }
# R script for the illustrations in chapter 4
rm(list=ls())
library(seminr)

## Preparation
# Read in data 
#corp_rep_data <- read.csv(file ="Corporate Reputation Data.csv",header=TRUE,sep=";") #Mortens dataload
corp_rep_data <- read.csv(file ="C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Explain Customer Behavior/PLS Morten/Corporate Reputation Data.csv",header=TRUE,sep=";")
head(corp_rep_data)
```

ANTEDECENTs (foregående) TO CORPORATE REPUTATION
-	Drivers of corporate reputation
o	Quality (QUAL)
o	Performance (PERF)
o	Attractiveness (ATTR)
o	Corporate social responsibility (CSOR)


```{r Original model: measurement/structural/estimate model }
# Create measurement model
corp_rep_mm <- constructs(
  composite("COMP",multi_items("comp_",1:3),weights = mode_A),
  composite("LIKE",multi_items("like_",1:3),weights = mode_A),
  composite("CUSA",single_item("cusa")),
  composite("CUSL",multi_items("cusl_",1:3),weights = mode_A))
# Create structural model
corp_rep_sm <- relationships(
  paths(from = c("COMP","LIKE"), to = c("CUSA","CUSL")),
  paths(from = c("CUSA"), to = c("CUSL")))
# Estimate the model
corp_rep_pls_model <- estimate_pls(data = corp_rep_data,
                                   measurement_model = corp_rep_mm,
                                   structural_model = corp_rep_sm,
                                   inner_weights = path_weighting,
                                   missing = mean_replacement,
                                   missing_value = "-99")
# Summarize the model results
summary_corp_rep <- summary(corp_rep_pls_model)
summary(corp_rep_pls_model)
```
EXACTLY AS IN 8.PLS_Ib:
Path Coefficients:
        CUSA  CUSL
R^2    0.295 0.562
AdjR^2 0.290 0.558
 - R^2: Indicates the proportion of variance in the dependent variables explained by the independent variables.
 - AdjR^2: Adjusted R-squared accounts for the number of predictors in the model.

        CUSA  CUSL
COMP   0.162 0.009
LIKE   0.424 0.342
CUSA       . 0.504
 - These coefficients indicate the strength and direction of the relationships between constructs.

SUMMARY: the model appears to have good reliability and validity, as all constructs meet the required thresholds for alpha, rhoC, rhoA, and AVE.

COMMENT ON RELIABILITY BELOW!


```{r Iterations + Loadings }
# Iterations to converge
summary_corp_rep$iterations

# Inspect the indicator loadings
summary_corp_rep$loadings

# Inspect the indicator reliability
summary_corp_rep$loadings^2
```
Iterations
- 4 means that the algorithm converged after 4 iterations.

Loadings
- Loadings represent the correlation between the observed variables (indicators) and the latent variables (constructs).
- Higher loadings indicate that the indicator is a good measure of the latent construct.
-	As a rule of thumb, we would like that a construct explains more than 50% of an indicators variance: loading > 0.708	(0.708^2 = 0.5)

Indicator Reliability (Loadings Squared):
 - summary_corp_rep$loadings^2 computes the squared loadings for each indicator.
 - Squared loadings represent the proportion of variance in each indicator that is explained by its corresponding latent construct.
-	As a rule of thumb, we would like that a construct explains more than 50% of an indicators variance: loading^2 > 0.5)


comp_1: 0.736
comp_2: 0.638
comp_3: 0.669
 - indicate that 73.6%, 63.8%, and 66.9% of the variance in comp_1, comp_2, and comp_3 are explained by COMP, respectively.

From slides:
-	The true reliability usually lies between Cronbach’s α (lower bound) and the composite reliability (upper bound)
```{r Reliability + cronbachAlpha + Reliability plot }
# Inspect the Cronbachs alpha and composite reliability
summary_corp_rep$reliability

# Plot the reliabilities of constructs
plot(summary_corp_rep$reliability)
```
Reliability:
     alpha  rhoC   AVE  rhoA
COMP 0.776 0.865 0.681 0.832
LIKE 0.831 0.899 0.747 0.836
CUSA 1.000 1.000 1.000 1.000(singleitem construct: perfect reliabily)
CUSL 0.831 0.899 0.748 0.839
alpha
 - Cronbach’s Alpha, measures internal consistency.
rhoC
 - Composite Reliability, measures the construct’s reliability.
AVE
 - Average Variance Extracted, measures the amount of variance captured by the construct in relation to the amount of variance due to measurement error.
rhoA
 - Another measure of composite reliability.

Alpha, rhoC, and rhoA should exceed 0.7 
AVE should exceed 0.5
These tresholds are met by the measures, which is also seen in the plot.

Validity of constructs in a Partial Least Squares (PLS) structural equation model (SEM): 
Fornell-Larcker criterion
 - Discriminant validity ensures that a construct is truly distinct from other constructs in the model.
 - table shows the square root of the Average Variance Extracted (AVE) on the diagonal and the correlations between constructs on the lower triangle.
 - For discriminant validity to be established, the square root of the AVE of each construct (diagonal values) should be greater than the correlations with other constructs (off-diagonal values).
```{r Validity FL }
# Table of the FL criteria (FornellLarcker)
summary_corp_rep$validity$fl_criteria
```
Fornell-Larcker criterion
 - COMP: diagonal 0.825 is higher than lower traingle 0.645 0.436 0.450 
 - The diagonal values (square root of AVE) are higher than the off-diagonal values (construct correlations), 
 SUMMARY: indicating good discriminant validity.

Validity of constructs in a Partial Least Squares (PLS) structural equation model (SEM):
Heterotrait-Monotrait (HTMT) ratio
 - HTMT ratio is another method to assess discriminant validity. It is considered more reliable than the Fornell-Larcker criterion.
```{r Validity HTMT }
# HTMT criterion
summary_corp_rep$validity$htmt
```
HTMT 
 - values close to 1 indicate a lack of discriminant validity, whereas values below 0.85 (or 0.90 in some cases) indicate good discriminant validity.
 SUMMARY: All HTMT values are below 0.85, indicating good discriminant validity between the constructs.
 - Discriminant validity: means that each construct is distinct and measures a unique aspect of the data.

Bootstrap HTMT output
```{r Bootstrap model + HTMT output }
# Bootstrap the model
boot_corp_rep <- bootstrap_model(seminr_model = corp_rep_pls_model,
                                 nboot = 1000,cores = NULL,seed = 123)
sum_boot_corp_rep <- summary(boot_corp_rep, alpha = 0.10)

# Extract the bootstrapped HTMT
sum_boot_corp_rep$bootstrapped_HTMT
```
Bootstrap Mean:
- if the bootstrap mean values are very close to the original estimates, indicating that the original loadings are stable.

Bootstrap SD:
 - if the standard deviations (Bootstrap SD) are relatively small, indicating that the estimated loadings have low variability across the bootstrap samples, suggesting reliable estimates.

95% Confidence Intervals (CI):
 - confidence intervals (2.5% CI and 97.5% CI) do not include zero for any of the loadings, reinforcing the significance of these loadings.


## 10.PLS_IIIa: Formative Measurement model
Formative Measurement model
```{r dataload Corporate Reputation }
# R script for the illustrations in chapter 4
#rm(list=ls())
library(seminr)
# Read in data 
#corp_rep_data <- read.csv(file ="Corporate Reputation Data.csv",header=TRUE,sep=";") #Mortens dataload
corp_rep_data <- read.csv(file ="C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Explain Customer Behavior/PLS Morten/Corporate Reputation Data.csv",header=TRUE,sep=";")
head(corp_rep_data)
```

```{r Original model: measurement/structural/estimate model }
# Create measurement model
corp_rep_mm_ext <- constructs(
  composite("QUAL", multi_items("qual_", 1:8), weights = mode_B),
  composite("PERF", multi_items("perf_", 1:5), weights = mode_B),
  composite("CSOR", multi_items("csor_", 1:5), weights = mode_B),
  composite("ATTR", multi_items("attr_", 1:3), weights = mode_B),
#Below is the skeleton from the reflective model (weight mode_A)
  composite("COMP", multi_items("comp_", 1:3), weights = mode_A),
  composite("LIKE", multi_items("like_", 1:3), weights = mode_A),
  composite("CUSA", single_item("cusa")),
  composite("CUSL", multi_items("cusl_", 1:3), weights = mode_A))
# Create structural model
corp_rep_sm_ext <- relationships(
  paths(from = c("QUAL", "PERF", "CSOR", "ATTR"), 
        to = c("COMP", "LIKE")),
#Below is the skeleton from the reflective model (weight mode_A)
  paths(from = c("COMP", "LIKE"), 
        to = c("CUSA", "CUSL")),
  paths(from = c("CUSA"), 
        to = c("CUSL")))
# Estimate the model
corp_rep_pls_model_ext <- estimate_pls(data = corp_rep_data,measurement_model=corp_rep_mm_ext,structural_model=corp_rep_sm_ext,missing = mean_replacement,missing_value = "-99")
# Summarize the model results
summary_corp_rep_ext <- summary(corp_rep_pls_model_ext)
summary(corp_rep_pls_model_ext)
```
Path Coefficients:
        COMP  LIKE  CUSA  CUSL
R^2    0.631 0.558 0.292 0.562
AdjR^2 0.627 0.552 0.288 0.558
 - R^2: Indicates the proportion of variance in the dependent variables explained by the independent variables.
 - High R^2 values indicate that a significant portion of the variance in the endogenous constructs (COMP, LIKE, CUSA, CUSL) is explained by the exogenous constructs and other predictors.
 - AdjR^2: Adjusted R-squared accounts for the number of predictors in the model.

        COMP  LIKE  CUSA  CUSL
QUAL   0.430 0.380     .     .
PERF   0.295 0.117     .     .
CSOR   0.059 0.178     .     .
ATTR   0.086 0.167     .     .
COMP       .     . 0.146 0.006
LIKE       .     . 0.436 0.344
CUSA       .     .     . 0.505
 - These coefficients indicate the strength and direction of the relationships between constructs.
 - QUAL -> COMP: The path coefficient is 0.430, indicating that QUAL positively influences COMP.

COMMENT ON RELIABILITY BELOW!

Missing in PLS-SEM
o	Scarce knowledge on how advanced missing data procedures work for PLS-SEM
o	Remove an observation if it has many missing values for specific constructs
o	Mean replacement often used in literature
```{r Missingness }
library(dplyr)
#corp_rep_pls_model_ext <- corp_rep_pls_model_ext %>% 
#  filter(!if_any(everything(), ~ . == -99))
# Missingness
summary_corp_rep_ext$descriptives$statistics
```
not deleting missings yet - dont know the procedure

```{r Iterations + Loadings }
# Iterations to converge
summary_corp_rep_ext$iterations

## Evaluation of the reflective measurement model
# Inspect the indicator loadings
summary_corp_rep_ext$loadings
# Inspect the indicator reliability
summary_corp_rep_ext$loadings^2
```
Iterations
- 8 means that the algorithm converged after 8 iterations.

Loadings
- Loadings represent the correlation between the observed variables (indicators) and the latent variables (constructs).
- Higher loadings indicate that the indicator is a good measure of the latent construct.
-	As a rule of thumb, we would like that a construct explains more than 50% of an indicators variance: loading > 0.708	(0.708^2 = 0.5)

Indicator Reliability (Loadings Squared):
 - summary_corp_rep$loadings^2 computes the squared loadings for each indicator.
 - Squared loadings represent the proportion of variance in each indicator that is explained by its corresponding latent construct.
-	As a rule of thumb, we would like that a construct explains more than 50% of an indicators variance: loading^2 > 0.5)

comp_1: 0.679 
comp_2: 0.673 
comp_3: 0.712 
 - indicate that 67.9%, 67.3%, and 71.2% of the variance in comp_1, comp_2, and comp_3 are explained by COMP, respectively.

```{r Reliability + cronbachAlpha }
# Inspect the internal consistency reliability
summary_corp_rep_ext$reliability
```
Reliability:
     alpha  rhoC   AVE  rhoA
QUAL 0.878 0.894 0.518 1.000
PERF 0.747 0.824 0.488 1.000
CSOR 0.816 0.854 0.545 1.000
ATTR 0.600 0.770 0.540 1.000
COMP 0.776 0.869 0.688 0.786
LIKE 0.831 0.899 0.747 0.836
CUSA 1.000 1.000 1.000 1.000(singleitem construct: perfect reliabily)
CUSL 0.831 0.899 0.748 0.839

alpha
 - Cronbach’s Alpha, measures internal consistency.
rhoC
 - Composite Reliability, measures the construct’s reliability.
AVE
 - Average Variance Extracted, measures the amount of variance captured by the construct in relation to the amount of variance due to measurement error.
rhoA
 - Another measure of composite reliability.

Alpha, rhoC, and rhoA should exceed 0.7 
AVE should exceed 0.5
These tresholds are met by the measures, which is also seen in the plot.


Validity of constructs in a Partial Least Squares (PLS) structural equation model (SEM): 
Fornell-Larcker criterion
 - Discriminant validity ensures that a construct is truly distinct from other constructs in the model.
 - table shows the square root of the Average Variance Extracted (AVE) on the diagonal and the correlations between constructs on the lower triangle.
 - For discriminant validity to be established, the square root of the AVE of each construct (diagonal values) should be greater than the correlations with other constructs (off-diagonal values).
```{r Validity FL }
# Table of the FL criteria
summary_corp_rep_ext$validity$fl_criteria
```
Fornell-Larcker criterion
 - QUAL: diagonal 0.719 is NOT higher than lower traingle 0.788 0.763 
 - indicates a lack of discriminant validity between QUAL and these constructs PERF COMP.
 - The diagonal values (square root of AVE) are higher than the off-diagonal values (construct correlations), 
 SUMMARY: NOT indicating good discriminant validity between QUAL and PERF+COMP

Things to do when lacking dicriminant validity:
- Re-evaluate the items used to measure each construct. Ensure that the items are uniquely related to their respective constructs.
 - Consider whether the constructs are conceptually distinct. Overlapping constructs might indicate the need to redefine them.


Validity of constructs in a Partial Least Squares (PLS) structural equation model (SEM):
Heterotrait-Monotrait (HTMT) ratio
 - HTMT ratio is another method to assess discriminant validity. It is considered more reliable than the Fornell-Larcker criterion.
```{r Validity HTMT }
# HTMT criterion
summary_corp_rep_ext$validity$htmt
```
HTMT 
 - values close to 1 indicate a lack of discriminant validity, whereas values below 0.85 (or 0.90 in cases where constructs are conceptually similar) indicate good discriminant validity.
 - QUAL///PERF: 0.918 lack of discriminant validity
 - ATTR///PERF: 0.911 lack of discriminant validity
 - COMP///PERF: 0.946 lack of discriminant validity
 - indicates dicriminant validity issues between PERF and QUAL+ATTR+COMP

SUMMARY: NOT all HTMT values are below 0.85, not indicating good discriminant validity between all the constructs.
 - PERF is object for discriminant valilidity problems across several constructs
 - Discriminant validity: means that each construct is distinct and measures a unique aspect of the data.

Things to do when lacking dicriminant validity:
- Re-evaluate the items used to measure each construct. Ensure that the items are uniquely related to their respective constructs.
 - Consider whether the constructs are conceptually distinct. Overlapping constructs might indicate the need to redefine them.
From lecture:
 - Remove indicators which are highly correlated with indicators from the opposing construct
 - Reassign indicators to other constructs


Bootstrap HTMT output
```{r Bootstrap model + HTMT }
# Bootstrap the model
boot_corp_rep_ext <- bootstrap_model(
  seminr_model = corp_rep_pls_model_ext, nboot = 1000,cores = NULL,seed = 123)

sum_boot_corp_rep_ext <- summary(boot_corp_rep_ext, alpha = 0.10)
# Extract the bootstrapped HTMT
sum_boot_corp_rep_ext$bootstrapped_HTMT
```
Bootstrap Mean:
- if the bootstrap mean values are very close to the original estimates, indicating that the original loadings are stable.

Bootstrap SD:
 - if the standard deviations (Bootstrap SD) are relatively small, indicating that the estimated loadings have low variability across the bootstrap samples, suggesting reliable estimates.

95% Confidence Intervals (CI):
 - confidence intervals (2.5% CI and 97.5% CI) do not include zero for any of the loadings, reinforcing the significance of these loadings.
- Lecture: if 1 is included in CI, indicates lack of discriminant validity

## 10.PLS_IIIa: Redundancy analysis

REDUNDANCY ANALYSIS - ATTR: Attractiveness
 - examining the relationships between formative constructs and their related reflective constructs to ensure that the formative indicators adequately capture the underlying construct.
 Multi_item: from the indicators attr_1 -> 3
 Single_item: from the attr_global
```{r Redundancy ATTR: measurement/structural/estimate model }
## Evaluation of the formative measurement model
# Redundancy analysis      # ATTR: Attractiveness 
# Create measurement model
ATTR_redundancy_mm <- constructs(
  composite("ATTR_F", multi_items("attr_", 1:3), weights = mode_B),
  composite("ATTR_G", single_item("attr_global")))
# Create structural model
ATTR_redundancy_sm <- relationships(
  paths(from = c("ATTR_F"), to = c("ATTR_G")))
# Estimate the model
ATTR_redundancy_pls_model <- estimate_pls(data =corp_rep_data,
                                          measurement_model = ATTR_redundancy_mm,
                                          structural_model = ATTR_redundancy_sm,
                                          missing = mean_replacement,
                                          missing_value = "-99")
# Summarize the model
sum_ATTR_red_model <- summary(ATTR_redundancy_pls_model)
summary(ATTR_redundancy_pls_model)
```
Path Coefficients:
       ATTR_G
R^2     0.764
AdjR^2  0.763

 - R^2: Indicates the proportion of variance in the dependent variables explained by the independent variables.
 - High R^2 values indicate that a significant portion of the variance in the endogenous constructs is explained by the exogenous constructs and other predictors.
 - AdjR^2: Adjusted R-squared accounts for the number of predictors in the model.

       ATTR_G
ATTR_F  0.874
 - These coefficients indicate the strength and direction of the relationships between constructs.
 - ATTR_F -> ATTR_G: The path coefficient is 0.874, indicating that ATTR_F positively influences ATTR_G

Reliability:
       alpha  rhoC   AVE  rhoA
ATTR_F 0.600 0.772 0.543 1.000
ATTR_G 1.000 1.000 1.000 1.000
COMMENT ON RELIABILITY BELOW!

REDUNDANCY ANALYSIS - CSOR: Corporate social responsibility 
 - examining the relationships between formative constructs and their related reflective constructs to ensure that the formative indicators adequately capture the underlying construct.
 Multi_item: from the indicators csor_1 -> 5
 Single_item: from the csor_global
```{r Formative model CSOR: measurement/structural/estimate model }
# Create measurement model # CSOR: Corporate social responsibility 
CSOR_redundancy_mm <- constructs(
  composite("CSOR_F", multi_items("csor_", 1:5), weights = mode_B),
  composite("CSOR_G", single_item("csor_global")))
# Create structural model
CSOR_redundancy_sm <- relationships(
  paths(from = c("CSOR_F"), to = c("CSOR_G")))
# Estimate the model
CSOR_redundancy_pls_model <- estimate_pls(data = corp_rep_data,
                                          measurement_model = CSOR_redundancy_mm,
                                          structural_model = CSOR_redundancy_sm,
                                          missing = mean_replacement,
                                          missing_value = "-99")
# Summarize the model
sum_CSOR_red_model <- summary(CSOR_redundancy_pls_model)
summary(CSOR_redundancy_pls_model)
```
Path Coefficients:
       CSOR_G
R^2     0.735
AdjR^2  0.734

 - R^2: Indicates the proportion of variance in the dependent variables explained by the independent variables.
 - High R^2 values indicate that a significant portion of the variance in the endogenous constructs is explained by the exogenous constructs and other predictors.
 - AdjR^2: Adjusted R-squared accounts for the number of predictors in the model.

       CSOR_G
CSOR_F  0.857
 - These coefficients indicate the strength and direction of the relationships between constructs.
 - CSOR_F -> CSOR_G: The path coefficient is 0.857, indicating that CSOR_F positively influences CSOR_G

Reliability:
       alpha  rhoC   AVE  rhoA
CSOR_F 0.816 0.853 0.542 1.000
CSOR_G 1.000 1.000 1.000 1.000

REDUNDANCY ANALYSIS -  PERF: Performance 
 - examining the relationships between formative constructs and their related reflective constructs to ensure that the formative indicators adequately capture the underlying construct.
 Multi_item: from the indicators perf_1 -> 5
 Single_item: from the perf_global
```{r Formative model PERF: measurement/structural/estimate model }
# PERF: Performance 
# Create measurement model
PERF_redundancy_mm <- constructs(
  composite("PERF_F", multi_items("perf_", 1:5), weights = mode_B),
  composite("PERF_G", single_item("perf_global")))
# Create structural model
PERF_redundancy_sm <- relationships(
  paths(from = c("PERF_F"), to = c("PERF_G")))
# Estimate the model
PERF_redundancy_pls_model <- estimate_pls(data = corp_rep_data,
                                          measurement_model = PERF_redundancy_mm,
                                          structural_model = PERF_redundancy_sm,
                                          missing = mean_replacement,
                                          missing_value = "-99")
# Summarize the model
sum_PERF_red_model <- summary(PERF_redundancy_pls_model)
summary(PERF_redundancy_pls_model)
```
Path Coefficients:
       PERF_G
R^2     0.657
AdjR^2  0.656

 - R^2: Indicates the proportion of variance in the dependent variables explained by the independent variables.
 - High R^2 values indicate that a significant portion of the variance in the endogenous constructs is explained by the exogenous constructs and other predictors.
 - AdjR^2: Adjusted R-squared accounts for the number of predictors in the model.

       PERF_G
PERF_F  0.811
 - These coefficients indicate the strength and direction of the relationships between constructs.
 - PERF_F -> PERF_G: The path coefficient is 0.811, indicating that PERF_F positively influences PERF_G

Reliability:
       alpha  rhoC   AVE  rhoA
PERF_F 0.747 0.827 0.490 1.000
PERF_G 1.000 1.000 1.000 1.000

VIOLATION of the AVE in this reliability measure^^


REDUNDANCY ANALYSIS - QUAL: Quality
 - examining the relationships between formative constructs and their related reflective constructs to ensure that the formative indicators adequately capture the underlying construct.
 Multi_item: from the indicators qual_1 -> 8
 Single_item: from the qual_global
```{r Formative model QUAL: measurement/structural/estimate model }
# Create measurement model     # QUAL: Quality
QUAL_redundancy_mm <- constructs(
  composite("QUAL_F", multi_items("qual_", 1:8), weights = mode_B),
  composite("QUAL_G", single_item("qual_global")))
# Create structural model
QUAL_redundancy_sm <- relationships(
  paths(from = c("QUAL_F"), to = c("QUAL_G")))
# Estimate the model
QUAL_redundancy_pls_model <- estimate_pls(data = corp_rep_data,
                                          measurement_model = QUAL_redundancy_mm,
                                          structural_model = QUAL_redundancy_sm,
                                          missing = mean_replacement,
                                          missing_value = "-99")
# Summarize the model
sum_QUAL_red_model <- summary(QUAL_redundancy_pls_model)
summary(QUAL_redundancy_pls_model)
```
Path Coefficients:
       QUAL_G
R^2     0.648
AdjR^2  0.647

 - R^2: Indicates the proportion of variance in the dependent variables explained by the independent variables.
 - High R^2 values indicate that a significant portion of the variance in the endogenous constructs is explained by the exogenous constructs and other predictors.
 - AdjR^2: Adjusted R-squared accounts for the number of predictors in the model.

       QUAL_G
QUAL_F  0.805
 - These coefficients indicate the strength and direction of the relationships between constructs.
 - QUAL_F -> QUAL_G: The path coefficient is 0.805, indicating that QUAL_F positively influences QUAL_G

Reliability:
       alpha  rhoC   AVE  rhoA
QUAL_F 0.878 0.894 0.516 1.000
QUAL_G 1.000 1.000 1.000 1.000

SUMMARY for the 4 anove models^^^^ 
```{r Path coef: convergent validity }
# Check the path coefficients for convergent validity
sum_ATTR_red_model$paths
sum_CSOR_red_model$paths
sum_PERF_red_model$paths
sum_QUAL_red_model$paths
```

Variance Inflation Factor (VIF)
 - Collinearity analysis for several construct values. 
  - VIF measures the extent of multicollinearity among the predictor variables in a regression model. 
  - High VIF values indicate high multicollinearity, which can affect the stability and interpretation of the regression coefficients.
```{r Collinearity analysis }
# Collinearity analysis
summary_corp_rep_ext$validity$vif_items
# Assess indicator weights for significance and relevance
```
QUAL (Quality):
 - qual_1 to qual_8 have VIF values ranging from 1.362 to 2.269.
 - These values are below the commonly accepted threshold of 5, indicating that multicollinearity is not a concern for these indicators.

...

ATTR (Attractiveness):
 - attr_1 to attr_3 have VIF values ranging from 1.129 to 1.275.
 - These values indicate very low multicollinearity.
 
CUSA (Customer Satisfaction):
 - cusa has a VIF value of 1.
 - As it is a single item, VIF is not relevant here.
 
SUMMARY:
 - VIF values across all constructs (QUAL, PERF, CSOR, ATTR, COMP, LIKE, CUSA, CUSL) are all well below the threshold of 5, indicating that multicollinearity is not a significant issue in this dataset.
 - implies that the indicators within each construct do not exhibit problematic levels of correlation with each other, which supports the validity and reliability of the measurement model.

If high multicollinearity
 - Possible treatment of collinearity issues:	Remove indicator


NOT WORKING
```{r Bootstrap }
# Summarize the results of the bootstrap
# alpha sets the specified level for significance, i.e. 0.05
sum_boot_corp_rep_ext <- summary(boot_corp_rep_ext, alpha = 0.05)
# Inspect the bootstrapping results for indicator weights
sum_boot_corp_rep_ext$bootstrapped_weights
# Inspect the bootstrapping results for indicator loadings
sum_boot_corp_rep_ext$bootstrapped_loadings
```



## 10.PLS_IIIb: Structural Model

```{r dataload Corporate Reputation }
# R script for the illustrations in chapter 4
rm(list=ls())
library(seminr)
#corp_rep_data <- read.csv(file ="Corporate Reputation Data.csv",header=TRUE,sep=";") #Mortens dataload
corp_rep_data <- read.csv(file ="C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Explain Customer Behavior/PLS Morten/Corporate Reputation Data.csv",header=TRUE,sep=";")
head(corp_rep_data)
```

```{r Original model: measurement/structural/estimate model }
# Create measurement model
corp_rep_mm_ext <- constructs(
  composite("QUAL", multi_items("qual_", 1:8), weights = mode_B),
  composite("PERF", multi_items("perf_", 1:5), weights = mode_B),
  composite("CSOR", multi_items("csor_", 1:5), weights = mode_B),
  composite("ATTR", multi_items("attr_", 1:3), weights = mode_B),
  #Below is the skeleton from the reflective model (weight mode_A)
  composite("COMP", multi_items("comp_", 1:3), weights = mode_A),
  composite("LIKE", multi_items("like_", 1:3), weights = mode_A),
  composite("CUSA", single_item("cusa")),
  composite("CUSL", multi_items("cusl_", 1:3), weights = mode_A))
  # Create structural model
corp_rep_sm_ext <- relationships(
  paths(from = c("QUAL", "PERF", "CSOR", "ATTR"),
        to = c("COMP", "LIKE")),
  #Below is the skeleton from the reflective model (weight mode_A)
  paths(from = c("COMP", "LIKE"), 
        to = c("CUSA", "CUSL")),
  paths(from = c("CUSA"), 
        to = c("CUSL")))
# Estimate the model
corp_rep_pls_model_ext <- estimate_pls(
  data = corp_rep_data,measurement_model = corp_rep_mm_ext,
  structural_model = corp_rep_sm_ext,missing = mean_replacement,
  missing_value = "-99")
# Summarize the model results
summary_corp_rep_ext <- summary(corp_rep_pls_model_ext)
summary(corp_rep_pls_model_ext)
```
Path Coefficients:
        COMP  LIKE  CUSA  CUSL
R^2    0.631 0.558 0.292 0.562
AdjR^2 0.627 0.552 0.288 0.558
 - R^2: Indicates the proportion of variance in the dependent variables explained by the independent variables.
 - High R^2 values indicate that a significant portion of the variance in the endogenous constructs (COMP, LIKE, CUSA, CUSL) is explained by the exogenous constructs and other predictors.
 - AdjR^2: Adjusted R-squared accounts for the number of predictors in the model.
Slides:
o	The model can explain more than 50% of the variance in all endogenous constructs, except CUSA
o	Only minor difference between R^2 and R^2_adj

        COMP  LIKE  CUSA  CUSL
QUAL   0.430 0.380     .     .
PERF   0.295 0.117     .     .
CSOR   0.059 0.178     .     .
ATTR   0.086 0.167     .     .
COMP       .     . 0.146 0.006
LIKE       .     . 0.436 0.344
CUSA       .     .     . 0.505
 - These coefficients indicate the strength and direction of the relationships between constructs.
 - QUAL -> COMP: The path coefficient is 0.430, indicating that QUAL positively influences COMP.
Slides:
 -	Path coefficients relevance, direct effects
o	QUAL is the strongest driver of COMP and LIKE
o	CSOR and ATTR are more important for LIKE than for COMP
o	LIKE is the most important corporate reputation dimension in terms of creating customer satisfaction and customer loyalty
 -	Path coefficients relevance, total effects
o	QUAL is the most important of the four formative driver constructs in terms of creating customer satisfaction and customer loyalty
 -	Path coefficients significance
o	All direct effects are significant on a 5% level except the following four relations: CSOR  COMP, ATTR  COMP, PERF  LIKE and COMP  CUSL
-	The results indicate that companies should focus on creating likeability instead of competence to increase the customer loyalty


Reliability:
     alpha  rhoC   AVE  rhoA
QUAL 0.878 0.894 0.518 1.000
PERF 0.747 0.824 0.488 1.000
CSOR 0.816 0.854 0.545 1.000
ATTR 0.600 0.770 0.540 1.000
COMP 0.776 0.869 0.688 0.786
LIKE 0.831 0.899 0.747 0.836
CUSA 1.000 1.000 1.000 1.000
CUSL 0.831 0.899 0.748 0.839
 - COMMENT ON RELIABILITY BELOW!

```{r}
plot(corp_rep_pls_model_ext)
```


Bootstrap analysis
 - Bootstrapping is a resampling technique used to estimate the precision of sample estimates (such as path coefficients) by resampling with replacement from the original data and calculating the estimates in each resample.
```{r Bootstrap }
# Bootstrap the model
boot_corp_rep_ext <- bootstrap_model(seminr_model = corp_rep_pls_model_ext,nboot = 1000,cores = NULL,seed = 123)

# Summarize the results of the bootstrap
summary_boot_corp_rep_ext <- summary(boot_corp_rep_ext, alpha = 0.05)
summary(boot_corp_rep_ext, alpha = 0.05)
```
BOOTSTRAP STRUCTURAL PATH
Bootstrap Mean:
- if the bootstrap mean values are very close to the original estimates, indicating that the original loadings are stable.
IF ASKED FOR INDIRECT EFFECTS: Indirect Effects:
 - To calculate indirect effects, identify the paths through intermediate variables and multiply the direct effects along these paths. For example, the indirect effect of QUAL on CUSA through COMP and LIKE can be calculated by:
 - QUAL -> COMP -> CUSA
 - QUAL -> LIKE -> CUSA
 - The indirect effect of QUAL on CUSA through COMP is QUAL -> COMP * COMP -> CUSA = 0.430 * 0.146 = 0.06278

Bootstrap SD:
 - if the standard deviations (Bootstrap SD) are relatively small, indicating that the estimated loadings have low variability across the bootstrap samples, suggesting reliable estimates.

95% Confidence Intervals (CI):
 - confidence intervals (2.5% CI and 97.5% CI) do not include zero for any of the loadings, reinforcing the significance of these loadings.

SUMMARY BOOTSTRAPPED STRUCTURAL PATHS:
 - The bootstrap results indicate which paths in the structural model are statistically significant. Paths with t-statistics greater than 1.96 and confidence intervals that do not include zero are considered significant. 
  - From this analysis, most paths are significant, but 
  - paths like PERF -> LIKE, CSOR -> COMP, ATTR -> COMP, and COMP -> CUSL are not significant due to their confidence intervals including zero, indicating that these relationships are not statistically supported by the data.


BOOTSTRAP WEIGHTS
 - The table of bootstrapped weights includes the same columns as the structural paths, providing estimates for the measurement model.
 
BOOTSTRAP LOADINGS
 - provides the loadings for each indicator on their respective latent constructs, including the original estimate, bootstrap mean, standard deviation and confidence intervals.

BOOTSTRAP HTMT
 -  a measure of discriminant validity. The bootstrapped HTMT values include the original estimate, bootstrap mean, standard deviation, and confidence intervals.
 
BOOTSTRAP TOTAL PATHS
 - summarizes the total effects of the constructs on each other, including the direct and indirect effects.

 - dont pay attention to CUSA->CUSL as cant change the CUSA construct.  - primarily focus on the upper constructs/drivers
 - have to assess the drivers (as far as possible to the left: QUAL, PERF, CSOR, ATTR) that is actually able to regulate


SUMMARY BOOTSTRAPPING
 - Significant Paths: Paths with t-statistics greater than 1.96 (for a 95% confidence level) are considered statistically significant. For example, the path QUAL -> COMP is significant with a t-statistic of 6.603.
 - Confidence Intervals: If the confidence interval for a path does not include zero, the path is considered significant. For example, the path QUAL -> COMP has a 95% CI of (0.303, 0.552), which does not include zero, indicating significance.
 - Weights and Loadings: These should be significant to confirm the measurement model's reliability and validity.
 - HTMT: Values below 0.90 indicate good discriminant validity between constructs.


Variance Inflation Factor (VIF)
 - Collinearity analysis for Structural model. 
  - VIF measures the extent of multicollinearity among the predictor variables in the structural model. 
  - High VIF values indicate high multicollinearity, which can affect the variance of the regression coefficients and make an unstable model
```{r Structural model: collinearity VIF}
## Evaluation of the structural model
# Inspect the structural model collinearity VIF (Variance Importance Factor)
summary_corp_rep_ext$vif_antecedents
```
threshold of 5
COMP (Comp):
 - from QUAL to ATTR have VIF values ranging from 3.487 to 2.122
 - These values are below the commonly accepted threshold of 5, indicating that multicollinearity is not a concern for the structural model.
 
SUMMARY:
 - VIF values in this analysis indicate that multicollinearity is not a significant problem in the structural model. The highest VIF value observed is 3.487 for QUAL and LIKE predicting COMP, which is well below the threshold of concern. 
 - Therefore, the regression estimates for the structural paths in your model are likely to be stable and reliable.

If high multicollinearity
 - Possible treatment of collinearity issues:	Remove indicator


This is adressed with CAPS SUMMARY above
```{r Structural paths }
# Inspect the structural paths
#summary_boot_corp_rep_ext$bootstrapped_paths
#ORIGINAL estimates are the main thing: 
#WE want to identify the minuses in the ConfIntervals
```

This is adressed with CAPS SUMMARY above
```{r Total effects }
# Inspect the total effects
#summary_boot_corp_rep_ext$bootstrapped_total_paths
#WE dont pay attention to CUSA->CUSL as we cant change the CUSA construct. Therefore we primarily focus on the upper constructs/drivers
#WE have to assess the drivers (as far as possible to the left: QUAL, PERF, CSOR, ATTR) that we actually can regulate
```

Effect size f^2
 -  a measure of the impact of a specific exogenous construct on an endogenous construct in a structural model. It provides an indication of how much an exogenous construct contributes to the R^2 value of an endogenous construct
```{r R^2 + effect size }
# Inspect the model RSquares
#summary_corp_rep_ext$paths
#ARE the values above 0.5??
#THE R^2 VALUES ARE ASSESSED ABOVE

# Inspect the effect sizes
summary_corp_rep_ext$fSquare
```
Effect size f^2
 - Lecture: ALL of these r^2 are categorized as "small" except for CUSA having 0.4 or something as value
 - Small effect: f^2 > 0.02
 - Medium effect: f^2 > 0.15
 - Large effect: f^2 > 0.35
SUMMARY f^2:
 - The f^2 effect size values help in understanding the relative importance of each exogenous construct on the endogenous constructs. In this model, "CUSA" has a large effect on "CUSL", while most other effects are small or very small.
  - These insights can guide researchers in focusing on the most impactful relationships in their structural model.
Slides:


Results of model predictions
 - both in-sample and out-of-sample, using Partial Least Squares (PLS) and Linear Model (LM) techniques. 
```{r Prediction results }
# Generate the model predictions
predict_corp_rep_ext <- predict_pls(
  model = corp_rep_pls_model_ext,
  technique = predict_DA, 
  noFolds = 10, reps = 10)

# Summarize the prediction results
sum_predict_corp_rep_ext <- summary(predict_corp_rep_ext)
summary(predict_corp_rep_ext)
```
Comparison:    PLS vs. LM:
In-Sample:
 - Generally, the RMSE and MAE values for the LM model are slightly lower compared to the PLS model, indicating that the LM model fits the in-sample data better.
Out-of-Sample:
For out-of-sample data, the RMSE and MAE values for the LM model are slightly higher compared to the PLS model, suggesting that the PLS model might generalize better to new data.

Metrics Interpretation:
RMSE and MAE Values:
 - Lower RMSE and MAE values indicate better predictive performance. Comparing these values across different constructs and models helps to understand which model performs better for specific constructs.
SUMMARY Model predictions:
The metrics provided indicate that both PLS and LM models have their strengths, with the LM model performing better in-sample and the PLS model showing slightly better generalization out-of-sample. 
 - The choice between PLS and LM models may depend on the specific context and goals of the analysis. For more robust generalization, the PLS model might be preferred based on the given results.

Model prediction plot
 - shows the distribution of the predictive errors for the indicator cusl_1. 
  - The goal is to analyze the prediction errors to determine whether RMSE (Root Mean Square Error) or MAE (Mean Absolute Error) is more appropriate for evaluating the model's performance.
```{r Distribution prediction error }
# Analyze the distribution of prediction error
#par(mfrow=c(1,3))
plot(sum_predict_corp_rep_ext, indicator = "cusl_1")
plot(sum_predict_corp_rep_ext, indicator = "cusl_2")
plot(sum_predict_corp_rep_ext, indicator = "cusl_3")
#par(mfrow=c(1,1))
#Look for the distribution in the figure: is RMSE or MAE appropriate?
```
Model prediction plot for sepcific indicator
 - The plot appears to be roughly centered around zero, which is ideal because it indicates that the prediction errors are symmetrically distributed around the actual values.
Slides:
o	Only slightly negative skewed prediction errors
o	PLS-SEM predictions is better than linear benchmark predictions on all indicators



## 10.PLS_IIIb: Alternative models
```{r Alternative models1;2;3 }
# Estimate alternative models
# Create measurement model
measurement_model <- constructs(
composite("QUAL", multi_items("qual_", 1:8), weights = mode_B),
composite("PERF", multi_items("perf_", 1:5), weights = mode_B),
composite("CSOR", multi_items("csor_", 1:5), weights = mode_B),
composite("ATTR", multi_items("attr_", 1:3), weights = mode_B),
  composite("COMP", multi_items("comp_", 1:3)),
  composite("LIKE", multi_items("like_", 1:3)),
  composite("CUSA", single_item("cusa")),
  composite("CUSL", multi_items("cusl_", 1:3)))
# Create structural models
# Model 1
structural_model1 <- relationships(
  paths(from = c("QUAL","PERF","CSOR","ATTR"), 
        to = c("COMP", "LIKE")),
  paths(from = c("COMP","LIKE"), 
        to = c("CUSA", "CUSL")),
  paths(from = "CUSA", 
        to = c("CUSL")))
# Model 2
structural_model2 <- relationships(
  paths(from = c("QUAL","PERF","CSOR","ATTR"), 
        to = c("COMP", "LIKE", "CUSA")),
  paths(from = c("COMP","LIKE"), 
        to = c("CUSA", "CUSL")),
  paths(from = "CUSA", 
        to = c("CUSL")))
# Model 3
structural_model3 <- relationships(
  paths(from = c("QUAL","PERF","CSOR","ATTR"), 
        to = c("COMP", "LIKE", "CUSA", "CUSL")),
  paths(from = c("COMP","LIKE"), 
        to = c("CUSA", "CUSL")),
  paths(from = "CUSA", 
        to = c("CUSL")))
# Estimate and summarize the models
pls_model1 <- estimate_pls(
  data = corp_rep_data,
  measurement_model = measurement_model,
  structural_model = structural_model1,
  missing_value = "-99")
sum_model1 <- summary(pls_model1)

pls_model2 <- estimate_pls(
  data = corp_rep_data,
  measurement_model = measurement_model,
  structural_model = structural_model2,
  missing_value = "-99")
sum_model2 <- summary(pls_model2)

pls_model3 <- estimate_pls(
  data = corp_rep_data,
  measurement_model = measurement_model,
  structural_model = structural_model3,
  missing_value = "-99")
sum_model3 <- summary(pls_model3)
```

```{r}
plot(pls_model1)
plot(pls_model2)
plot(pls_model3)
```


```{r Alternative models1 IT Criteria }
# Inspect the IT Criteria matrix of Model1
sum_model1$it_criteria
```
AIC BIC Criteria
-	Generally a model with a high R^2 is preferred but at the same time parsimonious models are seen as more likely to generalize to other settings
-	The Bayesian information criterion (BIC) seeks to balance those two goals


```{r Alternative models1;2;3 BIC values }
# Collect the vector of BIC values for CUSL
itcriteria_vector <- c(sum_model1$it_criteria["BIC","CUSA"],
                       sum_model2$it_criteria["BIC","CUSA"],
                       sum_model3$it_criteria["BIC","CUSA"])

# Assign the model names to IT Criteria vector
names(itcriteria_vector) <- c("Model1", "Model2", "Model3")

# Inspect the IT Criteria vector for competing models
itcriteria_vector
#CHOOse the lowest BIC-value (be aware of minuses)
```
-	The model with the smallest BIC value is preferred
-	The relative benefits of the different models can be determined based on Akaike weights (building on BIC values)
-	These weights indicate a model’s relative likelihood given the data and a set of competing models


```{r Alternative models1;2;3 AIC criteria }
# Calculate the model BIC Akaike weights
compute_itcriteria_weights(itcriteria_vector)
#CHoose the highest AIC criteria
```
-	Comparing model 1 to model 2 and 3 gives a very strong weighting to model 1


## 11.PLS_IV: Mediation and moderation

```{r dataload Corporate Reputation }
# R script for the illustrations in chapter 4
rm(list=ls())
library(seminr)
#corp_rep_data <- read.csv(file ="Corporate Reputation Data.csv",header=TRUE,sep=";") #Mortens dataload
corp_rep_data <- read.csv(file ="C:/Users/Bruger/OneDrive - Aarhus universitet/8. semester - BI/CA - Customer Analytics/Explain Customer Behavior/PLS Morten/Corporate Reputation Data.csv",header=TRUE,sep=";")
head(corp_rep_data)
```

```{r Original model: measurement/structural/estimate model }
# Create measurement model
corp_rep_mm_ext <- constructs(
composite("QUAL", multi_items("qual_", 1:8), weights = mode_B),
composite("PERF", multi_items("perf_", 1:5), weights = mode_B),
composite("CSOR", multi_items("csor_", 1:5), weights = mode_B),
composite("ATTR", multi_items("attr_", 1:3), weights = mode_B),
composite("COMP", multi_items("comp_", 1:3), weights = mode_A),
composite("LIKE", multi_items("like_", 1:3), weights = mode_A),
composite("CUSA", single_item("cusa")),
composite("CUSL", multi_items("cusl_", 1:3), weights = mode_A))
# Create structural model
corp_rep_sm_ext <- relationships(
  paths(from = c("QUAL", "PERF", "CSOR", "ATTR"), 
        to = c("COMP", "LIKE")),
  paths(from = c("COMP", "LIKE"), 
        to = c("CUSA", "CUSL")),
  paths(from = c("CUSA"), 
        to = c("CUSL")))
# Estimate the model
corp_rep_pls_model_ext <- estimate_pls(
  data = corp_rep_data,
  measurement_model = corp_rep_mm_ext,
  structural_model = corp_rep_sm_ext,
  missing = mean_replacement,
  missing_value = "-99")
# Summarize the model results
summary_corp_rep_ext <- summary(corp_rep_pls_model_ext)
summary(corp_rep_pls_model_ext)
```
Path Coefficients:
        COMP  LIKE  CUSA  CUSL
R^2    0.631 0.558 0.292 0.562
AdjR^2 0.627 0.552 0.288 0.558
 - R^2: Indicates the proportion of variance in the dependent variables explained by the independent variables.
 - High R^2 values indicate that a significant portion of the variance in the endogenous constructs (COMP, LIKE, CUSA, CUSL) is explained by the exogenous constructs and other predictors.
 - AdjR^2: Adjusted R-squared accounts for the number of predictors in the model.

        COMP  LIKE  CUSA  CUSL
QUAL   0.430 0.380     .     .
PERF   0.295 0.117     .     .
CSOR   0.059 0.178     .     .
ATTR   0.086 0.167     .     .
COMP       .     . 0.146 0.006
LIKE       .     . 0.436 0.344
CUSA       .     .     . 0.505
 - These coefficients indicate the strength and direction of the relationships between constructs.
 - QUAL -> COMP: The path coefficient is 0.430, indicating that QUAL positively influences COMP.

Reliability:
     alpha  rhoC   AVE  rhoA
QUAL 0.878 0.894 0.518 1.000
PERF 0.747 0.824 0.488 1.000
CSOR 0.816 0.854 0.545 1.000
ATTR 0.600 0.770 0.540 1.000
COMP 0.776 0.869 0.688 0.786
LIKE 0.831 0.899 0.747 0.836
CUSA 1.000 1.000 1.000 1.000
CUSL 0.831 0.899 0.748 0.839
 - COMMENT ON RELIABILITY BELOW!

```{r}
plot(corp_rep_pls_model_ext)
```

Bootstrap analysis
 - Bootstrapping is a resampling technique used to estimate the precision of sample estimates (such as path coefficients) by resampling with replacement from the original data and calculating the estimates in each resample.
```{r Bootstrap }
# Bootstrap the model
boot_corp_rep_ext <- bootstrap_model(seminr_model = corp_rep_pls_model_ext,nboot = 1000,cores = NULL,seed = 123)

# Summarize the results of the bootstrap
summary_boot_corp_rep_ext <- summary(boot_corp_rep_ext, alpha = 0.10)
summary(boot_corp_rep_ext, alpha = 0.05)
```
BOOTSTRAP STRUCTURAL PATH
Bootstrap Mean:
- if the bootstrap mean values are very close to the original estimates, indicating that the original loadings are stable.
IF ASKED FOR INDIRECT EFFECTS: Indirect Effects:
 - To calculate indirect effects, identify the paths through intermediate variables and multiply the direct effects along these paths. For example, the indirect effect of QUAL on CUSA through COMP and LIKE can be calculated by:
 - QUAL -> COMP -> CUSA
 - QUAL -> LIKE -> CUSA
 - The indirect effect of QUAL on CUSA through COMP is QUAL -> COMP * COMP -> CUSA = 0.430 * 0.146 = 0.06278

Bootstrap SD:
 - if the standard deviations (Bootstrap SD) are relatively small, indicating that the estimated loadings have low variability across the bootstrap samples, suggesting reliable estimates.

95% Confidence Intervals (CI):
 - confidence intervals (2.5% CI and 97.5% CI) do not include zero for any of the loadings, reinforcing the significance of these loadings.

SUMMARY BOOTSTRAPPED STRUCTURAL PATHS:
 - The bootstrap results indicate which paths in the structural model are statistically significant. Paths with t-statistics greater than 1.96 and confidence intervals that do not include zero are considered significant. 
  - From this analysis, most paths are significant, but 
  - paths like PERF -> LIKE, CSOR -> COMP, ATTR -> COMP, and COMP -> CUSL are not significant due to their confidence intervals including zero, indicating that these relationships are not statistically supported by the data.


BOOTSTRAP WEIGHTS
 - The table of bootstrapped weights includes the same columns as the structural paths, providing estimates for the measurement model.
 
BOOTSTRAP LOADINGS
 - provides the loadings for each indicator on their respective latent constructs, including the original estimate, bootstrap mean, standard deviation and confidence intervals.

BOOTSTRAP HTMT
 -  a measure of discriminant validity. The bootstrapped HTMT values include the original estimate, bootstrap mean, standard deviation, and confidence intervals.
 
BOOTSTRAP TOTAL PATHS
 - summarizes the total effects of the constructs on each other, including the direct and indirect effects.

 - dont pay attention to CUSA->CUSL as cant change the CUSA construct.  - primarily focus on the upper constructs/drivers
 - have to assess the drivers (as far as possible to the left: QUAL, PERF, CSOR, ATTR) that is actually able to regulate


SUMMARY BOOTSTRAPPING
 - Significant Paths: Paths with t-statistics greater than 1.96 (for a 95% confidence level) are considered statistically significant. For example, the path QUAL -> COMP is significant with a t-statistic of 6.603.
 - Confidence Intervals: If the confidence interval for a path does not include zero, the path is considered significant. For example, the path QUAL -> COMP has a 95% CI of (0.303, 0.552), which does not include zero, indicating significance.
 - Weights and Loadings: These should be significant to confirm the measurement model's reliability and validity.
 - HTMT: Values below 0.90 indicate good discriminant validity between constructs.


-	SEM models in general and hence PLS-SEM allow for several advanced analysis possibilities
-	Mediation and moderation are two of the most profound examples
-	Mediation is not available in plain vanilla regression but only for the more complex models we study
-	Moderation is also known in regression analysis (based on simple/naive measurement models)
Mediation: formidling/mellemkomst(uvildig indblanden)/mægling
```{r Mediation analysis - TOTAL inderict effects }
# Inspect total indirect effects
summary_corp_rep_ext$total_indirect_effects
```
Row and Column Variables:
 - The rows represent the independent variables.
 - The columns represent the dependent variables.
QUAL (Quality):
 - QUAL -> CUSA: 0.228
This value indicates that the total indirect effect of "QUAL" on "CUSA" through all mediators is 0.228.
SUMMARY:
 - table provides a comprehensive view of how the independent variables affect the dependent variables through mediators. It helps in understanding the indirect pathways and their magnitudes in the model, which is crucial for mediation analysis and for identifying the most influential variables in the structural equation model.
 
 - specific_effect_significance function is used to test the significance of these indirect effects through bootstrapping. 
```{r Mediation analysis - inderict effects }
# Inspect indirect effects
specific_effect_significance(
  boot_corp_rep_ext, 
  from = "COMP", 
  through = "CUSA",
  to = "CUSL", alpha = 0.05)

specific_effect_significance(
  boot_corp_rep_ext, 
  from = "LIKE", 
  through = "CUSA",
  to = "CUSL", alpha = 0.05)
```
COMP -> CUSA -> CUSL
 - tests the significance of the indirect effect of "COMP" on "CUSL" through "CUSA".

Both indirect effect significance
 - COMP -> CUSA -> CUSL: This indirect effect is significant with an estimate of approximately 0.0735.
 - LIKE -> CUSA -> CUSL: This indirect effect is highly significant with an estimate of approximately 0.2200

Both of these mediators are significant.

TESTING ON LIKE (NOT COMP)
```{r Mediation analysis - direct effects }
# Inspect the direct effects
summary_corp_rep_ext$paths
# Inspect the confidence intervals for direct effects
summary_boot_corp_rep_ext$bootstrapped_paths
# Calculate the sign of p1*p2*p3
summary_corp_rep_ext$paths["LIKE", "CUSL"] *
  summary_corp_rep_ext$paths["LIKE","CUSA"] *
  summary_corp_rep_ext$paths["CUSA","CUSL"]
```
Check if the mediator is directly significant? (p3)
LIKE is significant:
                 T Stat.
LIKE  ->  CUSA   7.069
LIKE  ->  CUSL   6.175
and p1*p2*p3 is positive: 0.07569007
The mediator effect is then=
Complementary (partial mediation)

MODERATION
o	A moderator variable changes the strength or the direction of a relation between two constructs. Accounts for           heterogeneity in the data
o	A priori hypothesis about the data: Is it some specific     relation that is influenced by the moderator variable (interaction effect), or is it the entire model (multigroup analysis)?
o	Moderators can be single variables or constructs measured either formatively or reflectively
o	Can be categorical variables, e.g. the strength of the relation between satisfaction and loyalty could depend on gender. Most often used in multigroup analysis
Can be continuous variables, e.g. the relation between satisfaction and loyalty is influenced by the level of income
The moderation part
  interaction_term(iv = "CUSA", 
                   moderator = "SC", 
                   method = two_stage))
```{r Moderation analysis: Measurement/Structural/Estimation }
# Create measurement model
corp_rep_mm_mod <- constructs(
composite("QUAL", multi_items("qual_", 1:8), weights = mode_B),
composite("PERF", multi_items("perf_", 1:5), weights = mode_B),
composite("CSOR", multi_items("csor_", 1:5), weights = mode_B),
composite("ATTR", multi_items("attr_", 1:3), weights = mode_B),
composite("COMP", multi_items("comp_", 1:3), weights = mode_A),
composite("LIKE", multi_items("like_", 1:3), weights = mode_A),
composite("CUSA", single_item("cusa")),
composite("SC",   multi_items("switch_",1:4),weights = mode_A),
composite("CUSL", multi_items("cusl_", 1:3), weights = mode_A),
  interaction_term(iv = "CUSA", 
                   moderator = "SC", 
                   method = two_stage))
# Create structural model
corp_rep_sm_mod <- relationships(
  paths(from = c("QUAL", "PERF", "CSOR", "ATTR"), to = c("COMP", "LIKE")),
  paths(from = c("COMP", "LIKE"), to = c("CUSA", "CUSL")),
  paths(from = c("CUSA","SC","CUSA*SC"), to = c("CUSL")))
# Estimate the model
corp_rep_pls_model_mod <- estimate_pls(
  data = corp_rep_data,measurement_model = corp_rep_mm_mod,
  structural_model = corp_rep_sm_mod,missing = mean_replacement,
  missing_value = "-99")
# Summarize the model results
summary_corp_rep_mod <- summary(corp_rep_pls_model_mod)
summary(corp_rep_pls_model_mod)
```


```{r Bootstrap Moderation }
# Bootstrap the model
boot_corp_rep_mod <- bootstrap_model(seminr_model = corp_rep_pls_model_mod,nboot = 1000,cores = NULL,seed = 123)

# Summarize the results of the bootstrap
summary_boot_corp_rep_mod <- summary(boot_corp_rep_mod, alpha = 0.10)
```


```{r Reflective measurement model: loadings }
## Evaluation of the reflective measurement model
# Inspect the indicator loadings
summary_corp_rep_mod$loadings

# Inspect the indicator reliability
summary_corp_rep_mod$loadings^2
```


```{r Reflective measurement model: Internal Reliability }
# Inspect the internal consistency reliability
summary_corp_rep_mod$reliability
```


```{r Reflective measurement model: Validity FL + HTMT }
# Table of the FL criteria
summary_corp_rep_mod$validity$fl_criteria

# HTMT criterion
summary_corp_rep_mod$validity$htmt
```


```{r Reflective measurement model: Validity FL + HTMT }
# Extract the bootstrapped HTMT
summary_boot_corp_rep_mod$bootstrapped_HTMT
```

REDUNDANCY:
```{r Formative measurement model: ATTR }
#Evaluation of formative measurement model Redundancy analysis
# ATTR: Attractiveness
# Create measurement model
ATTR_redundancy_mm <- constructs(
composite("ATTR_F", multi_items("attr_",1:3),weights = mode_B),
composite("ATTR_G", single_item("attr_global")))
# Create structural model
ATTR_redundancy_sm <- relationships(
paths(from = c("ATTR_F"), to = c("ATTR_G")))
# Estimate the model
ATTR_redundancy_pls_model <- estimate_pls(
  data = corp_rep_data,measurement_model = ATTR_redundancy_mm,
  structural_model = ATTR_redundancy_sm,missing = mean_replacement,
  missing_value = "-99")
# Summarize the model
sum_ATTR_red_model <- summary(ATTR_redundancy_pls_model)
summary(ATTR_redundancy_pls_model)
```


```{r Formative measurement model: CSOR }
# CSOR: Customer Social Responsibility
# Create measurement model
CSOR_redundancy_mm <- constructs(
composite("CSOR_F",multi_items("csor_",1:5),weights = mode_B),
composite("CSOR_G", single_item("csor_global")))
# Create structural model
CSOR_redundancy_sm <- relationships(
paths(from = c("CSOR_F"), to = c("CSOR_G")))
# Estimate the model
CSOR_redundancy_pls_model <- estimate_pls(
  data = corp_rep_data,measurement_model = CSOR_redundancy_mm,
  structural_model = CSOR_redundancy_sm,missing = mean_replacement,
  missing_value = "-99")
# Summarize the model
sum_CSOR_red_model <- summary(CSOR_redundancy_pls_model)
summary(CSOR_redundancy_pls_model)
```


```{r Formative measurement model: PERF }
# PERF: Performance
# Create measurement model
PERF_redundancy_mm <- constructs(
composite("PERF_F",multi_items("perf_", 1:5),weights = mode_B),
  composite("PERF_G", single_item("perf_global")))
# Create structural model
PERF_redundancy_sm <- relationships(
paths(from = c("PERF_F"), to = c("PERF_G")))
# Estimate the model
PERF_redundancy_pls_model <- estimate_pls(
  data = corp_rep_data,measurement_model = PERF_redundancy_mm,structural_model = PERF_redundancy_sm,
  missing = mean_replacement,
  missing_value = "-99")
# Summarize the model
sum_PERF_red_model <- summary(PERF_redundancy_pls_model)
summary(PERF_redundancy_pls_model)
```


```{r Formative measurement model: QUAL }
# QUAL: Quality
# Create measurement model
QUAL_redundancy_mm <- constructs(
composite("QUAL_F", multi_items("qual_",1:8),weights = mode_B),
composite("QUAL_G", single_item("qual_global")))
# Create structural model
QUAL_redundancy_sm <- relationships(
paths(from = c("QUAL_F"), to = c("QUAL_G")))
# Estimate the model
QUAL_redundancy_pls_model <- estimate_pls(
  data = corp_rep_data,
  measurement_model = QUAL_redundancy_mm,
  structural_model = QUAL_redundancy_sm,
  missing = mean_replacement,
  missing_value = "-99")
# Summarize the model
sum_QUAL_red_model <- summary(QUAL_redundancy_pls_model)
summary(QUAL_redundancy_pls_model)
```

```{r Path coef: convergent validity }
# Check the path coefficients for convergent validity
sum_ATTR_red_model$paths
sum_CSOR_red_model$paths
sum_PERF_red_model$paths
sum_QUAL_red_model$paths
```


```{r Collinearity VIF }
# Collinearity analysis
summary_corp_rep_mod$validity$vif_items
```

```{r Bootstrap: weights }
# Summarize the results of the bootstrap
# alpha sets the specified level for significance, i.e. 0.05
sum_boot_corp_rep_mod <- summary(boot_corp_rep_mod, alpha = 0.05)

# Inspect the bootstrapping results for indicator weights
sum_boot_corp_rep_mod$bootstrapped_weights
```


```{r Bootstrap: weights;loadings }
# Inspect the bootstrapping results for indicator loadings
sum_boot_corp_rep_mod$bootstrapped_loadings
```


```{r Bootstrap Moderation: structural paths  }
## Moderation analysis
# Inspect the bootstrapped structural paths
sum_boot_corp_rep_mod$bootstrapped_paths
# Simple slope analysis plot
slope_analysis(
  moderated_model = corp_rep_pls_model_mod,dv = "CUSL",
  moderator = "SC", 
  iv = "CUSA", 
  leg_place = "bottomright")
```
The moderatio n part:
  interaction_term(iv = "CUSA", 
                   moderator = "SC", 
                   method = two_stage))
Plot
Moderation Analysis Plot:
 - Moderated Model: The plot illustrates the moderation effect of SC on the relationship between CUSA and CUSL.
Interpretation of the Plot:
 - The slopes of the lines indicate how the relationship between CUSA and CUSL changes at different levels of the moderator SC.
A steeper slope indicates a stronger relationship between CUSA and CUSL.
SUMMARY:
Significant Moderation:
The interaction term CUSA*SC -> CUSL is significant with a negative effect, indicating that the relationship between CUSA and CUSL decreases as SC increases.
Visual Analysis:
 - The plot visually confirms this interaction effect, showing different slopes for the relationship between CUSA and CUSL at different levels of SC.

This comprehensive analysis highlights the direct, indirect, and moderated effects within the model, providing valuable insights into how different variables interact to influence the dependent variable CUSL.


